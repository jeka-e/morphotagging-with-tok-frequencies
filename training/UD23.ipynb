{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "IUjZMZXtb89p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmES4yFcEMAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92cc820-5e0c-40eb-ed3c-af82522914cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: uvloop==0.14.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.14.0)\n",
            "Requirement already satisfied: aio-pika==6.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (6.4.1)\n",
            "Requirement already satisfied: tqdm==4.62.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.62.0)\n",
            "Requirement already satisfied: prometheus-client==0.7.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.7.1)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.4.5)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Requirement already satisfied: uvicorn==0.11.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.11.7)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.4.417127.4579844)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.21.2)\n",
            "Requirement already satisfied: fastapi==0.47.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.47.1)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.22.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Requirement already satisfied: pyopenssl==22.0.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (22.0.0)\n",
            "Requirement already satisfied: pytelegrambotapi==3.6.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.6.7)\n",
            "Requirement already satisfied: ruamel.yaml==0.15.100 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.15.100)\n",
            "Requirement already satisfied: Cython==0.29.14 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.29.14)\n",
            "Requirement already satisfied: sacremoses==0.0.35 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.35)\n",
            "Requirement already satisfied: pytz==2019.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2019.1)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.25.3)\n",
            "Requirement already satisfied: pydantic==1.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.3)\n",
            "Requirement already satisfied: numpy==1.18.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.18.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.10.0)\n",
            "Requirement already satisfied: overrides==2.7.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.7.0)\n",
            "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.5)\n",
            "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.8)\n",
            "Requirement already satisfied: aiormq<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (3.3.1)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (1.7.2)\n",
            "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Requirement already satisfied: cryptography>=35.0 in /usr/local/lib/python3.7/dist-packages (from pyopenssl==22.0.0->deeppavlov) (37.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.10.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.9.0)\n",
            "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (8.1)\n",
            "Requirement already satisfied: httptools==0.1.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.1.2)\n",
            "Requirement already satisfied: pamqp==2.3.0 in /usr/local/lib/python3.7/dist-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.2.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "! pip install deeppavlov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "034KTVnxF3XJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow-gpu==1.15.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU8RW0YGEVwp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! python -m deeppavlov install morpho_ru_syntagrus_bert\n",
        "! pip install pyconll\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install icecream"
      ],
      "metadata": {
        "id": "Gx8hhIJUcTZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from icecream import ic\n",
        "import os"
      ],
      "metadata": {
        "id": "mcApbpo4chwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qooinGiRdBr6",
        "outputId": "4807ec8d-e4dd-489c-fd80-1e35bbb3171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data and model"
      ],
      "metadata": {
        "id": "89m2jMJMcJky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "EGRf5xGxcaHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data and save it to data folder"
      ],
      "metadata": {
        "id": "SJCVFsWl2Gew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/UD2.3/ru_syntagrus.tar.gz"
      ],
      "metadata": {
        "id": "ZiJf5yrS_rbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTupZKfufKTc"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "  \n",
        "# open file\n",
        "file = tarfile.open('./ru_syntagrus.tar.gz')\n",
        "  \n",
        "# extracting file\n",
        "file.extractall('./data/UD2.3/ru_syntagrus')\n",
        "  \n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RuBERT"
      ],
      "metadata": {
        "id": "YGxpVfS4ccbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download bert model, don't know why though"
      ],
      "metadata": {
        "id": "4CvyP2TR2T4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz"
      ],
      "metadata": {
        "id": "q9slJMLbv_nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "file = tarfile.open('./rubert_cased_L-12_H-768_A-12_v1.tar.gz')\n",
        "  \n",
        "# extracting file\n",
        "file.extractall('./downloads/bert_models')\n",
        "  \n",
        "file.close()"
      ],
      "metadata": {
        "id": "A2mPT-j1weEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count and split tokens by frequency"
      ],
      "metadata": {
        "id": "Br3NWTQEcnXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datafolder_path = '/content/data/UD2.3/ru_syntagrus' #path to datafolder\n",
        "models_path = '/content/drive/MyDrive/models_diploma/UD2.3'"
      ],
      "metadata": {
        "id": "awnnlfyixzbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY5Ou00JEc3t"
      },
      "outputs": [],
      "source": [
        "from utils import divide_by_freq\n",
        "\n",
        "top100, top1000, other = divide_by_freq(datafolder_path+'/ru_syntagrus-ud-train.conllu')\n",
        "\n",
        "os.makedirs(models_path + '/freq_groups')\n",
        "\n",
        "for i, x in enumerate([top100, top1000, other]):\n",
        "    file_path = models_path + '/freq_groups' + '/{}.txt'.format(i)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(','.join(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Components"
      ],
      "metadata": {
        "id": "bb-UPIUPczCA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcMJpEuZLzPh"
      },
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYynb_4rKLUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425e63ba-72db-4236-c350-1bccddc177bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "from logging import getLogger\n",
        "from typing import Tuple, List, Optional, Union\n",
        "\n",
        "from deeppavlov.core.common.registry import register\n",
        "from bert_dp.preprocessing import convert_examples_to_features, InputExample, InputFeatures\n",
        "from bert_dp.tokenization import FullTokenizer\n",
        "\n",
        "from deeppavlov.core.commands.utils import expand_path\n",
        "from deeppavlov.core.data.utils import zero_pad\n",
        "from deeppavlov.core.models.component import Component\n",
        "from deeppavlov.models.preprocessors.mask import Mask\n",
        "\n",
        "\n",
        "@register('my_bert_ner_preprocessor')\n",
        "class MyBertNerPreprocessor(Component):\n",
        "    \"\"\"Takes tokens and splits them into bert subtokens, encodes subtokens with their indices.\n",
        "    Creates a mask of subtokens (one for the first subtoken, zero for the others).\n",
        "    If tags are provided, calculates tags for subtokens.\n",
        "    Args:\n",
        "        vocab_file: path to vocabulary\n",
        "        do_lower_case: set True if lowercasing is needed\n",
        "        max_seq_length: max sequence length in subtokens, including [SEP] and [CLS] tokens\n",
        "        max_subword_length: replace token to <unk> if it's length is larger than this\n",
        "            (defaults to None, which is equal to +infinity)\n",
        "        token_masking_prob: probability of masking token while training\n",
        "        provide_subword_tags: output tags for subwords or for words\n",
        "        subword_mask_mode: subword to select inside word tokens, can be \"first\" or \"last\"\n",
        "            (default=\"first\")\n",
        "    Attributes:\n",
        "        max_seq_length: max sequence length in subtokens, including [SEP] and [CLS] tokens\n",
        "        max_subword_length: rmax lenght of a bert subtoken\n",
        "        tokenizer: instance of Bert FullTokenizer\n",
        "\n",
        "    !!Added: \n",
        "        topk_tokens: path to file with tokens to consider in topk_tokens_mask in train mode\n",
        "        if list of files is passed,  condiser all the tokens apart from the ones included in the files\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_file: str,\n",
        "                 topk_tokens_path: List[str] = None, # added\n",
        "                 last: bool = False,\n",
        "                 do_lower_case: bool = False,\n",
        "                 max_seq_length: int = 512,\n",
        "                 max_subword_length: int = None,\n",
        "                 token_masking_prob: float = 0.0,\n",
        "                 provide_subword_tags: bool = False,\n",
        "                 subword_mask_mode: str = \"first\",\n",
        "                 **kwargs):\n",
        "        self._re_tokenizer = re.compile(r\"[\\w']+|[^\\w ]\")\n",
        "        self.provide_subword_tags = provide_subword_tags\n",
        "        self.mode = kwargs.get('mode')\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.max_subword_length = max_subword_length\n",
        "        self.subword_mask_mode = subword_mask_mode\n",
        "        vocab_file = str(expand_path(vocab_file))\n",
        "        self.tokenizer = FullTokenizer(vocab_file=vocab_file,\n",
        "                                       do_lower_case=do_lower_case)\n",
        "        self.token_masking_prob = token_masking_prob\n",
        "\n",
        "        self.last = None # added\n",
        "        self.topk_tokens = [] # added\n",
        "        for filename in topk_tokens_path: # added\n",
        "            with open(filename, 'r') as f: # added\n",
        "                  tokens = f.read().split(',') # added\n",
        "            self.topk_tokens.extend(tokens) # added\n",
        "        \n",
        "        \n",
        "        self.last = last\n",
        "        \n",
        "\n",
        "    def __call__(self,\n",
        "                 tokens: Union[List[List[str]], List[str]],\n",
        "                 tags: List[List[str]] = None,\n",
        "                 **kwargs):\n",
        "      \n",
        "        if isinstance(tokens[0], str):\n",
        "            tokens = [re.findall(self._re_tokenizer, s) for s in tokens]\n",
        "        subword_tokens, subword_tok_ids, startofword_markers, subword_tags, topk_tok_mask = [], [], [], [], []\n",
        "        for i in range(len(tokens)):\n",
        "            toks = tokens[i]\n",
        "            ys = ['O'] * len(toks) if tags is None else tags[i]\n",
        "            assert len(toks) == len(ys), \\\n",
        "                f\"toks({len(toks)}) should have the same length as ys({len(ys)})\"\n",
        "            sw_toks, sw_marker, sw_ys, tk_masks = \\\n",
        "                self._ner_bert_tokenize(toks,\n",
        "                                        ys,\n",
        "                                        self.topk_tokens, # added\n",
        "                                        self.tokenizer,\n",
        "                                        self.max_subword_length,\n",
        "                                        mode=self.mode,\n",
        "                                        last=self.last,\n",
        "                                        subword_mask_mode=self.subword_mask_mode,\n",
        "                                        token_masking_prob=self.token_masking_prob)\n",
        "            if self.max_seq_length is not None:\n",
        "                if len(sw_toks) > self.max_seq_length:\n",
        "                    raise RuntimeError(f\"input sequence after bert tokenization\"\n",
        "                                       f\" shouldn't exceed {self.max_seq_length} tokens.\")\n",
        "            topk_tok_mask.append(tk_masks) # added\n",
        "            subword_tokens.append(sw_toks)\n",
        "            subword_tok_ids.append(self.tokenizer.convert_tokens_to_ids(sw_toks))\n",
        "            startofword_markers.append(sw_marker)\n",
        "            subword_tags.append(sw_ys)\n",
        "            assert len(sw_marker) == len(sw_toks) == len(subword_tok_ids[-1]) == len(sw_ys), \\\n",
        "                f\"length of sow_marker({len(sw_marker)}), tokens({len(sw_toks)}),\" \\\n",
        "                f\" token ids({len(subword_tok_ids[-1])}) and ys({len(ys)})\" \\\n",
        "                f\" for tokens = `{toks}` should match\"\n",
        "\n",
        "        subword_tok_ids = zero_pad(subword_tok_ids, dtype=int, padding=0)\n",
        "        startofword_markers = zero_pad(startofword_markers, dtype=int, padding=0)\n",
        "        attention_mask = Mask()(subword_tokens)\n",
        "        topk_tok_mask = zero_pad(topk_tok_mask, dtype=int, padding=0) # added\n",
        "\n",
        "\n",
        "        if tags is not None:\n",
        "            if self.provide_subword_tags:\n",
        "                return tokens, subword_tokens, subword_tok_ids, \\\n",
        "                    attention_mask, startofword_markers, subword_tags\n",
        "            else:\n",
        "                nonmasked_tags = [[t for t in ts if t != 'X'] for ts in tags]\n",
        "                for swts, swids, swms, ts in zip(subword_tokens,\n",
        "                                                 subword_tok_ids,\n",
        "                                                 startofword_markers,\n",
        "                                                 nonmasked_tags):\n",
        "                    if (len(swids) != len(swms)) or (len(ts) != sum(swms)):\n",
        "                        log.warning('Not matching lengths of the tokenization!')\n",
        "                        log.warning(f'Tokens len: {len(swts)}\\n Tokens: {swts}')\n",
        "                        log.warning(f'Markers len: {len(swms)}, sum: {sum(swms)}')\n",
        "                        log.warning(f'Masks: {swms}')\n",
        "                        log.warning(f'Tags len: {len(ts)}\\n Tags: {ts}')\n",
        "                return tokens, subword_tokens, subword_tok_ids, \\\n",
        "                    attention_mask, startofword_markers, nonmasked_tags\n",
        "\n",
        "        return tokens, subword_tokens, subword_tok_ids, startofword_markers, attention_mask, topk_tok_mask\n",
        "\n",
        "    @staticmethod\n",
        "    def _ner_bert_tokenize(tokens: List[str],\n",
        "                           tags: List[str],\n",
        "                           topk_tokens: List[str],\n",
        "                           tokenizer: FullTokenizer,\n",
        "                           max_subword_len: int = None,\n",
        "                           mode: str = None,\n",
        "                           last: str = None,\n",
        "                           subword_mask_mode: str = \"first\",\n",
        "                           token_masking_prob: float = None) -> Tuple[List[str], List[int], List[str]]:\n",
        "        do_masking = (mode == 'train') and (token_masking_prob is not None)\n",
        "        do_cutting = (max_subword_len is not None)\n",
        "        tokens_subword = ['[CLS]']\n",
        "        topk_tokens_mask = [] # added\n",
        "        startofword_markers = [0]\n",
        "        tags_subword = ['X']\n",
        "        for token, tag in zip(tokens, tags):\n",
        "            token_marker = int(tag != 'X')\n",
        "            subwords = tokenizer.tokenize(token)\n",
        "            if not subwords or (do_cutting and (len(subwords) > max_subword_len)):\n",
        "                tokens_subword.append('[UNK]')\n",
        "                startofword_markers.append(token_marker)\n",
        "                tags_subword.append(tag)\n",
        "            else:\n",
        "                if do_masking and (random.random() < token_masking_prob):\n",
        "                    tokens_subword.extend(['[MASK]'] * len(subwords))\n",
        "                else:\n",
        "                    tokens_subword.extend(subwords)\n",
        "\n",
        "                if subword_mask_mode == \"last\":\n",
        "                    startofword_markers.extend([0] * (len(subwords) - 1) + [token_marker])\n",
        "                else: #subword_mask_mode=first\n",
        "                    startofword_markers.extend([token_marker] + [0] * (len(subwords) - 1))\n",
        "\n",
        "                if token.lower() in topk_tokens:  # added\n",
        "                    if last == True:  # added\n",
        "                        topk_tokens_mask.extend([0]) # added\n",
        "                    else:\n",
        "                        topk_tokens_mask.extend([1]) # added\n",
        "                else:\n",
        "                    if last == True:   # added\n",
        "                        topk_tokens_mask.extend([1]) # added\n",
        "                    else:\n",
        "                        topk_tokens_mask.extend([0]) # added\n",
        "\n",
        "\n",
        "                tags_subword.extend([tag] + ['X'] * (len(subwords) - 1))\n",
        "                \n",
        "        tokens_subword.append('[SEP]')\n",
        "        # topk_tokens_mask.append(0)\n",
        "        startofword_markers.append(0)\n",
        "        tags_subword.append('X')\n",
        "        return tokens_subword, startofword_markers, tags_subword, topk_tokens_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0czko8L2Iv"
      },
      "source": [
        "## Tagger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uV-LZV1HTH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c36e71-d51d-4451-d1e1-31fc05b80a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from logging import getLogger\n",
        "from typing import List, Union, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from bert_dp.modeling import BertConfig, BertModel\n",
        "from bert_dp.optimization import AdamWeightDecayOptimizer\n",
        "\n",
        "from deeppavlov.core.commands.utils import expand_path\n",
        "from deeppavlov.core.common.registry import register\n",
        "from deeppavlov.core.layers.tf_layers import bi_rnn\n",
        "from deeppavlov.core.models.tf_model import LRScheduledTFModel\n",
        "\n",
        "log = getLogger(__name__)\n",
        "\n",
        "\n",
        "def token_from_subtoken(units: tf.Tensor, mask: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\" Assemble token level units from subtoken level units\n",
        "    Args:\n",
        "        units: tf.Tensor of shape [batch_size, SUBTOKEN_seq_length, n_features]\n",
        "        mask: mask of token beginnings. For example: for tokens\n",
        "                [[``[CLS]`` ``My``, ``capybara``, ``[SEP]``],\n",
        "                [``[CLS]`` ``Your``, ``aar``, ``##dvark``, ``is``, ``awesome``, ``[SEP]``]]\n",
        "            the mask will be\n",
        "                [[0, 1, 1, 0, 0, 0, 0],\n",
        "                [0, 1, 1, 0, 1, 1, 0]]\n",
        "    Returns:\n",
        "        word_level_units: Units assembled from ones in the mask. For the\n",
        "            example above this units will correspond to the following\n",
        "                [[``My``, ``capybara``],\n",
        "                [``Your`, ``aar``, ``is``, ``awesome``,]]\n",
        "            the shape of this tensor will be [batch_size, TOKEN_seq_length, n_features]\n",
        "    \"\"\"\n",
        "    shape = tf.cast(tf.shape(units), tf.int64)\n",
        "    batch_size = shape[0]\n",
        "    nf = shape[2]\n",
        "    nf_int = units.get_shape().as_list()[-1]\n",
        "\n",
        "    # number of TOKENS in each sentence\n",
        "    token_seq_lengths = tf.cast(tf.reduce_sum(mask, 1), tf.int64)\n",
        "    # for a matrix m =\n",
        "    # [[1, 1, 1],\n",
        "    #  [0, 1, 1],\n",
        "    #  [1, 0, 0]]\n",
        "    # it will be\n",
        "    # [3, 2, 1]\n",
        "\n",
        "    n_words = tf.reduce_sum(token_seq_lengths)\n",
        "    # n_words -> 6\n",
        "\n",
        "    max_token_seq_len = tf.cast(tf.reduce_max(token_seq_lengths), tf.int64)\n",
        "    # max_token_seq_len -> 3\n",
        "\n",
        "    idxs = tf.where(mask)\n",
        "    # for the matrix mentioned above\n",
        "    # tf.where(mask) ->\n",
        "    # [[0, 0],\n",
        "    #  [0, 1]\n",
        "    #  [0, 2],\n",
        "    #  [1, 1],\n",
        "    #  [1, 2]\n",
        "    #  [2, 0]]\n",
        "\n",
        "    sample_ids_in_batch = tf.pad(idxs[:, 0], [[1, 0]])\n",
        "    # for indices\n",
        "    # [[0, 0],\n",
        "    #  [0, 1]\n",
        "    #  [0, 2],\n",
        "    #  [1, 1],\n",
        "    #  [1, 2],\n",
        "    #  [2, 0]]\n",
        "    # it is\n",
        "    # [0, 0, 0, 0, 1, 1, 2]\n",
        "    # padding is for computing change from one sample to another in the batch\n",
        "\n",
        "    a = tf.cast(tf.not_equal(sample_ids_in_batch[1:], sample_ids_in_batch[:-1]), tf.int64)\n",
        "    # for the example above the result of this statement equals\n",
        "    # [0, 0, 0, 1, 0, 1]\n",
        "    # so data samples begin in 3rd and 5th positions (the indexes of ones)\n",
        "\n",
        "    # transforming sample start masks to the sample starts themselves\n",
        "    q = a * tf.cast(tf.range(n_words), tf.int64)\n",
        "    # [0, 0, 0, 3, 0, 5]\n",
        "    count_to_substract = tf.pad(tf.boolean_mask(q, q), [(1, 0)])\n",
        "    # [0, 3, 5]\n",
        "\n",
        "    new_word_indices = tf.cast(tf.range(n_words), tf.int64) - tf.gather(count_to_substract, tf.cumsum(a))\n",
        "    # tf.range(n_words) -> [0, 1, 2, 3, 4, 5]\n",
        "    # tf.cumsum(a) -> [0, 0, 0, 1, 1, 2]\n",
        "    # tf.gather(count_to_substract, tf.cumsum(a)) -> [0, 0, 0, 3, 3, 5]\n",
        "    # new_word_indices -> [0, 1, 2, 3, 4, 5] - [0, 0, 0, 3, 3, 5] = [0, 1, 2, 0, 1, 0]\n",
        "    # new_word_indices is the concatenation of range(word_len(sentence))\n",
        "    # for all sentences in units\n",
        "\n",
        "    n_total_word_elements = tf.cast(batch_size * max_token_seq_len, tf.int32)\n",
        "    word_indices_flat = tf.cast(idxs[:, 0] * max_token_seq_len + new_word_indices, tf.int32)\n",
        "    x_mask = tf.reduce_sum(tf.one_hot(word_indices_flat, n_total_word_elements), 0)\n",
        "    x_mask = tf.cast(x_mask, tf.bool)\n",
        "    # to get absolute indices we add max_token_seq_len:\n",
        "    # idxs[:, 0] * max_token_seq_len -> [0, 0, 0, 1, 1, 2] * 2 = [0, 0, 0, 3, 3, 6]\n",
        "    # word_indices_flat -> [0, 0, 0, 3, 3, 6] + [0, 1, 2, 0, 1, 0] = [0, 1, 2, 3, 4, 6]\n",
        "    # total number of words in the batch (including paddings)\n",
        "    # batch_size * max_token_seq_len -> 3 * 3 = 9\n",
        "    # tf.one_hot(...) ->\n",
        "    # [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
        "    #  x_mask -> [1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
        "\n",
        "    full_range = tf.cast(tf.range(batch_size * max_token_seq_len), tf.int32)\n",
        "    # full_range -> [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "    nonword_indices_flat = tf.boolean_mask(full_range, tf.math.logical_not(x_mask))\n",
        "    # # y_idxs -> [5, 7, 8]\n",
        "\n",
        "    # get a sequence of units corresponding to the start subtokens of the words\n",
        "    # size: [n_words, n_features]\n",
        "    elements = tf.gather_nd(units, idxs)\n",
        "\n",
        "    # prepare zeros for paddings\n",
        "    # size: [batch_size * TOKEN_seq_length - n_words, n_features]\n",
        "    paddings = tf.zeros(tf.stack([tf.reduce_sum(max_token_seq_len - token_seq_lengths),\n",
        "                                  nf], 0), tf.float32)\n",
        "\n",
        "    tensor_flat = tf.dynamic_stitch([word_indices_flat, nonword_indices_flat],\n",
        "                                    [elements, paddings])\n",
        "    # tensor_flat -> [x, x, x, x, x, 0, x, 0, 0]\n",
        "\n",
        "    tensor = tf.reshape(tensor_flat, tf.stack([batch_size, max_token_seq_len, nf_int], 0))\n",
        "    # tensor -> [[x, x, x],\n",
        "    #            [x, x, 0],\n",
        "    #            [x, 0, 0]]\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "@register('my_bert_sequence_network')\n",
        "class MyBertSequenceNetwork(LRScheduledTFModel):\n",
        "    \"\"\"\n",
        "    Basic class for BERT-based sequential architectures.\n",
        "    Args:\n",
        "\n",
        "        keep_prob: dropout keep_prob for non-Bert layers\n",
        "        bert_config_file: path to Bert configuration file\n",
        "        pretrained_bert: pretrained Bert checkpoint\n",
        "        attention_probs_keep_prob: keep_prob for Bert self-attention layers\n",
        "        hidden_keep_prob: keep_prob for Bert hidden layers\n",
        "        encoder_layer_ids: list of averaged layers from Bert encoder (layer ids)\n",
        "            optimizer: name of tf.train.* optimizer or None for `AdamWeightDecayOptimizer`\n",
        "            weight_decay_rate: L2 weight decay for `AdamWeightDecayOptimizer`\n",
        "        encoder_dropout: dropout probability of encoder output layer\n",
        "        ema_decay: what exponential moving averaging to use for network parameters, value from 0.0 to 1.0.\n",
        "            Values closer to 1.0 put weight on the parameters history and values closer to 0.0 corresponds put weight\n",
        "            on the current parameters.\n",
        "        ema_variables_on_cpu: whether to put EMA variables to CPU. It may save a lot of GPU memory\n",
        "        freeze_embeddings: set True to not train input embeddings set True to\n",
        "            not train input embeddings set True to not train input embeddings\n",
        "        learning_rate: learning rate of BERT head\n",
        "        bert_learning_rate: learning rate of BERT body\n",
        "        min_learning_rate: min value of learning rate if learning rate decay is used\n",
        "        learning_rate_drop_patience: how many validations with no improvements to wait\n",
        "        learning_rate_drop_div: the divider of the learning rate after `learning_rate_drop_patience` unsuccessful\n",
        "            validations\n",
        "        load_before_drop: whether to load best model before dropping learning rate or not\n",
        "        clip_norm: clip gradients by norm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 keep_prob: float,\n",
        "                 bert_config_file: str,\n",
        "                 pretrained_bert: str = None,\n",
        "                 attention_probs_keep_prob: float = None,\n",
        "                 hidden_keep_prob: float = None,\n",
        "                 encoder_layer_ids: List[int] = (-1,),\n",
        "                 encoder_dropout: float = 0.0,\n",
        "                 optimizer: str = None,\n",
        "                 weight_decay_rate: float = 1e-6,\n",
        "                 ema_decay: float = None,\n",
        "                 ema_variables_on_cpu: bool = True,\n",
        "                 freeze_embeddings: bool = False,\n",
        "                 learning_rate: float = 1e-3,\n",
        "                 bert_learning_rate: float = 2e-5,\n",
        "                 min_learning_rate: float = 1e-07,\n",
        "                 learning_rate_drop_patience: int = 20,\n",
        "                 learning_rate_drop_div: float = 2.0,\n",
        "                 load_before_drop: bool = True,\n",
        "                 clip_norm: float = 1.0,\n",
        "                 **kwargs) -> None:\n",
        "        super().__init__(learning_rate=learning_rate,\n",
        "                         learning_rate_drop_div=learning_rate_drop_div,\n",
        "                         learning_rate_drop_patience=learning_rate_drop_patience,\n",
        "                         load_before_drop=load_before_drop,\n",
        "                         clip_norm=clip_norm,\n",
        "                         **kwargs)\n",
        "        self.keep_prob = keep_prob\n",
        "        self.encoder_layer_ids = encoder_layer_ids\n",
        "        self.encoder_dropout = encoder_dropout\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay_rate = weight_decay_rate\n",
        "        self.ema_decay = ema_decay\n",
        "        self.ema_variables_on_cpu = ema_variables_on_cpu\n",
        "        self.freeze_embeddings = freeze_embeddings\n",
        "        self.bert_learning_rate_multiplier = bert_learning_rate / learning_rate\n",
        "        self.min_learning_rate = min_learning_rate\n",
        "\n",
        "        self.bert_config = BertConfig.from_json_file(str(expand_path(bert_config_file)))\n",
        "\n",
        "        if attention_probs_keep_prob is not None:\n",
        "            self.bert_config.attention_probs_dropout_prob = 1.0 - attention_probs_keep_prob\n",
        "        if hidden_keep_prob is not None:\n",
        "            self.bert_config.hidden_dropout_prob = 1.0 - hidden_keep_prob\n",
        "\n",
        "        self.sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
        "        self.sess_config.gpu_options.allow_growth = True\n",
        "        self.sess = tf.Session(config=self.sess_config)\n",
        "\n",
        "        self._init_graph()\n",
        "\n",
        "        self._init_optimizer()\n",
        "\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        if pretrained_bert is not None:\n",
        "            pretrained_bert = str(expand_path(pretrained_bert))\n",
        "\n",
        "            if tf.train.checkpoint_exists(pretrained_bert) \\\n",
        "                    and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):\n",
        "                log.info('[initializing model with Bert from {}]'.format(pretrained_bert))\n",
        "                # Exclude optimizer and classification variables from saved variables\n",
        "                var_list = self._get_saveable_variables(\n",
        "                    exclude_scopes=('Optimizer', 'learning_rate', 'momentum', 'ner', 'EMA'))\n",
        "                saver = tf.train.Saver(var_list)\n",
        "                saver.restore(self.sess, pretrained_bert)\n",
        "\n",
        "        if self.load_path is not None:\n",
        "            self.load()\n",
        "\n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.init_op)\n",
        "\n",
        "    def _init_graph(self) -> None:\n",
        "        self.seq_lengths = tf.reduce_sum(self.y_masks_ph, axis=1)\n",
        "\n",
        "        self.bert = BertModel(config=self.bert_config,\n",
        "                              is_training=self.is_train_ph,\n",
        "                              input_ids=self.input_ids_ph,\n",
        "                              input_mask=self.input_masks_ph,\n",
        "                              token_type_ids=self.token_types_ph,\n",
        "                              use_one_hot_embeddings=False)\n",
        "        with tf.variable_scope('ner'):\n",
        "            layer_weights = tf.get_variable('layer_weights_',\n",
        "                                            shape=len(self.encoder_layer_ids),\n",
        "                                            initializer=tf.ones_initializer(),\n",
        "                                            trainable=True)\n",
        "            layer_mask = tf.ones_like(layer_weights)\n",
        "            layer_mask = tf.nn.dropout(layer_mask, self.encoder_keep_prob_ph)\n",
        "            layer_weights *= layer_mask\n",
        "            # to prevent zero division\n",
        "            mask_sum = tf.maximum(tf.reduce_sum(layer_mask), 1.0)\n",
        "            layer_weights = tf.unstack(layer_weights / mask_sum)\n",
        "            # TODO: may be stack and reduce_sum is faster\n",
        "            units = sum(w * l for w, l in zip(layer_weights, self.encoder_layers()))\n",
        "            units = tf.nn.dropout(units, keep_prob=self.keep_prob_ph)\n",
        "            # print('init graph var scope ner')\n",
        "        return units\n",
        "\n",
        "    def _get_tag_mask(self) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Returns: tag_mask,\n",
        "            a mask that selects positions corresponding to word tokens (not padding and `CLS`)\n",
        "        \"\"\"\n",
        "        max_length = tf.reduce_max(self.seq_lengths)\n",
        "        one_hot_max_len = tf.one_hot(self.seq_lengths - 1, max_length)\n",
        "        tag_mask = tf.cumsum(one_hot_max_len[:, ::-1], axis=1)[:, ::-1]\n",
        "\n",
        "        return tag_mask\n",
        "\n",
        "    def encoder_layers(self):\n",
        "        \"\"\"\n",
        "        Returns: the output of BERT layers specfied in ``self.encoder_layers_ids``\n",
        "        \"\"\"\n",
        "        return [self.bert.all_encoder_layers[i] for i in self.encoder_layer_ids]\n",
        "\n",
        "    def _init_placeholders(self) -> None:\n",
        "        self.input_ids_ph = tf.placeholder(shape=(None, None),\n",
        "                                           dtype=tf.int32,\n",
        "                                           name='token_indices_ph')\n",
        "        self.input_masks_ph = tf.placeholder(shape=(None, None),\n",
        "                                             dtype=tf.int32,\n",
        "                                             name='token_mask_ph')\n",
        "        self.token_types_ph = \\\n",
        "            tf.placeholder_with_default(tf.zeros_like(self.input_ids_ph, dtype=tf.int32),\n",
        "                                        shape=self.input_ids_ph.shape,\n",
        "                                        name='token_types_ph')\n",
        "        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name='learning_rate_ph')\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='keep_prob_ph')\n",
        "        self.encoder_keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='encoder_keep_prob_ph')\n",
        "        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name='is_train_ph')\n",
        "\n",
        "    def _init_optimizer(self) -> None:\n",
        "        with tf.variable_scope('Optimizer'):\n",
        "            self.global_step = tf.get_variable('global_step',\n",
        "                                               shape=[],\n",
        "                                               dtype=tf.int32,\n",
        "                                               initializer=tf.constant_initializer(0),\n",
        "                                               trainable=False)\n",
        "            # default optimizer for Bert is Adam with fixed L2 regularization\n",
        "\n",
        "        if self.optimizer is None:\n",
        "            self.train_op = \\\n",
        "                self.get_train_op(self.loss,\n",
        "                                  learning_rate=self.learning_rate_ph,\n",
        "                                  optimizer=AdamWeightDecayOptimizer,\n",
        "                                  weight_decay_rate=self.weight_decay_rate,\n",
        "                                  beta_1=0.9,\n",
        "                                  beta_2=0.999,\n",
        "                                  epsilon=1e-6,\n",
        "                                  optimizer_scope_name='Optimizer',\n",
        "                                  exclude_from_weight_decay=[\"LayerNorm\",\n",
        "                                                             \"layer_norm\",\n",
        "                                                             \"bias\",\n",
        "                                                             \"EMA\"])\n",
        "        else:\n",
        "            self.train_op = self.get_train_op(self.loss,\n",
        "                                              learning_rate=self.learning_rate_ph,\n",
        "                                              optimizer_scope_name='Optimizer')\n",
        "\n",
        "        if self.optimizer is None:\n",
        "            with tf.variable_scope('Optimizer'):\n",
        "                new_global_step = self.global_step + 1\n",
        "                self.train_op = tf.group(self.train_op, [self.global_step.assign(new_global_step)])\n",
        "\n",
        "        if self.ema_decay is not None:\n",
        "            _vars = self._get_trainable_variables(exclude_scopes=[\"Optimizer\",\n",
        "                                                                  \"LayerNorm\",\n",
        "                                                                  \"layer_norm\",\n",
        "                                                                  \"bias\",\n",
        "                                                                  \"learning_rate\",\n",
        "                                                                  \"momentum\"])\n",
        "\n",
        "            self.ema = ExponentialMovingAverage(self.ema_decay,\n",
        "                                                variables_on_cpu=self.ema_variables_on_cpu)\n",
        "            self.train_op = self.ema.build(self.train_op, _vars, name=\"EMA\")\n",
        "        else:\n",
        "            self.ema = None\n",
        "\n",
        "    def get_train_op(self, loss: tf.Tensor, learning_rate: Union[tf.Tensor, float], **kwargs) -> tf.Operation:\n",
        "        assert \"learnable_scopes\" not in kwargs, \"learnable scopes unsupported\"\n",
        "        # train_op for bert variables\n",
        "        kwargs['learnable_scopes'] = ('bert/encoder', 'bert/embeddings')\n",
        "        if self.freeze_embeddings:\n",
        "            kwargs['learnable_scopes'] = ('bert/encoder',)\n",
        "        bert_learning_rate = learning_rate * self.bert_learning_rate_multiplier\n",
        "        bert_train_op = super().get_train_op(loss,\n",
        "                                             bert_learning_rate,\n",
        "                                             **kwargs)\n",
        "        # train_op for ner head variables\n",
        "        kwargs['learnable_scopes'] = ('ner',)\n",
        "        # print('1 get train op')\n",
        "        head_train_op = super().get_train_op(loss,\n",
        "                                             learning_rate,\n",
        "                                             **kwargs)\n",
        "        return tf.group(bert_train_op, head_train_op)\n",
        "\n",
        "    def _build_basic_feed_dict(self, input_ids: tf.Tensor, input_masks: tf.Tensor,\n",
        "                               token_types: Optional[tf.Tensor]=None, train: bool=False) -> dict:\n",
        "        \"\"\"Fills the feed_dict with the tensors defined in the basic class.\n",
        "        You need to update this dict by the values of output placeholders\n",
        "        and class-specific network inputs in your derived class.\n",
        "        \"\"\"\n",
        "        # print('1 _build_basic_feed_dict')\n",
        "        feed_dict = {\n",
        "            self.input_ids_ph: input_ids,\n",
        "            self.input_masks_ph: input_masks,\n",
        "        }\n",
        "        if token_types is not None:\n",
        "            feed_dict[self.token_types_ph] = token_types\n",
        "        if train:\n",
        "            # print('1 _build_basic_feed_dict train')\n",
        "            feed_dict.update({\n",
        "                self.learning_rate_ph: max(self.get_learning_rate(), self.min_learning_rate),\n",
        "                self.keep_prob_ph: self.keep_prob,\n",
        "                self.encoder_keep_prob_ph: 1.0 - self.encoder_dropout,\n",
        "                self.is_train_ph: True,\n",
        "            })\n",
        "\n",
        "        return feed_dict\n",
        "\n",
        "    def _build_feed_dict(self, input_ids, input_masks, token_types=None, *args,  **kwargs):\n",
        "        raise NotImplementedError(\"You must implement _build_feed_dict in your derived class.\")\n",
        "\n",
        "    def train_on_batch(self,\n",
        "                       input_ids: Union[List[List[int]], np.ndarray],\n",
        "                       input_masks: Union[List[List[int]], np.ndarray],\n",
        "                      #  topk_tok_mask: Union[List[List[int]], np.ndarray]\n",
        "                       *args, **kwargs) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: batch of indices of subwords\n",
        "            input_masks: batch of masks which determine what should be attended\n",
        "            args: arguments passed  to _build_feed_dict\n",
        "                and corresponding to additional input\n",
        "                and output tensors of the derived class.\n",
        "            kwargs: keyword arguments passed to _build_feed_dict\n",
        "                and corresponding to additional input\n",
        "                and output tensors of the derived class.\n",
        "\n",
        "        Returns:\n",
        "            dict with fields 'loss', 'head_learning_rate', and 'bert_learning_rate'\n",
        "        \"\"\"\n",
        "        # print('1 tr_on_batch1')\n",
        "        feed_dict = self._build_feed_dict(input_ids, input_masks, *args, **kwargs)\n",
        "        # print('1 feed_dict_tr_batch')\n",
        "        # print('1 tr_on_batch2')\n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.switch_to_train_op)\n",
        "        # print('1 sess with loss')\n",
        "        # print(self.topk_tok_mask)\n",
        "        _, loss, lr = self.sess.run([self.train_op, self.loss, self.learning_rate_ph],\n",
        "                                     feed_dict=feed_dict)\n",
        "\n",
        "        return {'loss': loss,\n",
        "                'head_learning_rate': float(lr),\n",
        "                'bert_learning_rate': float(lr) * self.bert_learning_rate_multiplier}\n",
        "\n",
        "    def __call__(self,\n",
        "                 input_ids: Union[List[List[int]], np.ndarray],\n",
        "                 input_masks: Union[List[List[int]], np.ndarray],\n",
        "                 **kwargs) -> Union[List[List[int]], List[np.ndarray]]:\n",
        "        raise NotImplementedError(\"You must implement method __call__ in your derived class.\")\n",
        "\n",
        "    def save(self, exclude_scopes=('Optimizer', 'EMA/BackupVariables')) -> None:\n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.switch_to_train_op)\n",
        "        return super().save(exclude_scopes=exclude_scopes)\n",
        "\n",
        "    def load(self,\n",
        "             exclude_scopes=('Optimizer',\n",
        "                             'learning_rate',\n",
        "                             'momentum',\n",
        "                             'EMA/BackupVariables'),\n",
        "             **kwargs) -> None:\n",
        "        return super().load(exclude_scopes=exclude_scopes, **kwargs)\n",
        "\n",
        "\n",
        "@register('my_bert_sequence_tagger')\n",
        "class MyBertSequenceTagger(MyBertSequenceNetwork):\n",
        "    \"\"\"BERT-based model for text tagging. It predicts a label for every token (not subtoken) in the text.\n",
        "    You can use it for sequence labeling tasks, such as morphological tagging or named entity recognition.\n",
        "    See :class:`deeppavlov.models.bert.bert_sequence_tagger.BertSequenceNetwork`\n",
        "    for the description of inherited parameters.\n",
        "    Args:\n",
        "        n_tags: number of distinct tags\n",
        "        use_crf: whether to use CRF on top or not\n",
        "        use_birnn: whether to use bidirection rnn after BERT layers.\n",
        "            For NER and morphological tagging we usually set it to `False` as otherwise the model overfits\n",
        "        birnn_cell_type: the type of Bidirectional RNN. Either `lstm` or `gru`\n",
        "        birnn_hidden_size: number of hidden units in the BiRNN layer in each direction\n",
        "        return_probas: set this to `True` if you need the probabilities instead of raw answers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_tags: List[str],\n",
        "                 keep_prob: float,\n",
        "                 bert_config_file: str,\n",
        "                 pretrained_bert: str = None,\n",
        "                 attention_probs_keep_prob: float = None,\n",
        "                 hidden_keep_prob: float = None,\n",
        "                 use_crf=False,\n",
        "                 encoder_layer_ids: List[int] = (-1,),\n",
        "                 encoder_dropout: float = 0.0,\n",
        "                 optimizer: str = None,\n",
        "                 weight_decay_rate: float = 1e-6,\n",
        "                 use_birnn: bool = False,\n",
        "                 birnn_cell_type: str = 'lstm',\n",
        "                 birnn_hidden_size: int = 128,\n",
        "                 ema_decay: float = None,\n",
        "                 ema_variables_on_cpu: bool = True,\n",
        "                 return_probas: bool = False,\n",
        "                 freeze_embeddings: bool = False,\n",
        "                 learning_rate: float = 1e-3,\n",
        "                 bert_learning_rate: float = 2e-5,\n",
        "                 min_learning_rate: float = 1e-07,\n",
        "                 learning_rate_drop_patience: int = 20,\n",
        "                 learning_rate_drop_div: float = 2.0,\n",
        "                 load_before_drop: bool = True,\n",
        "                 clip_norm: float = 1.0,\n",
        "                 **kwargs) -> None:\n",
        "        self.n_tags = n_tags\n",
        "        self.use_crf = use_crf\n",
        "        self.use_birnn = use_birnn\n",
        "        self.birnn_cell_type = birnn_cell_type\n",
        "        self.birnn_hidden_size = birnn_hidden_size\n",
        "        self.return_probas = return_probas\n",
        "        super().__init__(keep_prob=keep_prob,\n",
        "                         bert_config_file=bert_config_file,\n",
        "                         pretrained_bert=pretrained_bert,\n",
        "                         attention_probs_keep_prob=attention_probs_keep_prob,\n",
        "                         hidden_keep_prob=hidden_keep_prob,\n",
        "                         encoder_layer_ids=encoder_layer_ids,\n",
        "                         encoder_dropout=encoder_dropout,\n",
        "                         optimizer=optimizer,\n",
        "                         weight_decay_rate=weight_decay_rate,\n",
        "                         ema_decay=ema_decay,\n",
        "                         ema_variables_on_cpu=ema_variables_on_cpu,\n",
        "                         freeze_embeddings=freeze_embeddings,\n",
        "                         learning_rate=learning_rate,\n",
        "                         bert_learning_rate=bert_learning_rate,\n",
        "                         min_learning_rate=min_learning_rate,\n",
        "                         learning_rate_drop_div=learning_rate_drop_div,\n",
        "                         learning_rate_drop_patience=learning_rate_drop_patience,\n",
        "                         load_before_drop=load_before_drop,\n",
        "                         clip_norm=clip_norm,\n",
        "                         **kwargs)\n",
        "\n",
        "    def _init_graph(self) -> None:\n",
        "        self._init_placeholders()\n",
        "\n",
        "        units = super()._init_graph()\n",
        "\n",
        "        with tf.variable_scope('ner'):\n",
        "            if self.use_birnn:\n",
        "                units, _ = bi_rnn(units,\n",
        "                                  self.birnn_hidden_size,\n",
        "                                  cell_type=self.birnn_cell_type,\n",
        "                                  seq_lengths=self.seq_lengths,\n",
        "                                  name='birnn')\n",
        "                units = tf.concat(units, -1)\n",
        "            # TODO: maybe add one more layer?\n",
        "            logits = tf.layers.dense(units, units=self.n_tags, name=\"output_dense\")\n",
        "            self.logits = token_from_subtoken(logits, self.y_masks_ph) #token_ids of startwords?\n",
        "\n",
        "            # CRF\n",
        "            if self.use_crf:\n",
        "                transition_params = tf.get_variable('Transition_Params',\n",
        "                                                    shape=[self.n_tags, self.n_tags],\n",
        "                                                    initializer=tf.zeros_initializer())\n",
        "                log_likelihood, transition_params = \\\n",
        "                    tf.contrib.crf.crf_log_likelihood(self.logits,\n",
        "                                                      self.y_ph,\n",
        "                                                      self.seq_lengths,\n",
        "                                                      transition_params)\n",
        "                loss_tensor = -log_likelihood\n",
        "                self._transition_params = transition_params\n",
        "\n",
        "            self.y_predictions = tf.argmax(self.logits, -1)\n",
        "            self.y_probas = tf.nn.softmax(self.logits, axis=2)\n",
        "\n",
        "        with tf.variable_scope(\"loss\"):\n",
        "            tag_mask = self._get_tag_mask()\n",
        "            y_mask = tf.cast(tag_mask, tf.float32)\n",
        "            if self.use_crf:\n",
        "                self.loss = tf.reduce_mean(loss_tensor)\n",
        "            else:                \n",
        "                self.loss = tf.losses.sparse_softmax_cross_entropy(labels=self.y_ph,\n",
        "                                                                   logits=self.logits,\n",
        "                                                                   weights=self.topk_masks_ph)  #instead of y_mask\n",
        "\n",
        "\n",
        "    def _init_placeholders(self) -> None:\n",
        "        super()._init_placeholders()\n",
        "        self.y_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='y_ph')\n",
        "        self.y_masks_ph = tf.placeholder(shape=(None, None),\n",
        "                                         dtype=tf.int32,\n",
        "                                         name='y_mask_ph')\n",
        "        self.topk_masks_ph = tf.placeholder(shape=(None, None),  # added\n",
        "                                         dtype=tf.int32,\n",
        "                                         name='topk_mask_ph')\n",
        "\n",
        "    def _decode_crf(self, feed_dict: Dict[tf.Tensor, np.ndarray]) -> List[np.ndarray]:\n",
        "        logits, trans_params, mask, seq_lengths = self.sess.run([self.logits,\n",
        "                                                                 self._transition_params,\n",
        "                                                                 self.y_masks_ph,\n",
        "                                                                 self.seq_lengths],\n",
        "                                                                feed_dict=feed_dict)\n",
        "        # iterate over the sentences because no batching in viterbi_decode\n",
        "        y_pred = []\n",
        "        for logit, sequence_length in zip(logits, seq_lengths):\n",
        "            logit = logit[:int(sequence_length)]  # keep only the valid steps\n",
        "            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
        "            y_pred += [viterbi_seq]\n",
        "        return y_pred\n",
        "\n",
        "    def _build_feed_dict(self, input_ids, input_masks, y_masks, topk_tok_mask, y=None):\n",
        "        feed_dict = self._build_basic_feed_dict(input_ids, input_masks, train=(y is not None))\n",
        "\n",
        "        if y is not None:\n",
        "            max_len = 0\n",
        "            for seq in topk_tok_mask:\n",
        "                if len(seq) > max_len:\n",
        "                    max_len = len(seq)\n",
        "            feed_dict[self.topk_masks_ph] = topk_tok_mask # added            \n",
        "            feed_dict[self.y_ph] = y\n",
        "        feed_dict[self.y_masks_ph] = y_masks\n",
        "\n",
        "        return feed_dict\n",
        "\n",
        "    def __call__(self,\n",
        "                 input_ids: Union[List[List[int]], np.ndarray],\n",
        "                 input_masks: Union[List[List[int]], np.ndarray],\n",
        "                 y_masks: Union[List[List[int]], np.ndarray],\n",
        "                 topk_tok_mask: Union[List[List[int]], np.ndarray]) -> Union[List[List[int]], List[np.ndarray]]:\n",
        "        \"\"\" Predicts tag indices for a given subword tokens batch\n",
        "        Args:\n",
        "            input_ids: indices of the subwords\n",
        "            input_masks: mask that determines where to attend and where not to\n",
        "            y_masks: mask which determines the first subword units in the the word\n",
        "\n",
        "        Added: \n",
        "            topk_tok_mask: mask that determines where to attend and where not to\n",
        "        Returns:\n",
        "            Label indices or class probabilities for each token (not subtoken)\n",
        "        # \"\"\"\n",
        "        \n",
        "        feed_dict = self._build_feed_dict(input_ids, input_masks, y_masks, topk_tok_mask)\n",
        "       \n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.switch_to_test_op)\n",
        "        if not self.return_probas:\n",
        "            if self.use_crf:\n",
        "                pred = self._decode_crf(feed_dict)\n",
        "            else:\n",
        "                pred, seq_lengths = self.sess.run([self.y_predictions, self.seq_lengths], feed_dict=feed_dict)\n",
        "                pred = [p[:l] for l, p in zip(seq_lengths, pred)]\n",
        "        else:\n",
        "            pred = self.sess.run(self.y_probas, feed_dict=feed_dict)\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "class ExponentialMovingAverage:\n",
        "    def __init__(self,\n",
        "                 decay: float = 0.999,\n",
        "                 variables_on_cpu: bool = True) -> None:\n",
        "        self.decay = decay\n",
        "        self.ema = tf.train.ExponentialMovingAverage(decay=decay)\n",
        "        self.var_device_name = '/cpu:0' if variables_on_cpu else None\n",
        "        self.train_mode = None\n",
        "\n",
        "    def build(self,\n",
        "              minimize_op: tf.Tensor,\n",
        "              update_vars: List[tf.Variable] = None,\n",
        "              name: str = \"EMA\") -> tf.Tensor:\n",
        "        with tf.variable_scope(name):\n",
        "            if update_vars is None:\n",
        "                update_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "\n",
        "            with tf.control_dependencies([minimize_op]):\n",
        "                minimize_op = self.ema.apply(update_vars)\n",
        "\n",
        "            with tf.device(self.var_device_name):\n",
        "                # Make backup variables\n",
        "                with tf.variable_scope('BackupVariables'):\n",
        "                    backup_vars = [tf.get_variable(var.op.name,\n",
        "                                                   dtype=var.value().dtype,\n",
        "                                                   trainable=False,\n",
        "                                                   initializer=var.initialized_value())\n",
        "                                   for var in update_vars]\n",
        "\n",
        "                def ema_to_weights():\n",
        "                    return tf.group(*(tf.assign(var, self.ema.average(var).read_value())\n",
        "                                      for var in update_vars))\n",
        "\n",
        "                def save_weight_backups():\n",
        "                    return tf.group(*(tf.assign(bck, var.read_value())\n",
        "                                      for var, bck in zip(update_vars, backup_vars)))\n",
        "\n",
        "                def restore_weight_backups():\n",
        "                    return tf.group(*(tf.assign(var, bck.read_value())\n",
        "                                      for var, bck in zip(update_vars, backup_vars)))\n",
        "\n",
        "                train_switch_op = restore_weight_backups()\n",
        "                with tf.control_dependencies([save_weight_backups()]):\n",
        "                    test_switch_op = ema_to_weights()\n",
        "\n",
        "            self.train_switch_op = train_switch_op\n",
        "            self.test_switch_op = test_switch_op\n",
        "            self.do_nothing_op = tf.no_op()\n",
        "\n",
        "        return minimize_op\n",
        "\n",
        "    @property\n",
        "    def init_op(self) -> tf.Operation:\n",
        "        self.train_mode = False\n",
        "        return self.test_switch_op\n",
        "\n",
        "    @property\n",
        "    def switch_to_train_op(self) -> tf.Operation:\n",
        "        assert self.train_mode is not None, \"ema variables aren't initialized\"\n",
        "        if not self.train_mode:\n",
        "            # log.info(\"switching to train mode\")\n",
        "            self.train_mode = True\n",
        "            return self.train_switch_op\n",
        "        return self.do_nothing_op\n",
        "\n",
        "    @property\n",
        "    def switch_to_test_op(self) -> tf.Operation:\n",
        "        assert self.train_mode is not None, \"ema variables aren't initialized\"\n",
        "        if self.train_mode:\n",
        "            # log.info(\"switching to test mode\")\n",
        "            self.train_mode = False\n",
        "            return self.test_switch_op\n",
        "        return self.do_nothing_op"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrMdYc1dG7eO"
      },
      "source": [
        "## Mask_ys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Component that masks tokens for the evaluation, so the metrics are counted considering certain group of tokens. By masking here I mean just forming new lists of tokens without the irrelevant ones."
      ],
      "metadata": {
        "id": "_yquqwCeE63b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS5h0kWtGx2e"
      },
      "outputs": [],
      "source": [
        "@register('mask_ys')\n",
        "class mask_ys(Component):\n",
        "    def __init__(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, y, topk_tok_mask, y_predicted, *args, **kwargs):\n",
        "\n",
        "        y_predicted_masked = []\n",
        "        y_masked = []\n",
        "        \n",
        "        for i in range(len(y_predicted)):\n",
        "            line_preds = []\n",
        "            line_true = []\n",
        "            for j in range(len(y_predicted[i])):\n",
        "                if topk_tok_mask[i][j] == 1:\n",
        "                    line_preds.append(y_predicted[i][j])\n",
        "                    line_true.append(y[i][j])\n",
        "            y_predicted_masked.append(np.array(line_preds))\n",
        "            y_masked.append(np.array(line_true))\n",
        "\n",
        "        return y_masked, y_predicted_masked"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Return Error - delete later, should be in Evaluate and Analysis"
      ],
      "metadata": {
        "id": "ylWGF63EOycm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@register('Info_logger')\n",
        "class Info_logger(Component):\n",
        "    def __init__(self, info_path, **kwargs):\n",
        "        os.makedirs(info_path, exist_ok=True)\n",
        "\n",
        "        self.error_path = info_path + '/errors.txt'\n",
        "        self.correct_path = info_path + '/correct.txt'\n",
        "        self.count_path = info_path + '/count.txt'\n",
        "\n",
        "\n",
        "    def __call__(self, y, topk_tok_mask, y_predicted, x_words, *args, **kwargs):\n",
        "        # ic (topk_tok_mask)\n",
        "        # ic (y_predicted)\n",
        "        # ic (y)\n",
        "\n",
        "        error_file = open(self.error_path, 'a')  # token/predicted/true/sentence\n",
        "        correct_file = open(self.correct_path, 'a') # token/predicted/sentence\n",
        "        count_file = open(self.count_path, 'a') # overall_tokens/correct_tokens\n",
        "\n",
        "        y_predicted_masked = []\n",
        "        y_masked = []\n",
        "        overall_tokens = 0\n",
        "        correct_tokens = 0\n",
        "\n",
        "        for i in range(len(y_predicted)):\n",
        "            line_preds = []\n",
        "            line_true = []\n",
        "            if x_words[i] != []:\n",
        "                sentence = ' '.join(x_words[i])\n",
        "            for j in range(len(y_predicted[i])):\n",
        "                if topk_tok_mask[i][j] == 1:\n",
        "                    overall_tokens += 1\n",
        "                    line_preds.append(y_predicted[i][j])\n",
        "                    line_true.append(y[i][j])\n",
        "                    if y_predicted[i][j] == y[i][j]:\n",
        "                        correct_tokens += 1\n",
        "                        correct_file.write(x_words[i][j] + '\\t' + y[i][j] + '\\t' + sentence + '\\n')\n",
        "                    else:\n",
        "                        error_file.write(x_words[i][j] + '\\t' + y_predicted[i][j] + '\\t' + y[i][j] + '\\t' + sentence + '\\n')\n",
        "\n",
        "            y_predicted_masked.append(np.array(line_preds))\n",
        "            y_masked.append(np.array(line_true))\n",
        "\n",
        "        \n",
        "        count_file.write(str(overall_tokens)+'\\t'+str(correct_tokens)+'\\n')\n",
        "\n",
        "        error_file.close()\n",
        "        correct_file.close()\n",
        "        count_file.close()\n",
        "        # ic (y_predicted_masked)\n",
        "        # ic (y_masked)\n",
        "        return y_masked, y_predicted_masked\n",
        "        "
      ],
      "metadata": {
        "id": "cq15SHY4Oyj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XSodQDbIMDo"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to specify in config:\n",
        "- ['dataset_reader']['data_path'] - path to datafolder\n",
        "- ['metadata']['variables']['MODELS_PATH'] - path to general folder devoted to certain dataset\n",
        "- ['train']['evaluation_targets'] = valid, ['dataset_reader']['data_types'] = ['train', 'dev'], if there is no test file\n",
        "- ['metadata']['variables']['DATA_PATH'] - path to datafolder\n",
        "\n",
        "will be specified below:\n",
        "- ['metadata']['variables']['WORK_PATH'] - path to certain model folder\n",
        "- ['chainer']['pipe'][1]['topk_tokens_path'] - path to the group of tokens to consider\n"
      ],
      "metadata": {
        "id": "yYptObzp3DO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-rIu6PaIb6J"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import json\n",
        "from deeppavlov import build_model, configs, train_model, evaluate_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUJPGa0qMu86"
      },
      "outputs": [],
      "source": [
        "base_config = json.load(open('./base_config.json'))\n",
        "\n",
        "base_config['metadata']['variables']['DATA_PATH'] = datafolder_path\n",
        "base_config['metadata']['variables']['MODELS_PATH'] = '{ROOT_PATH}/drive/MyDrive/models_diploma/UD2.3'\n",
        "base_config['train']['evaluation_targets'] = ['valid']\n",
        "base_config['dataset_reader']['data_types'] = ['train', 'dev']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUM0DVJd_82_"
      },
      "source": [
        "## From Scratch Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZJHizlECewm"
      },
      "source": [
        "### top100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XAii2IWQrvE"
      },
      "outputs": [],
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_top100'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False)#30 imp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-afuQlUGOO3",
        "outputId": "4e294141-d9dd-42de-bcb7-b004042ed5a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:53:54.684 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-19 20:53:57.653 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:54:17.478 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-19 20:54:50.939 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.0006, \"accuracy\": 0.0615}, \"time_spent\": \"0:00:34\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:56:33.616 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0006 to 0.9316\n",
            "2022-05-19 20:56:33.621 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 20:56:33.627 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9316, \"accuracy\": 0.76}, \"time_spent\": \"0:02:17\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 9600, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:58:12.579 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9316 to 0.9502\n",
            "2022-05-19 20:58:12.581 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 20:58:12.589 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9502, \"accuracy\": 0.8194}, \"time_spent\": \"0:03:56\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 19200, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:59:47.741 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9502 to 0.9614\n",
            "2022-05-19 20:59:47.742 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 20:59:47.752 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9614, \"accuracy\": 0.8546}, \"time_spent\": \"0:05:31\", \"epochs_done\": 0, \"batches_seen\": 900, \"train_examples_seen\": 28800, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:01:24.456 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9614 to 0.9662\n",
            "2022-05-19 21:01:24.458 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:01:24.468 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9662, \"accuracy\": 0.8729}, \"time_spent\": \"0:07:07\", \"epochs_done\": 0, \"batches_seen\": 1200, \"train_examples_seen\": 38382, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:03:01.596 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9662 to 0.9686\n",
            "2022-05-19 21:03:01.597 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:03:01.608 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9686, \"accuracy\": 0.8799}, \"time_spent\": \"0:08:45\", \"epochs_done\": 0, \"batches_seen\": 1500, \"train_examples_seen\": 47982, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:03:30.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9686, \"accuracy\": 0.8803}, \"time_spent\": \"0:09:14\", \"epochs_done\": 1, \"batches_seen\": 1526, \"train_examples_seen\": 48814, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:04:56.416 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9686 to 0.9715\n",
            "2022-05-19 21:04:56.418 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:04:56.427 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9715, \"accuracy\": 0.8906}, \"time_spent\": \"0:10:39\", \"epochs_done\": 1, \"batches_seen\": 1800, \"train_examples_seen\": 57582, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:06:33.359 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9715 to 0.9738\n",
            "2022-05-19 21:06:33.360 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:06:33.369 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.8993}, \"time_spent\": \"0:12:16\", \"epochs_done\": 1, \"batches_seen\": 2100, \"train_examples_seen\": 67182, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:08:09.584 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9738 to 0.975\n",
            "2022-05-19 21:08:09.585 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:08:09.593 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.975, \"accuracy\": 0.9026}, \"time_spent\": \"0:13:53\", \"epochs_done\": 1, \"batches_seen\": 2400, \"train_examples_seen\": 76764, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:09:47.484 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.975 to 0.9752\n",
            "2022-05-19 21:09:47.486 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:09:47.495 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9752, \"accuracy\": 0.904}, \"time_spent\": \"0:15:30\", \"epochs_done\": 1, \"batches_seen\": 2700, \"train_examples_seen\": 86364, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:11:19.843 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9748, \"accuracy\": 0.9033}, \"time_spent\": \"0:17:03\", \"epochs_done\": 1, \"batches_seen\": 3000, \"train_examples_seen\": 95964, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:11:48.498 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9752 to 0.9765\n",
            "2022-05-19 21:11:48.503 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:11:48.511 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9765, \"accuracy\": 0.9095}, \"time_spent\": \"0:17:32\", \"epochs_done\": 2, \"batches_seen\": 3052, \"train_examples_seen\": 97628, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:13:13.734 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9765 to 0.977\n",
            "2022-05-19 21:13:13.735 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:13:13.745 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.977, \"accuracy\": 0.9105}, \"time_spent\": \"0:18:57\", \"epochs_done\": 2, \"batches_seen\": 3300, \"train_examples_seen\": 105564, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:14:45.796 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9755, \"accuracy\": 0.9043}, \"time_spent\": \"0:20:29\", \"epochs_done\": 2, \"batches_seen\": 3600, \"train_examples_seen\": 115164, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:16:21.868 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9768, \"accuracy\": 0.9111}, \"time_spent\": \"0:22:05\", \"epochs_done\": 2, \"batches_seen\": 3900, \"train_examples_seen\": 124746, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:17:54.557 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9761, \"accuracy\": 0.907}, \"time_spent\": \"0:23:38\", \"epochs_done\": 2, \"batches_seen\": 4200, \"train_examples_seen\": 134346, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:19:22.274 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.977 to 0.978\n",
            "2022-05-19 21:19:22.275 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:19:22.284 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.978, \"accuracy\": 0.9156}, \"time_spent\": \"0:25:05\", \"epochs_done\": 2, \"batches_seen\": 4500, \"train_examples_seen\": 143946, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:20:01.248 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.978 to 0.9784\n",
            "2022-05-19 21:20:01.249 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:20:01.258 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9784, \"accuracy\": 0.9159}, \"time_spent\": \"0:25:44\", \"epochs_done\": 3, \"batches_seen\": 4578, \"train_examples_seen\": 146442, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:21:18.69 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9782, \"accuracy\": 0.916}, \"time_spent\": \"0:27:01\", \"epochs_done\": 3, \"batches_seen\": 4800, \"train_examples_seen\": 153546, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:22:46.506 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9784 to 0.9791\n",
            "2022-05-19 21:22:46.513 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:22:46.523 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9791, \"accuracy\": 0.9189}, \"time_spent\": \"0:28:30\", \"epochs_done\": 3, \"batches_seen\": 5100, \"train_examples_seen\": 163146, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:24:21.470 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9791, \"accuracy\": 0.9189}, \"time_spent\": \"0:30:04\", \"epochs_done\": 3, \"batches_seen\": 5400, \"train_examples_seen\": 172746, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:25:53.140 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9791 to 0.9792\n",
            "2022-05-19 21:25:53.146 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:25:53.151 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9792, \"accuracy\": 0.9201}, \"time_spent\": \"0:31:36\", \"epochs_done\": 3, \"batches_seen\": 5700, \"train_examples_seen\": 182328, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:27:31.510 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9792 to 0.9795\n",
            "2022-05-19 21:27:31.511 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:27:31.520 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9795, \"accuracy\": 0.92}, \"time_spent\": \"0:33:15\", \"epochs_done\": 3, \"batches_seen\": 6000, \"train_examples_seen\": 191928, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:28:18.130 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9773, \"accuracy\": 0.9119}, \"time_spent\": \"0:34:01\", \"epochs_done\": 4, \"batches_seen\": 6104, \"train_examples_seen\": 195256, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:29:23.654 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9795 to 0.98\n",
            "2022-05-19 21:29:23.656 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:29:23.668 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.98, \"accuracy\": 0.9221}, \"time_spent\": \"0:35:07\", \"epochs_done\": 4, \"batches_seen\": 6300, \"train_examples_seen\": 201510, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:31:00.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9792, \"accuracy\": 0.92}, \"time_spent\": \"0:36:43\", \"epochs_done\": 4, \"batches_seen\": 6600, \"train_examples_seen\": 211110, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:32:32.413 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.98, \"accuracy\": 0.9222}, \"time_spent\": \"0:38:15\", \"epochs_done\": 4, \"batches_seen\": 6900, \"train_examples_seen\": 220710, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:34:01.785 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9789, \"accuracy\": 0.9189}, \"time_spent\": \"0:39:45\", \"epochs_done\": 4, \"batches_seen\": 7200, \"train_examples_seen\": 230310, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:35:31.252 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9799, \"accuracy\": 0.9231}, \"time_spent\": \"0:41:14\", \"epochs_done\": 4, \"batches_seen\": 7500, \"train_examples_seen\": 239910, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:36:20.680 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.98 to 0.9802\n",
            "2022-05-19 21:36:20.681 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:36:20.691 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9235}, \"time_spent\": \"0:42:04\", \"epochs_done\": 5, \"batches_seen\": 7630, \"train_examples_seen\": 244070, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:37:28.13 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9796, \"accuracy\": 0.9203}, \"time_spent\": \"0:43:11\", \"epochs_done\": 5, \"batches_seen\": 7800, \"train_examples_seen\": 249492, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:38:58.784 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9231}, \"time_spent\": \"0:44:42\", \"epochs_done\": 5, \"batches_seen\": 8100, \"train_examples_seen\": 259092, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:40:28.221 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9799, \"accuracy\": 0.9216}, \"time_spent\": \"0:46:11\", \"epochs_done\": 5, \"batches_seen\": 8400, \"train_examples_seen\": 268692, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:41:58.21 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9792, \"accuracy\": 0.9193}, \"time_spent\": \"0:47:41\", \"epochs_done\": 5, \"batches_seen\": 8700, \"train_examples_seen\": 278292, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:43:28.594 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9802 to 0.9808\n",
            "2022-05-19 21:43:28.595 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:43:28.605 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9808, \"accuracy\": 0.9253}, \"time_spent\": \"0:49:12\", \"epochs_done\": 5, \"batches_seen\": 9000, \"train_examples_seen\": 287892, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:44:27.832 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9806, \"accuracy\": 0.9245}, \"time_spent\": \"0:50:11\", \"epochs_done\": 6, \"batches_seen\": 9156, \"train_examples_seen\": 292884, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:45:22.367 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9786, \"accuracy\": 0.9165}, \"time_spent\": \"0:51:05\", \"epochs_done\": 6, \"batches_seen\": 9300, \"train_examples_seen\": 297492, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:46:52.564 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.98, \"accuracy\": 0.9219}, \"time_spent\": \"0:52:36\", \"epochs_done\": 6, \"batches_seen\": 9600, \"train_examples_seen\": 307092, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:48:23.778 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9807, \"accuracy\": 0.9247}, \"time_spent\": \"0:54:07\", \"epochs_done\": 6, \"batches_seen\": 9900, \"train_examples_seen\": 316674, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:49:55.204 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9797, \"accuracy\": 0.9209}, \"time_spent\": \"0:55:38\", \"epochs_done\": 6, \"batches_seen\": 10200, \"train_examples_seen\": 326274, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:51:23.808 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9227}, \"time_spent\": \"0:57:07\", \"epochs_done\": 6, \"batches_seen\": 10500, \"train_examples_seen\": 335874, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:52:24.860 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9798, \"accuracy\": 0.9219}, \"time_spent\": \"0:58:08\", \"epochs_done\": 7, \"batches_seen\": 10682, \"train_examples_seen\": 341698, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:53:11.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9801, \"accuracy\": 0.9231}, \"time_spent\": \"0:58:55\", \"epochs_done\": 7, \"batches_seen\": 10800, \"train_examples_seen\": 345474, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:54:42.716 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9808 to 0.9812\n",
            "2022-05-19 21:54:42.717 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:54:42.734 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9812, \"accuracy\": 0.9259}, \"time_spent\": \"1:00:26\", \"epochs_done\": 7, \"batches_seen\": 11100, \"train_examples_seen\": 355074, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:56:18.659 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9805, \"accuracy\": 0.9241}, \"time_spent\": \"1:02:02\", \"epochs_done\": 7, \"batches_seen\": 11400, \"train_examples_seen\": 364656, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:57:50.915 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9801, \"accuracy\": 0.9228}, \"time_spent\": \"1:03:34\", \"epochs_done\": 7, \"batches_seen\": 11700, \"train_examples_seen\": 374256, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:59:18.858 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9793, \"accuracy\": 0.9213}, \"time_spent\": \"1:05:02\", \"epochs_done\": 7, \"batches_seen\": 12000, \"train_examples_seen\": 383856, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:00:27.242 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.979, \"accuracy\": 0.918}, \"time_spent\": \"1:06:10\", \"epochs_done\": 8, \"batches_seen\": 12208, \"train_examples_seen\": 390512, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:01:06.899 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9804, \"accuracy\": 0.9227}, \"time_spent\": \"1:06:50\", \"epochs_done\": 8, \"batches_seen\": 12300, \"train_examples_seen\": 393456, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:02:36.748 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9225}, \"time_spent\": \"1:08:20\", \"epochs_done\": 8, \"batches_seen\": 12600, \"train_examples_seen\": 403038, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:04:05.497 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9806, \"accuracy\": 0.9236}, \"time_spent\": \"1:09:49\", \"epochs_done\": 8, \"batches_seen\": 12900, \"train_examples_seen\": 412638, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:05:37.136 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9805, \"accuracy\": 0.9239}, \"time_spent\": \"1:11:20\", \"epochs_done\": 8, \"batches_seen\": 13200, \"train_examples_seen\": 422238, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:07:08.528 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9809, \"accuracy\": 0.926}, \"time_spent\": \"1:12:52\", \"epochs_done\": 8, \"batches_seen\": 13500, \"train_examples_seen\": 431838, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:08:24.749 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9245}, \"time_spent\": \"1:14:08\", \"epochs_done\": 9, \"batches_seen\": 13734, \"train_examples_seen\": 439326, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:08:58.57 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9798, \"accuracy\": 0.923}, \"time_spent\": \"1:14:41\", \"epochs_done\": 9, \"batches_seen\": 13800, \"train_examples_seen\": 441438, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:10:27.323 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9799, \"accuracy\": 0.9218}, \"time_spent\": \"1:16:10\", \"epochs_done\": 9, \"batches_seen\": 14100, \"train_examples_seen\": 451038, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:11:55.980 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9806, \"accuracy\": 0.9254}, \"time_spent\": \"1:17:39\", \"epochs_done\": 9, \"batches_seen\": 14400, \"train_examples_seen\": 460638, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:13:25.858 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9795, \"accuracy\": 0.9209}, \"time_spent\": \"1:19:09\", \"epochs_done\": 9, \"batches_seen\": 14700, \"train_examples_seen\": 470238, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:14:59.30 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9795, \"accuracy\": 0.9212}, \"time_spent\": \"1:20:42\", \"epochs_done\": 9, \"batches_seen\": 15000, \"train_examples_seen\": 479820, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:16:20.40 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9806, \"accuracy\": 0.9253}, \"time_spent\": \"1:22:03\", \"epochs_done\": 10, \"batches_seen\": 15260, \"train_examples_seen\": 488140, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:16:21.391 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/tag.dict]\n",
            "2022-05-19 22:16:35.369 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:16:37.253 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9812, \"accuracy\": 0.9259}, \"time_spent\": \"0:00:26\"}}\n",
            "{\"test\": {\"eval_examples_count\": 6491, \"metrics\": {\"per_token_accuracy\": 0.9845, \"accuracy\": 0.9364}, \"time_spent\": \"0:00:23\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:17:25.646 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/tag.dict]\n",
            "2022-05-19 22:17:42.571 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:17:44.355 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top1000 "
      ],
      "metadata": {
        "id": "AKX3MH-nN872"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_top1000'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "5xpXTL1OvrhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False)  #30imp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE3965QdFUp4",
        "outputId": "ee88a3da-d7a2-4656-96f5-db0596328872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:53:23.951 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-19 20:53:24.371 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/tag.dict]\n",
            "2022-05-19 20:53:26.575 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:53:43.275 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-19 20:54:17.965 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.0023, \"accuracy\": 0.1596}, \"time_spent\": \"0:00:35\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:55:58.114 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0023 to 0.6527\n",
            "2022-05-19 20:55:58.115 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 20:55:58.122 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.6527, \"accuracy\": 0.4631}, \"time_spent\": \"0:02:15\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 9600, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:57:37.193 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6527 to 0.8879\n",
            "2022-05-19 20:57:37.197 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 20:57:37.202 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.8879, \"accuracy\": 0.7622}, \"time_spent\": \"0:03:54\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 19200, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 20:59:13.228 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8879 to 0.9349\n",
            "2022-05-19 20:59:13.233 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 20:59:13.238 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9349, \"accuracy\": 0.8522}, \"time_spent\": \"0:05:30\", \"epochs_done\": 0, \"batches_seen\": 900, \"train_examples_seen\": 28800, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:00:49.207 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9349 to 0.9507\n",
            "2022-05-19 21:00:49.210 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:00:49.219 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9507, \"accuracy\": 0.8858}, \"time_spent\": \"0:07:06\", \"epochs_done\": 0, \"batches_seen\": 1200, \"train_examples_seen\": 38400, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:02:28.913 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9507 to 0.9565\n",
            "2022-05-19 21:02:28.915 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:02:28.922 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9565, \"accuracy\": 0.9002}, \"time_spent\": \"0:08:46\", \"epochs_done\": 0, \"batches_seen\": 1500, \"train_examples_seen\": 47982, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:02:57.438 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9565 to 0.9567\n",
            "2022-05-19 21:02:57.439 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:02:57.446 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9567, \"accuracy\": 0.8995}, \"time_spent\": \"0:09:15\", \"epochs_done\": 1, \"batches_seen\": 1526, \"train_examples_seen\": 48814, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:04:28.331 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9567 to 0.9628\n",
            "2022-05-19 21:04:28.333 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:04:28.343 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9628, \"accuracy\": 0.9127}, \"time_spent\": \"0:10:46\", \"epochs_done\": 1, \"batches_seen\": 1800, \"train_examples_seen\": 57582, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:06:03.669 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9628 to 0.9629\n",
            "2022-05-19 21:06:03.670 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:06:03.678 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9629, \"accuracy\": 0.9104}, \"time_spent\": \"0:12:21\", \"epochs_done\": 1, \"batches_seen\": 2100, \"train_examples_seen\": 67182, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:07:38.829 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9629 to 0.9657\n",
            "2022-05-19 21:07:38.830 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:07:38.838 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9657, \"accuracy\": 0.9178}, \"time_spent\": \"0:13:56\", \"epochs_done\": 1, \"batches_seen\": 2400, \"train_examples_seen\": 76764, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:09:18.75 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9657 to 0.9672\n",
            "2022-05-19 21:09:18.78 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:09:18.83 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9672, \"accuracy\": 0.921}, \"time_spent\": \"0:15:35\", \"epochs_done\": 1, \"batches_seen\": 2700, \"train_examples_seen\": 86364, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:10:55.422 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9672 to 0.9699\n",
            "2022-05-19 21:10:55.424 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:10:55.438 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9699, \"accuracy\": 0.9268}, \"time_spent\": \"0:17:13\", \"epochs_done\": 1, \"batches_seen\": 3000, \"train_examples_seen\": 95964, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:11:30.265 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9683, \"accuracy\": 0.9239}, \"time_spent\": \"0:17:47\", \"epochs_done\": 2, \"batches_seen\": 3052, \"train_examples_seen\": 97628, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:12:50.365 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9699 to 0.9719\n",
            "2022-05-19 21:12:50.370 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:12:50.375 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9719, \"accuracy\": 0.932}, \"time_spent\": \"0:19:08\", \"epochs_done\": 2, \"batches_seen\": 3300, \"train_examples_seen\": 105564, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:14:25.917 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9715, \"accuracy\": 0.9301}, \"time_spent\": \"0:20:43\", \"epochs_done\": 2, \"batches_seen\": 3600, \"train_examples_seen\": 115164, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:16:02.387 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9714, \"accuracy\": 0.9307}, \"time_spent\": \"0:22:20\", \"epochs_done\": 2, \"batches_seen\": 3900, \"train_examples_seen\": 124764, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:17:33.629 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9719, \"accuracy\": 0.9306}, \"time_spent\": \"0:23:51\", \"epochs_done\": 2, \"batches_seen\": 4200, \"train_examples_seen\": 134346, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:19:04.148 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9719 to 0.9736\n",
            "2022-05-19 21:19:04.149 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:19:04.156 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.9354}, \"time_spent\": \"0:25:21\", \"epochs_done\": 2, \"batches_seen\": 4500, \"train_examples_seen\": 143946, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:19:43.892 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.9344}, \"time_spent\": \"0:26:01\", \"epochs_done\": 3, \"batches_seen\": 4578, \"train_examples_seen\": 146442, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:20:56.561 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.9342}, \"time_spent\": \"0:27:14\", \"epochs_done\": 3, \"batches_seen\": 4800, \"train_examples_seen\": 153546, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:22:27.896 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9736 to 0.9753\n",
            "2022-05-19 21:22:27.897 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:22:27.904 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9753, \"accuracy\": 0.9396}, \"time_spent\": \"0:28:45\", \"epochs_done\": 3, \"batches_seen\": 5100, \"train_examples_seen\": 163146, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:24:04.562 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9729, \"accuracy\": 0.9341}, \"time_spent\": \"0:30:22\", \"epochs_done\": 3, \"batches_seen\": 5400, \"train_examples_seen\": 172746, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:25:35.364 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9734, \"accuracy\": 0.935}, \"time_spent\": \"0:31:53\", \"epochs_done\": 3, \"batches_seen\": 5700, \"train_examples_seen\": 182328, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:27:10.576 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9753 to 0.9764\n",
            "2022-05-19 21:27:10.577 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:27:10.585 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9764, \"accuracy\": 0.9412}, \"time_spent\": \"0:33:28\", \"epochs_done\": 3, \"batches_seen\": 6000, \"train_examples_seen\": 191928, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:27:57.602 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.9362}, \"time_spent\": \"0:34:15\", \"epochs_done\": 4, \"batches_seen\": 6104, \"train_examples_seen\": 195256, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:29:05.669 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9752, \"accuracy\": 0.9389}, \"time_spent\": \"0:35:23\", \"epochs_done\": 4, \"batches_seen\": 6300, \"train_examples_seen\": 201528, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:30:36.387 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9757, \"accuracy\": 0.9402}, \"time_spent\": \"0:36:54\", \"epochs_done\": 4, \"batches_seen\": 6600, \"train_examples_seen\": 211128, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:32:08.815 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9752, \"accuracy\": 0.94}, \"time_spent\": \"0:38:26\", \"epochs_done\": 4, \"batches_seen\": 6900, \"train_examples_seen\": 220728, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:33:39.772 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.9365}, \"time_spent\": \"0:39:57\", \"epochs_done\": 4, \"batches_seen\": 7200, \"train_examples_seen\": 230310, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:35:10.620 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9751, \"accuracy\": 0.9386}, \"time_spent\": \"0:41:28\", \"epochs_done\": 4, \"batches_seen\": 7500, \"train_examples_seen\": 239910, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:36:01.69 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9757, \"accuracy\": 0.9405}, \"time_spent\": \"0:42:18\", \"epochs_done\": 5, \"batches_seen\": 7630, \"train_examples_seen\": 244070, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:37:02.19 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9764, \"accuracy\": 0.9427}, \"time_spent\": \"0:43:19\", \"epochs_done\": 5, \"batches_seen\": 7800, \"train_examples_seen\": 249492, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:38:32.957 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9744, \"accuracy\": 0.9371}, \"time_spent\": \"0:44:50\", \"epochs_done\": 5, \"batches_seen\": 8100, \"train_examples_seen\": 259092, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:40:03.776 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9761, \"accuracy\": 0.9412}, \"time_spent\": \"0:46:21\", \"epochs_done\": 5, \"batches_seen\": 8400, \"train_examples_seen\": 268692, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:41:36.795 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9764 to 0.9768\n",
            "2022-05-19 21:41:36.796 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:41:36.807 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9768, \"accuracy\": 0.943}, \"time_spent\": \"0:47:54\", \"epochs_done\": 5, \"batches_seen\": 8700, \"train_examples_seen\": 278292, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:43:14.883 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9759, \"accuracy\": 0.9406}, \"time_spent\": \"0:49:32\", \"epochs_done\": 5, \"batches_seen\": 9000, \"train_examples_seen\": 287892, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:44:10.550 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9768 to 0.9772\n",
            "2022-05-19 21:44:10.551 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 21:44:10.559 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9772, \"accuracy\": 0.9443}, \"time_spent\": \"0:50:28\", \"epochs_done\": 6, \"batches_seen\": 9156, \"train_examples_seen\": 292884, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:45:09.413 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9757, \"accuracy\": 0.9408}, \"time_spent\": \"0:51:27\", \"epochs_done\": 6, \"batches_seen\": 9300, \"train_examples_seen\": 297474, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:46:43.445 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9748, \"accuracy\": 0.9383}, \"time_spent\": \"0:53:01\", \"epochs_done\": 6, \"batches_seen\": 9600, \"train_examples_seen\": 307074, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:48:12.959 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9759, \"accuracy\": 0.9408}, \"time_spent\": \"0:54:30\", \"epochs_done\": 6, \"batches_seen\": 9900, \"train_examples_seen\": 316674, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:49:43.830 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9744, \"accuracy\": 0.9371}, \"time_spent\": \"0:56:01\", \"epochs_done\": 6, \"batches_seen\": 10200, \"train_examples_seen\": 326274, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:51:15.758 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9771, \"accuracy\": 0.9437}, \"time_spent\": \"0:57:33\", \"epochs_done\": 6, \"batches_seen\": 10500, \"train_examples_seen\": 335874, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:52:19.101 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9766, \"accuracy\": 0.9418}, \"time_spent\": \"0:58:36\", \"epochs_done\": 7, \"batches_seen\": 10682, \"train_examples_seen\": 341698, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:53:07.956 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9771, \"accuracy\": 0.9444}, \"time_spent\": \"0:59:25\", \"epochs_done\": 7, \"batches_seen\": 10800, \"train_examples_seen\": 345474, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:54:40.556 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.977, \"accuracy\": 0.943}, \"time_spent\": \"1:00:58\", \"epochs_done\": 7, \"batches_seen\": 11100, \"train_examples_seen\": 355056, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:56:13.868 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9759, \"accuracy\": 0.9411}, \"time_spent\": \"1:02:31\", \"epochs_done\": 7, \"batches_seen\": 11400, \"train_examples_seen\": 364656, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:57:44.792 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9759, \"accuracy\": 0.9412}, \"time_spent\": \"1:04:02\", \"epochs_done\": 7, \"batches_seen\": 11700, \"train_examples_seen\": 374256, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 21:59:14.429 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9764, \"accuracy\": 0.9424}, \"time_spent\": \"1:05:32\", \"epochs_done\": 7, \"batches_seen\": 12000, \"train_examples_seen\": 383856, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:00:23.471 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9762, \"accuracy\": 0.9415}, \"time_spent\": \"1:06:41\", \"epochs_done\": 8, \"batches_seen\": 12208, \"train_examples_seen\": 390512, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:01:03.561 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9762, \"accuracy\": 0.9417}, \"time_spent\": \"1:07:21\", \"epochs_done\": 8, \"batches_seen\": 12300, \"train_examples_seen\": 393456, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:02:32.317 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9753, \"accuracy\": 0.9396}, \"time_spent\": \"1:08:50\", \"epochs_done\": 8, \"batches_seen\": 12600, \"train_examples_seen\": 403056, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:04:07.384 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.976, \"accuracy\": 0.9409}, \"time_spent\": \"1:10:25\", \"epochs_done\": 8, \"batches_seen\": 12900, \"train_examples_seen\": 412656, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:05:37.36 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9758, \"accuracy\": 0.9406}, \"time_spent\": \"1:11:54\", \"epochs_done\": 8, \"batches_seen\": 13200, \"train_examples_seen\": 422256, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:07:09.943 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9765, \"accuracy\": 0.9423}, \"time_spent\": \"1:13:27\", \"epochs_done\": 8, \"batches_seen\": 13500, \"train_examples_seen\": 431856, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:08:27.775 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.976, \"accuracy\": 0.942}, \"time_spent\": \"1:14:45\", \"epochs_done\": 9, \"batches_seen\": 13734, \"train_examples_seen\": 439326, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:09:00.655 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9761, \"accuracy\": 0.9426}, \"time_spent\": \"1:15:18\", \"epochs_done\": 9, \"batches_seen\": 13800, \"train_examples_seen\": 441438, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:10:34.771 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9767, \"accuracy\": 0.9424}, \"time_spent\": \"1:16:52\", \"epochs_done\": 9, \"batches_seen\": 14100, \"train_examples_seen\": 451038, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:12:06.522 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9753, \"accuracy\": 0.9399}, \"time_spent\": \"1:18:24\", \"epochs_done\": 9, \"batches_seen\": 14400, \"train_examples_seen\": 460638, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:13:36.526 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9763, \"accuracy\": 0.9424}, \"time_spent\": \"1:19:54\", \"epochs_done\": 9, \"batches_seen\": 14700, \"train_examples_seen\": 470220, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:15:07.797 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9751, \"accuracy\": 0.9392}, \"time_spent\": \"1:21:25\", \"epochs_done\": 9, \"batches_seen\": 15000, \"train_examples_seen\": 479820, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:16:32.66 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9769, \"accuracy\": 0.9433}, \"time_spent\": \"1:22:49\", \"epochs_done\": 10, \"batches_seen\": 15260, \"train_examples_seen\": 488140, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:16:33.376 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/tag.dict]\n",
            "2022-05-19 22:16:47.278 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:16:48.954 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9772, \"accuracy\": 0.9443}, \"time_spent\": \"0:00:26\"}}\n",
            "{\"test\": {\"eval_examples_count\": 6491, \"metrics\": {\"per_token_accuracy\": 0.9799, \"accuracy\": 0.9493}, \"time_spent\": \"0:00:22\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:17:36.819 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/tag.dict]\n",
            "2022-05-19 22:17:53.676 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:17:55.368 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top1000+"
      ],
      "metadata": {
        "id": "1-BjOUj8uYmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_other'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt', '{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['chainer']['pipe'][1]['last'] = True"
      ],
      "metadata": {
        "id": "xj0GK0hYubQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False) #30 impp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTa5OVM2dZgI",
        "outputId": "a4ce3c16-6c1b-4998-d597-d8b4e98e430f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:35:01.790 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-19 22:35:06.160 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:35:23.548 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-19 22:35:57.816 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.0021, \"accuracy\": 0.0}, \"time_spent\": \"0:00:35\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:37:35.148 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0021 to 0.8246\n",
            "2022-05-19 22:37:35.149 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:37:35.156 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.8246, \"accuracy\": 0.2622}, \"time_spent\": \"0:02:12\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 9582, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:39:15.668 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8246 to 0.9023\n",
            "2022-05-19 22:39:15.669 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:39:15.676 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9023, \"accuracy\": 0.4479}, \"time_spent\": \"0:03:53\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 19182, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:40:53.269 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9023 to 0.931\n",
            "2022-05-19 22:40:53.275 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:40:53.279 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.931, \"accuracy\": 0.5568}, \"time_spent\": \"0:05:30\", \"epochs_done\": 0, \"batches_seen\": 900, \"train_examples_seen\": 28782, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:42:32.7 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.931 to 0.9435\n",
            "2022-05-19 22:42:32.8 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:42:32.15 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9435, \"accuracy\": 0.6141}, \"time_spent\": \"0:07:09\", \"epochs_done\": 0, \"batches_seen\": 1200, \"train_examples_seen\": 38382, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:44:07.438 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9435 to 0.9518\n",
            "2022-05-19 22:44:07.439 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:44:07.448 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9518, \"accuracy\": 0.6578}, \"time_spent\": \"0:08:44\", \"epochs_done\": 0, \"batches_seen\": 1500, \"train_examples_seen\": 47982, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:44:35.69 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9505, \"accuracy\": 0.6482}, \"time_spent\": \"0:09:12\", \"epochs_done\": 1, \"batches_seen\": 1526, \"train_examples_seen\": 48814, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:46:05.598 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9518 to 0.9555\n",
            "2022-05-19 22:46:05.599 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:46:05.605 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9555, \"accuracy\": 0.6792}, \"time_spent\": \"0:10:43\", \"epochs_done\": 1, \"batches_seen\": 1800, \"train_examples_seen\": 57564, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:47:43.931 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9555 to 0.9593\n",
            "2022-05-19 22:47:43.932 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:47:43.942 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9593, \"accuracy\": 0.6997}, \"time_spent\": \"0:12:21\", \"epochs_done\": 1, \"batches_seen\": 2100, \"train_examples_seen\": 67164, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:49:20.515 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9593 to 0.9626\n",
            "2022-05-19 22:49:20.517 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:49:20.524 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9626, \"accuracy\": 0.7169}, \"time_spent\": \"0:13:57\", \"epochs_done\": 1, \"batches_seen\": 2400, \"train_examples_seen\": 76764, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:50:57.645 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9626 to 0.9636\n",
            "2022-05-19 22:50:57.649 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:50:57.654 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9636, \"accuracy\": 0.7272}, \"time_spent\": \"0:15:35\", \"epochs_done\": 1, \"batches_seen\": 2700, \"train_examples_seen\": 86364, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:52:30.900 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9636 to 0.9641\n",
            "2022-05-19 22:52:30.905 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:52:30.910 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9641, \"accuracy\": 0.726}, \"time_spent\": \"0:17:08\", \"epochs_done\": 1, \"batches_seen\": 3000, \"train_examples_seen\": 95964, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:53:06.397 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9641 to 0.9656\n",
            "2022-05-19 22:53:06.412 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:53:06.417 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9656, \"accuracy\": 0.7369}, \"time_spent\": \"0:17:43\", \"epochs_done\": 2, \"batches_seen\": 3052, \"train_examples_seen\": 97628, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:54:31.571 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9656 to 0.9664\n",
            "2022-05-19 22:54:31.572 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:54:31.579 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9664, \"accuracy\": 0.7439}, \"time_spent\": \"0:19:09\", \"epochs_done\": 2, \"batches_seen\": 3300, \"train_examples_seen\": 105564, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:56:09.590 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9664 to 0.9678\n",
            "2022-05-19 22:56:09.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:56:09.597 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9678, \"accuracy\": 0.7517}, \"time_spent\": \"0:20:47\", \"epochs_done\": 2, \"batches_seen\": 3600, \"train_examples_seen\": 115164, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:57:45.686 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9678 to 0.9681\n",
            "2022-05-19 22:57:45.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:57:45.693 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9681, \"accuracy\": 0.7556}, \"time_spent\": \"0:22:23\", \"epochs_done\": 2, \"batches_seen\": 3900, \"train_examples_seen\": 124764, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 22:59:25.641 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9681 to 0.9691\n",
            "2022-05-19 22:59:25.643 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 22:59:25.651 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9691, \"accuracy\": 0.7606}, \"time_spent\": \"0:24:03\", \"epochs_done\": 2, \"batches_seen\": 4200, \"train_examples_seen\": 134346, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:01:00.397 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9691 to 0.97\n",
            "2022-05-19 23:01:00.399 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:01:00.406 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.97, \"accuracy\": 0.7667}, \"time_spent\": \"0:25:37\", \"epochs_done\": 2, \"batches_seen\": 4500, \"train_examples_seen\": 143946, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:01:41.770 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.7658}, \"time_spent\": \"0:26:19\", \"epochs_done\": 3, \"batches_seen\": 4578, \"train_examples_seen\": 146442, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:02:55.467 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.97 to 0.9702\n",
            "2022-05-19 23:02:55.469 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:02:55.491 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9702, \"accuracy\": 0.7673}, \"time_spent\": \"0:27:32\", \"epochs_done\": 3, \"batches_seen\": 4800, \"train_examples_seen\": 153528, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:04:34.833 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9702 to 0.9706\n",
            "2022-05-19 23:04:34.834 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:04:34.841 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9706, \"accuracy\": 0.7704}, \"time_spent\": \"0:29:12\", \"epochs_done\": 3, \"batches_seen\": 5100, \"train_examples_seen\": 163128, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:06:09.932 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9706 to 0.9714\n",
            "2022-05-19 23:06:09.933 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:06:09.941 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9714, \"accuracy\": 0.7723}, \"time_spent\": \"0:30:47\", \"epochs_done\": 3, \"batches_seen\": 5400, \"train_examples_seen\": 172728, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:07:46.655 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9711, \"accuracy\": 0.7741}, \"time_spent\": \"0:32:24\", \"epochs_done\": 3, \"batches_seen\": 5700, \"train_examples_seen\": 182328, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:09:19.455 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9714 to 0.9721\n",
            "2022-05-19 23:09:19.456 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:09:19.465 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9721, \"accuracy\": 0.779}, \"time_spent\": \"0:33:56\", \"epochs_done\": 3, \"batches_seen\": 6000, \"train_examples_seen\": 191928, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:10:07.921 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9719, \"accuracy\": 0.777}, \"time_spent\": \"0:34:45\", \"epochs_done\": 4, \"batches_seen\": 6104, \"train_examples_seen\": 195256, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:11:14.125 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.972, \"accuracy\": 0.7793}, \"time_spent\": \"0:35:51\", \"epochs_done\": 4, \"batches_seen\": 6300, \"train_examples_seen\": 201510, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:12:43.782 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9721 to 0.9726\n",
            "2022-05-19 23:12:43.783 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:12:43.791 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9726, \"accuracy\": 0.7824}, \"time_spent\": \"0:37:21\", \"epochs_done\": 4, \"batches_seen\": 6600, \"train_examples_seen\": 211110, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:14:20.345 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9724, \"accuracy\": 0.784}, \"time_spent\": \"0:38:57\", \"epochs_done\": 4, \"batches_seen\": 6900, \"train_examples_seen\": 220710, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:15:53.826 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9722, \"accuracy\": 0.7814}, \"time_spent\": \"0:40:31\", \"epochs_done\": 4, \"batches_seen\": 7200, \"train_examples_seen\": 230310, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:17:28.804 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9726 to 0.9734\n",
            "2022-05-19 23:17:28.806 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:17:28.813 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9734, \"accuracy\": 0.7865}, \"time_spent\": \"0:42:06\", \"epochs_done\": 4, \"batches_seen\": 7500, \"train_examples_seen\": 239910, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:18:25.434 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9734 to 0.9737\n",
            "2022-05-19 23:18:25.439 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:18:25.444 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9737, \"accuracy\": 0.7907}, \"time_spent\": \"0:43:02\", \"epochs_done\": 5, \"batches_seen\": 7630, \"train_examples_seen\": 244070, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:19:28.938 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7909}, \"time_spent\": \"0:44:06\", \"epochs_done\": 5, \"batches_seen\": 7800, \"train_examples_seen\": 249510, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:21:02.132 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.7901}, \"time_spent\": \"0:45:39\", \"epochs_done\": 5, \"batches_seen\": 8100, \"train_examples_seen\": 259110, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:22:34.394 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9728, \"accuracy\": 0.7865}, \"time_spent\": \"0:47:11\", \"epochs_done\": 5, \"batches_seen\": 8400, \"train_examples_seen\": 268692, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:24:06.464 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9732, \"accuracy\": 0.788}, \"time_spent\": \"0:48:43\", \"epochs_done\": 5, \"batches_seen\": 8700, \"train_examples_seen\": 278292, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:25:41.588 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9732, \"accuracy\": 0.7892}, \"time_spent\": \"0:50:19\", \"epochs_done\": 5, \"batches_seen\": 9000, \"train_examples_seen\": 287892, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:26:37.799 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9735, \"accuracy\": 0.7896}, \"time_spent\": \"0:51:15\", \"epochs_done\": 6, \"batches_seen\": 9156, \"train_examples_seen\": 292884, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:27:31.184 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9737 to 0.9738\n",
            "2022-05-19 23:27:31.186 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:27:31.194 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.7943}, \"time_spent\": \"0:52:08\", \"epochs_done\": 6, \"batches_seen\": 9300, \"train_examples_seen\": 297492, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:29:07.634 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9731, \"accuracy\": 0.7869}, \"time_spent\": \"0:53:45\", \"epochs_done\": 6, \"batches_seen\": 9600, \"train_examples_seen\": 307092, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:30:41.422 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.7899}, \"time_spent\": \"0:55:18\", \"epochs_done\": 6, \"batches_seen\": 9900, \"train_examples_seen\": 316674, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:32:10.824 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9731, \"accuracy\": 0.7899}, \"time_spent\": \"0:56:48\", \"epochs_done\": 6, \"batches_seen\": 10200, \"train_examples_seen\": 326274, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:33:45.563 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9737, \"accuracy\": 0.7916}, \"time_spent\": \"0:58:23\", \"epochs_done\": 6, \"batches_seen\": 10500, \"train_examples_seen\": 335874, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:34:50.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9731, \"accuracy\": 0.7892}, \"time_spent\": \"0:59:28\", \"epochs_done\": 7, \"batches_seen\": 10682, \"train_examples_seen\": 341698, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:35:36.725 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9727, \"accuracy\": 0.7861}, \"time_spent\": \"1:00:14\", \"epochs_done\": 7, \"batches_seen\": 10800, \"train_examples_seen\": 345474, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:37:09.730 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9738 to 0.9739\n",
            "2022-05-19 23:37:09.731 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:37:09.738 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9739, \"accuracy\": 0.7936}, \"time_spent\": \"1:01:47\", \"epochs_done\": 7, \"batches_seen\": 11100, \"train_examples_seen\": 355074, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:38:50.853 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9739 to 0.9742\n",
            "2022-05-19 23:38:50.855 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:38:50.864 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9742, \"accuracy\": 0.7928}, \"time_spent\": \"1:03:28\", \"epochs_done\": 7, \"batches_seen\": 11400, \"train_examples_seen\": 364674, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:40:24.372 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.794}, \"time_spent\": \"1:05:01\", \"epochs_done\": 7, \"batches_seen\": 11700, \"train_examples_seen\": 374274, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:41:57.935 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.7943}, \"time_spent\": \"1:06:35\", \"epochs_done\": 7, \"batches_seen\": 12000, \"train_examples_seen\": 383874, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:43:08.237 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7951}, \"time_spent\": \"1:07:45\", \"epochs_done\": 8, \"batches_seen\": 12208, \"train_examples_seen\": 390512, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:43:50.335 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.794}, \"time_spent\": \"1:08:27\", \"epochs_done\": 8, \"batches_seen\": 12300, \"train_examples_seen\": 393456, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:45:23.845 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7956}, \"time_spent\": \"1:10:01\", \"epochs_done\": 8, \"batches_seen\": 12600, \"train_examples_seen\": 403056, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:46:56.985 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.974, \"accuracy\": 0.793}, \"time_spent\": \"1:11:34\", \"epochs_done\": 8, \"batches_seen\": 12900, \"train_examples_seen\": 412656, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:48:29.255 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7927}, \"time_spent\": \"1:13:06\", \"epochs_done\": 8, \"batches_seen\": 13200, \"train_examples_seen\": 422238, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:50:00.184 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9742 to 0.9744\n",
            "2022-05-19 23:50:00.186 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:50:00.194 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9744, \"accuracy\": 0.7959}, \"time_spent\": \"1:14:37\", \"epochs_done\": 8, \"batches_seen\": 13500, \"train_examples_seen\": 431838, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:51:21.192 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.794}, \"time_spent\": \"1:15:58\", \"epochs_done\": 9, \"batches_seen\": 13734, \"train_examples_seen\": 439326, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:51:56.210 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7945}, \"time_spent\": \"1:16:33\", \"epochs_done\": 9, \"batches_seen\": 13800, \"train_examples_seen\": 441438, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:53:27.94 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9742, \"accuracy\": 0.7937}, \"time_spent\": \"1:18:04\", \"epochs_done\": 9, \"batches_seen\": 14100, \"train_examples_seen\": 451038, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:54:58.699 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.7918}, \"time_spent\": \"1:19:36\", \"epochs_done\": 9, \"batches_seen\": 14400, \"train_examples_seen\": 460620, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:56:30.101 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9744 to 0.9745\n",
            "2022-05-19 23:56:30.103 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-19 23:56:30.111 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9745, \"accuracy\": 0.7962}, \"time_spent\": \"1:21:07\", \"epochs_done\": 9, \"batches_seen\": 14700, \"train_examples_seen\": 470220, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:58:09.335 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9745, \"accuracy\": 0.7968}, \"time_spent\": \"1:22:46\", \"epochs_done\": 9, \"batches_seen\": 15000, \"train_examples_seen\": 479820, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:59:34.279 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.795}, \"time_spent\": \"1:24:11\", \"epochs_done\": 10, \"batches_seen\": 15260, \"train_examples_seen\": 488140, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:59:35.807 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/tag.dict]\n",
            "2022-05-19 23:59:50.381 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 23:59:52.9 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9745, \"accuracy\": 0.7962}, \"time_spent\": \"0:00:26\"}}\n",
            "{\"test\": {\"eval_examples_count\": 6491, \"metrics\": {\"per_token_accuracy\": 0.9739, \"accuracy\": 0.7842}, \"time_spent\": \"0:00:22\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 00:00:40.132 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/tag.dict]\n",
            "2022-05-20 00:00:57.471 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/UD2.3/fs_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 00:00:59.305 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FineTuned Models"
      ],
      "metadata": {
        "id": "bhyIG3at48Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model top 100"
      ],
      "metadata": {
        "id": "xveNIwrd48ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_top100'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "0jV-yjM347qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=True) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG2b5InSLxyt",
        "outputId": "b82d8de2-b749-478c-d565-a83f587df7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:36:28.495 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
            "2022-05-20 20:36:29.760 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/BERT/morpho_ru_syntagrus_bert.tar.gz to /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/morpho_ru_syntagrus_bert.tar.gz\n",
            "100%|| 661M/661M [00:49<00:00, 13.3MB/s]\n",
            "2022-05-20 20:37:21.7 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/morpho_ru_syntagrus_bert.tar.gz archive into /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100\n",
            "2022-05-20 20:37:32.640 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:37:33.677 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/tag.dict]\n",
            "2022-05-20 20:37:36.372 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From <ipython-input-13-5405f03ac0b9>:54: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-13-5405f03ac0b9>:228: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:37:57.100 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:37:59.128 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-20 20:38:22.606 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9813, \"accuracy\": 0.9266}, \"time_spent\": \"0:00:24\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:178: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:39:52.854 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.98, \"accuracy\": 0.9218}, \"time_spent\": \"0:01:54\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 9600, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:41:26.28 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9798, \"accuracy\": 0.9216}, \"time_spent\": \"0:03:27\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 19200, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:42:59.164 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9219}, \"time_spent\": \"0:05:01\", \"epochs_done\": 0, \"batches_seen\": 900, \"train_examples_seen\": 28782, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:44:27.919 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9806, \"accuracy\": 0.925}, \"time_spent\": \"0:06:29\", \"epochs_done\": 0, \"batches_seen\": 1200, \"train_examples_seen\": 38382, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:45:58.667 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9792, \"accuracy\": 0.9189}, \"time_spent\": \"0:08:00\", \"epochs_done\": 0, \"batches_seen\": 1500, \"train_examples_seen\": 47982, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:46:22.83 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9793, \"accuracy\": 0.9195}, \"time_spent\": \"0:08:23\", \"epochs_done\": 1, \"batches_seen\": 1526, \"train_examples_seen\": 48814, \"impatience\": 6, \"patience_limit\": 30}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:211: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:47:47.769 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9807, \"accuracy\": 0.925}, \"time_spent\": \"0:09:49\", \"epochs_done\": 1, \"batches_seen\": 1800, \"train_examples_seen\": 57582, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:49:18.955 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9812, \"accuracy\": 0.9266}, \"time_spent\": \"0:11:20\", \"epochs_done\": 1, \"batches_seen\": 2100, \"train_examples_seen\": 67182, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:50:53.456 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9797, \"accuracy\": 0.9221}, \"time_spent\": \"0:12:55\", \"epochs_done\": 1, \"batches_seen\": 2400, \"train_examples_seen\": 76782, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:52:27.349 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.98, \"accuracy\": 0.9231}, \"time_spent\": \"0:14:29\", \"epochs_done\": 1, \"batches_seen\": 2700, \"train_examples_seen\": 86364, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:53:57.908 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9802, \"accuracy\": 0.9231}, \"time_spent\": \"0:15:59\", \"epochs_done\": 1, \"batches_seen\": 3000, \"train_examples_seen\": 95964, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:54:26.304 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9805, \"accuracy\": 0.9244}, \"time_spent\": \"0:16:28\", \"epochs_done\": 2, \"batches_seen\": 3052, \"train_examples_seen\": 97628, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:55:44.754 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9801, \"accuracy\": 0.9225}, \"time_spent\": \"0:17:46\", \"epochs_done\": 2, \"batches_seen\": 3300, \"train_examples_seen\": 105564, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:57:19.707 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9811, \"accuracy\": 0.9266}, \"time_spent\": \"0:19:21\", \"epochs_done\": 2, \"batches_seen\": 3600, \"train_examples_seen\": 115164, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 20:58:52.598 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9795, \"accuracy\": 0.9216}, \"time_spent\": \"0:20:54\", \"epochs_done\": 2, \"batches_seen\": 3900, \"train_examples_seen\": 124764, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:00:25.648 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9799, \"accuracy\": 0.9224}, \"time_spent\": \"0:22:27\", \"epochs_done\": 2, \"batches_seen\": 4200, \"train_examples_seen\": 134346, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:01:53.364 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9793, \"accuracy\": 0.92}, \"time_spent\": \"0:23:55\", \"epochs_done\": 2, \"batches_seen\": 4500, \"train_examples_seen\": 143946, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:02:28.402 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9805, \"accuracy\": 0.9241}, \"time_spent\": \"0:24:30\", \"epochs_done\": 3, \"batches_seen\": 4578, \"train_examples_seen\": 146442, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:03:40.996 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9805, \"accuracy\": 0.9251}, \"time_spent\": \"0:25:42\", \"epochs_done\": 3, \"batches_seen\": 4800, \"train_examples_seen\": 153546, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:05:12.472 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.98, \"accuracy\": 0.9218}, \"time_spent\": \"0:27:14\", \"epochs_done\": 3, \"batches_seen\": 5100, \"train_examples_seen\": 163146, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:06:43.364 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9813, \"accuracy\": 0.9269}, \"time_spent\": \"0:28:45\", \"epochs_done\": 3, \"batches_seen\": 5400, \"train_examples_seen\": 172746, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:08:15.374 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9804, \"accuracy\": 0.9235}, \"time_spent\": \"0:30:17\", \"epochs_done\": 3, \"batches_seen\": 5700, \"train_examples_seen\": 182346, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:09:45.861 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9809, \"accuracy\": 0.9256}, \"time_spent\": \"0:31:47\", \"epochs_done\": 3, \"batches_seen\": 6000, \"train_examples_seen\": 191928, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:10:30.898 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9807, \"accuracy\": 0.9242}, \"time_spent\": \"0:32:32\", \"epochs_done\": 4, \"batches_seen\": 6104, \"train_examples_seen\": 195256, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:11:39.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.981, \"accuracy\": 0.9259}, \"time_spent\": \"0:33:41\", \"epochs_done\": 4, \"batches_seen\": 6300, \"train_examples_seen\": 201528, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:13:12.388 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9807, \"accuracy\": 0.9248}, \"time_spent\": \"0:35:14\", \"epochs_done\": 4, \"batches_seen\": 6600, \"train_examples_seen\": 211128, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:14:44.294 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9809, \"accuracy\": 0.925}, \"time_spent\": \"0:36:46\", \"epochs_done\": 4, \"batches_seen\": 6900, \"train_examples_seen\": 220710, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:16:14.330 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9806, \"accuracy\": 0.9248}, \"time_spent\": \"0:38:16\", \"epochs_done\": 4, \"batches_seen\": 7200, \"train_examples_seen\": 230310, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:17:43.236 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9798, \"accuracy\": 0.9212}, \"time_spent\": \"0:39:45\", \"epochs_done\": 4, \"batches_seen\": 7500, \"train_examples_seen\": 239910, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:18:32.596 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9813\n",
            "2022-05-20 21:18:32.603 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:18:34.720 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9807, \"accuracy\": 0.9239}, \"time_spent\": \"0:40:34\", \"epochs_done\": 5, \"batches_seen\": 7630, \"train_examples_seen\": 244070, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:18:35.144 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-20 21:18:35.587 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/tag.dict]\n",
            "2022-05-20 21:18:49.90 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:18:50.770 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9813, \"accuracy\": 0.9266}, \"time_spent\": \"0:00:24\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:19:14.749 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/tag.dict]\n",
            "2022-05-20 21:19:29.615 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 21:19:31.377 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model top 1000"
      ],
      "metadata": {
        "id": "7r6lFDlGYBY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_top1000'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "33uK3ZEPYBY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=True) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0e66f9-e673-461b-e0bb-bb56c5872f05",
        "id": "nvTxk1ghYBY6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:29:57.773 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
            "2022-05-20 21:29:59.60 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/BERT/morpho_ru_syntagrus_bert.tar.gz to /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/morpho_ru_syntagrus_bert.tar.gz\n",
            "100%|| 661M/661M [00:57<00:00, 11.5MB/s]\n",
            "2022-05-20 21:30:57.944 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/morpho_ru_syntagrus_bert.tar.gz archive into /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000\n",
            "2022-05-20 21:31:10.297 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-20 21:31:11.299 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-20 21:31:13.639 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-20 21:31:30.658 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:31:32.533 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-20 21:31:57.58 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9783, \"accuracy\": 0.9458}, \"time_spent\": \"0:00:25\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:33:30.532 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9782, \"accuracy\": 0.947}, \"time_spent\": \"0:01:58\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 9600, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:35:04.398 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9753, \"accuracy\": 0.9403}, \"time_spent\": \"0:03:32\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 19200, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:36:42.682 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9776, \"accuracy\": 0.9458}, \"time_spent\": \"0:05:11\", \"epochs_done\": 0, \"batches_seen\": 900, \"train_examples_seen\": 28800, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:38:17.422 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9769, \"accuracy\": 0.9432}, \"time_spent\": \"0:06:45\", \"epochs_done\": 0, \"batches_seen\": 1200, \"train_examples_seen\": 38382, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:39:54.170 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.978, \"accuracy\": 0.9449}, \"time_spent\": \"0:08:22\", \"epochs_done\": 0, \"batches_seen\": 1500, \"train_examples_seen\": 47982, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:40:18.638 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9779, \"accuracy\": 0.945}, \"time_spent\": \"0:08:47\", \"epochs_done\": 1, \"batches_seen\": 1526, \"train_examples_seen\": 48814, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:41:48.194 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9776, \"accuracy\": 0.9447}, \"time_spent\": \"0:10:16\", \"epochs_done\": 1, \"batches_seen\": 1800, \"train_examples_seen\": 57582, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:43:21.379 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9767, \"accuracy\": 0.9429}, \"time_spent\": \"0:11:49\", \"epochs_done\": 1, \"batches_seen\": 2100, \"train_examples_seen\": 67182, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:44:58.159 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9745, \"accuracy\": 0.9382}, \"time_spent\": \"0:13:26\", \"epochs_done\": 1, \"batches_seen\": 2400, \"train_examples_seen\": 76782, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:46:34.849 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.977, \"accuracy\": 0.9424}, \"time_spent\": \"0:15:03\", \"epochs_done\": 1, \"batches_seen\": 2700, \"train_examples_seen\": 86382, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:48:07.84 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.937}, \"time_spent\": \"0:16:35\", \"epochs_done\": 1, \"batches_seen\": 3000, \"train_examples_seen\": 95964, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:48:37.106 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.976, \"accuracy\": 0.9406}, \"time_spent\": \"0:17:05\", \"epochs_done\": 2, \"batches_seen\": 3052, \"train_examples_seen\": 97628, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:49:58.724 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9764, \"accuracy\": 0.9418}, \"time_spent\": \"0:18:27\", \"epochs_done\": 2, \"batches_seen\": 3300, \"train_examples_seen\": 105564, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:51:32.990 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9764, \"accuracy\": 0.9417}, \"time_spent\": \"0:20:01\", \"epochs_done\": 2, \"batches_seen\": 3600, \"train_examples_seen\": 115146, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:53:04.167 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9778, \"accuracy\": 0.945}, \"time_spent\": \"0:21:32\", \"epochs_done\": 2, \"batches_seen\": 3900, \"train_examples_seen\": 124746, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:54:40.392 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9767, \"accuracy\": 0.9429}, \"time_spent\": \"0:23:08\", \"epochs_done\": 2, \"batches_seen\": 4200, \"train_examples_seen\": 134346, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:56:18.244 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9768, \"accuracy\": 0.9437}, \"time_spent\": \"0:24:46\", \"epochs_done\": 2, \"batches_seen\": 4500, \"train_examples_seen\": 143946, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:56:55.427 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9765, \"accuracy\": 0.943}, \"time_spent\": \"0:25:23\", \"epochs_done\": 3, \"batches_seen\": 4578, \"train_examples_seen\": 146442, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:58:10.544 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9768, \"accuracy\": 0.9433}, \"time_spent\": \"0:26:39\", \"epochs_done\": 3, \"batches_seen\": 4800, \"train_examples_seen\": 153546, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 21:59:41.854 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9756, \"accuracy\": 0.9397}, \"time_spent\": \"0:28:10\", \"epochs_done\": 3, \"batches_seen\": 5100, \"train_examples_seen\": 163146, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:01:17.123 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9757, \"accuracy\": 0.9406}, \"time_spent\": \"0:29:45\", \"epochs_done\": 3, \"batches_seen\": 5400, \"train_examples_seen\": 172746, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:02:54.130 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.977, \"accuracy\": 0.9441}, \"time_spent\": \"0:31:22\", \"epochs_done\": 3, \"batches_seen\": 5700, \"train_examples_seen\": 182328, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:04:29.476 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9769, \"accuracy\": 0.943}, \"time_spent\": \"0:32:57\", \"epochs_done\": 3, \"batches_seen\": 6000, \"train_examples_seen\": 191928, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:05:13.138 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.977, \"accuracy\": 0.944}, \"time_spent\": \"0:33:41\", \"epochs_done\": 4, \"batches_seen\": 6104, \"train_examples_seen\": 195256, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:06:19.851 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9764, \"accuracy\": 0.9427}, \"time_spent\": \"0:34:48\", \"epochs_done\": 4, \"batches_seen\": 6300, \"train_examples_seen\": 201528, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:07:56.25 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9774, \"accuracy\": 0.9453}, \"time_spent\": \"0:36:24\", \"epochs_done\": 4, \"batches_seen\": 6600, \"train_examples_seen\": 211110, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:09:30.768 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9766, \"accuracy\": 0.9427}, \"time_spent\": \"0:37:59\", \"epochs_done\": 4, \"batches_seen\": 6900, \"train_examples_seen\": 220710, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:11:08.185 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.977, \"accuracy\": 0.9433}, \"time_spent\": \"0:39:36\", \"epochs_done\": 4, \"batches_seen\": 7200, \"train_examples_seen\": 230310, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:12:39.976 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9774, \"accuracy\": 0.9447}, \"time_spent\": \"0:41:08\", \"epochs_done\": 4, \"batches_seen\": 7500, \"train_examples_seen\": 239910, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:13:30.725 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9783\n",
            "2022-05-20 22:13:30.733 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:13:33.42 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9758, \"accuracy\": 0.9403}, \"time_spent\": \"0:41:59\", \"epochs_done\": 5, \"batches_seen\": 7630, \"train_examples_seen\": 244070, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:13:33.531 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-20 22:13:33.987 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-20 22:13:48.668 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:13:50.425 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9783, \"accuracy\": 0.9458}, \"time_spent\": \"0:00:26\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:14:16.468 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-20 22:14:33.339 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:14:35.87 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###other"
      ],
      "metadata": {
        "id": "FuMkEbyWjCGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_other'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt', '{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['chainer']['pipe'][1]['last'] = True"
      ],
      "metadata": {
        "id": "2VCRBtOKjCMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=True) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJazt3_BjCOD",
        "outputId": "e620fa4a-c6cb-4e7a-e56a-01db67ef9ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:18:14.304 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
            "2022-05-20 22:18:15.593 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/BERT/morpho_ru_syntagrus_bert.tar.gz to /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/morpho_ru_syntagrus_bert.tar.gz\n",
            "100%|| 661M/661M [01:03<00:00, 10.4MB/s]\n",
            "2022-05-20 22:19:20.583 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/morpho_ru_syntagrus_bert.tar.gz archive into /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other\n",
            "2022-05-20 22:19:33.494 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-20 22:19:33.915 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/tag.dict]\n",
            "2022-05-20 22:19:36.810 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/tag.dict]\n",
            "2022-05-20 22:19:54.149 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:19:55.961 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-20 22:20:20.677 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9756, \"accuracy\": 0.8044}, \"time_spent\": \"0:00:25\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:21:53.171 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9732, \"accuracy\": 0.7857}, \"time_spent\": \"0:01:58\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 9600, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:23:25.41 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9729, \"accuracy\": 0.7854}, \"time_spent\": \"0:03:30\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 19200, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:24:56.846 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9735, \"accuracy\": 0.7868}, \"time_spent\": \"0:05:01\", \"epochs_done\": 0, \"batches_seen\": 900, \"train_examples_seen\": 28800, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:26:36.519 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.7874}, \"time_spent\": \"0:06:41\", \"epochs_done\": 0, \"batches_seen\": 1200, \"train_examples_seen\": 38400, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:28:10.795 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.7884}, \"time_spent\": \"0:08:15\", \"epochs_done\": 0, \"batches_seen\": 1500, \"train_examples_seen\": 47982, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:28:35.16 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.7866}, \"time_spent\": \"0:08:40\", \"epochs_done\": 1, \"batches_seen\": 1526, \"train_examples_seen\": 48814, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:30:05.352 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.973, \"accuracy\": 0.7861}, \"time_spent\": \"0:10:10\", \"epochs_done\": 1, \"batches_seen\": 1800, \"train_examples_seen\": 57582, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:31:39.82 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7896}, \"time_spent\": \"0:11:44\", \"epochs_done\": 1, \"batches_seen\": 2100, \"train_examples_seen\": 67182, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:33:10.909 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7922}, \"time_spent\": \"0:13:15\", \"epochs_done\": 1, \"batches_seen\": 2400, \"train_examples_seen\": 76764, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:34:46.417 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9737, \"accuracy\": 0.7919}, \"time_spent\": \"0:14:51\", \"epochs_done\": 1, \"batches_seen\": 2700, \"train_examples_seen\": 86364, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:36:23.375 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7909}, \"time_spent\": \"0:16:28\", \"epochs_done\": 1, \"batches_seen\": 3000, \"train_examples_seen\": 95964, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:36:54.906 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7909}, \"time_spent\": \"0:16:59\", \"epochs_done\": 2, \"batches_seen\": 3052, \"train_examples_seen\": 97628, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:38:17.405 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9731, \"accuracy\": 0.7869}, \"time_spent\": \"0:18:22\", \"epochs_done\": 2, \"batches_seen\": 3300, \"train_examples_seen\": 105564, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:39:52.36 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9733, \"accuracy\": 0.7904}, \"time_spent\": \"0:19:57\", \"epochs_done\": 2, \"batches_seen\": 3600, \"train_examples_seen\": 115164, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:41:28.81 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9736, \"accuracy\": 0.7913}, \"time_spent\": \"0:21:33\", \"epochs_done\": 2, \"batches_seen\": 3900, \"train_examples_seen\": 124764, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:43:02.596 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.7872}, \"time_spent\": \"0:23:07\", \"epochs_done\": 2, \"batches_seen\": 4200, \"train_examples_seen\": 134346, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:44:37.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.974, \"accuracy\": 0.7954}, \"time_spent\": \"0:24:42\", \"epochs_done\": 2, \"batches_seen\": 4500, \"train_examples_seen\": 143946, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:45:14.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7931}, \"time_spent\": \"0:25:19\", \"epochs_done\": 3, \"batches_seen\": 4578, \"train_examples_seen\": 146442, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:46:31.609 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.975, \"accuracy\": 0.8006}, \"time_spent\": \"0:26:36\", \"epochs_done\": 3, \"batches_seen\": 4800, \"train_examples_seen\": 153546, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 22:48:01.847 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9749, \"accuracy\": 0.8004}, \"time_spent\": \"0:28:06\", \"epochs_done\": 3, \"batches_seen\": 5100, \"train_examples_seen\": 163146, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:49:37.431 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.974, \"accuracy\": 0.7945}, \"time_spent\": \"0:29:42\", \"epochs_done\": 3, \"batches_seen\": 5400, \"train_examples_seen\": 172746, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:51:14.202 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9747, \"accuracy\": 0.7962}, \"time_spent\": \"0:31:19\", \"epochs_done\": 3, \"batches_seen\": 5700, \"train_examples_seen\": 182346, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:52:51.165 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9739, \"accuracy\": 0.7922}, \"time_spent\": \"0:32:56\", \"epochs_done\": 3, \"batches_seen\": 6000, \"train_examples_seen\": 191928, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:53:33.742 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9749, \"accuracy\": 0.7974}, \"time_spent\": \"0:33:38\", \"epochs_done\": 4, \"batches_seen\": 6104, \"train_examples_seen\": 195256, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:54:43.983 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7939}, \"time_spent\": \"0:34:49\", \"epochs_done\": 4, \"batches_seen\": 6300, \"train_examples_seen\": 201528, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:56:22.57 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9748, \"accuracy\": 0.7963}, \"time_spent\": \"0:36:27\", \"epochs_done\": 4, \"batches_seen\": 6600, \"train_examples_seen\": 211128, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:57:53.824 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9743, \"accuracy\": 0.7939}, \"time_spent\": \"0:37:58\", \"epochs_done\": 4, \"batches_seen\": 6900, \"train_examples_seen\": 220728, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 22:59:27.56 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7969}, \"time_spent\": \"0:39:32\", \"epochs_done\": 4, \"batches_seen\": 7200, \"train_examples_seen\": 230328, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:01:00.684 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9738, \"accuracy\": 0.7915}, \"time_spent\": \"0:41:05\", \"epochs_done\": 4, \"batches_seen\": 7500, \"train_examples_seen\": 239928, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:01:52.230 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9756\n",
            "2022-05-20 23:01:52.239 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:01:54.474 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.7965}, \"time_spent\": \"0:41:57\", \"epochs_done\": 5, \"batches_seen\": 7630, \"train_examples_seen\": 244070, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:01:54.947 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-20 23:01:55.409 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/tag.dict]\n",
            "2022-05-20 23:02:11.252 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:02:13.26 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 6584, \"metrics\": {\"per_token_accuracy\": 0.9756, \"accuracy\": 0.8044}, \"time_spent\": \"0:00:26\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:02:38.557 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/tag.dict]\n",
            "2022-05-20 23:02:54.590 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/models_diploma/UD2.3/finetuned_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-20 23:02:56.350 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xsoI2BNPjLQi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IUjZMZXtb89p",
        "89m2jMJMcJky",
        "YGxpVfS4ccbj",
        "Br3NWTQEcnXL",
        "bb-UPIUPczCA",
        "hcMJpEuZLzPh",
        "Qa0czko8L2Iv",
        "rrMdYc1dG7eO",
        "ylWGF63EOycm",
        "vUM0DVJd_82_",
        "0ZJHizlECewm",
        "AKX3MH-nN872",
        "1-BjOUj8uYmd",
        "xveNIwrd48ix",
        "7r6lFDlGYBY5",
        "FuMkEbyWjCGy"
      ],
      "name": "UD23.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}