{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "IUjZMZXtb89p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QmES4yFcEMAc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install deeppavlov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "034KTVnxF3XJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow-gpu==1.15.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eU8RW0YGEVwp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! python -m deeppavlov install morpho_ru_syntagrus_bert\n",
        "! pip install pyconll\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install icecream"
      ],
      "metadata": {
        "id": "Gx8hhIJUcTZ1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from icecream import ic\n",
        "import os"
      ],
      "metadata": {
        "id": "mcApbpo4chwC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qooinGiRdBr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e49c3c0-2b21-42aa-d762-ec61664ce06d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data and model"
      ],
      "metadata": {
        "id": "89m2jMJMcJky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "EGRf5xGxcaHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data and save it to data folder"
      ],
      "metadata": {
        "id": "SJCVFsWl2Gew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! wget https://raw.githubusercontent.com/dialogue-evaluation/GramEval2020/master/dataTrain/GramEval2020-Taiga-social-train.conllu\n",
        "! wget https://raw.githubusercontent.com/dialogue-evaluation/GramEval2020/master/dataTrain/MorphoRuEval2017-VK-gold.conllu\n",
        "! wget https://raw.githubusercontent.com/dialogue-evaluation/GramEval2020/master/dataOpenTest/GramEval2020-RuEval2017-social-dev.conllu"
      ],
      "metadata": {
        "id": "QSp0IJv8HKFD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/content/data/GramEval/social')\n",
        "\n",
        "os.rename(\"/content/GramEval2020-RuEval2017-social-dev.conllu\", \"/content/data/GramEval/social/ru_social-ud-dev.conllu\")\n",
        "\n",
        "train1 = open('/content/GramEval2020-Taiga-social-train.conllu','r') \n",
        "train2 = open('/content/MorphoRuEval2017-VK-gold.conllu','r')\n",
        "train_all = open('/content/data/GramEval/social/ru_social-ud-train.conllu', 'w')\n",
        "\n",
        "train_all.write(train1.read())\n",
        "train_all.write(train2.read())\n",
        "\n",
        "train1.close()\n",
        "train2.close()\n",
        "train_all.close()"
      ],
      "metadata": {
        "id": "TP8FjD91HUK0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafolder_path = '/content/data/GramEval/social' #path to datafolder\n",
        "models_path = '/content/drive/MyDrive/models_diploma/GramEval_social'\n",
        "language_conf = 'ru_social'"
      ],
      "metadata": {
        "id": "XO2cVPHKgEHx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RuBERT"
      ],
      "metadata": {
        "id": "YGxpVfS4ccbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download bert model, don't know why though"
      ],
      "metadata": {
        "id": "4CvyP2TR2T4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz"
      ],
      "metadata": {
        "id": "q9slJMLbv_nI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "file = tarfile.open('./rubert_cased_L-12_H-768_A-12_v1.tar.gz')\n",
        "  \n",
        "# extracting file\n",
        "file.extractall('./downloads/bert_models')\n",
        "  \n",
        "file.close()"
      ],
      "metadata": {
        "id": "A2mPT-j1weEV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count and split tokens by frequency"
      ],
      "metadata": {
        "id": "Br3NWTQEcnXL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY5Ou00JEc3t"
      },
      "outputs": [],
      "source": [
        "from utils import divide_by_freq\n",
        "\n",
        "top100, top1000, other = divide_by_freq(datafolder_path+'/ru_social-ud-train.conllu')\n",
        "\n",
        "os.makedirs(models_path + '/freq_groups')\n",
        "\n",
        "for i, x in enumerate([top100, top1000, other]):\n",
        "    file_path = models_path + '/freq_groups' + '/{}.txt'.format(i)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(','.join(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Components"
      ],
      "metadata": {
        "id": "bb-UPIUPczCA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcMJpEuZLzPh"
      },
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bYynb_4rKLUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a621c051-f977-4f3b-9220-058f18afe5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "from logging import getLogger\n",
        "from typing import Tuple, List, Optional, Union\n",
        "\n",
        "from deeppavlov.core.common.registry import register\n",
        "from bert_dp.preprocessing import convert_examples_to_features, InputExample, InputFeatures\n",
        "from bert_dp.tokenization import FullTokenizer\n",
        "\n",
        "from deeppavlov.core.commands.utils import expand_path\n",
        "from deeppavlov.core.data.utils import zero_pad\n",
        "from deeppavlov.core.models.component import Component\n",
        "from deeppavlov.models.preprocessors.mask import Mask\n",
        "\n",
        "\n",
        "@register('my_bert_ner_preprocessor')\n",
        "class MyBertNerPreprocessor(Component):\n",
        "    \"\"\"Takes tokens and splits them into bert subtokens, encodes subtokens with their indices.\n",
        "    Creates a mask of subtokens (one for the first subtoken, zero for the others).\n",
        "    If tags are provided, calculates tags for subtokens.\n",
        "    Args:\n",
        "        vocab_file: path to vocabulary\n",
        "        do_lower_case: set True if lowercasing is needed\n",
        "        max_seq_length: max sequence length in subtokens, including [SEP] and [CLS] tokens\n",
        "        max_subword_length: replace token to <unk> if it's length is larger than this\n",
        "            (defaults to None, which is equal to +infinity)\n",
        "        token_masking_prob: probability of masking token while training\n",
        "        provide_subword_tags: output tags for subwords or for words\n",
        "        subword_mask_mode: subword to select inside word tokens, can be \"first\" or \"last\"\n",
        "            (default=\"first\")\n",
        "    Attributes:\n",
        "        max_seq_length: max sequence length in subtokens, including [SEP] and [CLS] tokens\n",
        "        max_subword_length: rmax lenght of a bert subtoken\n",
        "        tokenizer: instance of Bert FullTokenizer\n",
        "\n",
        "    !!Added: \n",
        "        topk_tokens: path to file with tokens to consider in topk_tokens_mask in train mode\n",
        "        if list of files is passed,  condiser all the tokens apart from the ones included in the files\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_file: str,\n",
        "                 topk_tokens_path: List[str] = None, # added\n",
        "                 last: bool = False,\n",
        "                 do_lower_case: bool = False,\n",
        "                 max_seq_length: int = 512,\n",
        "                 max_subword_length: int = None,\n",
        "                 token_masking_prob: float = 0.0,\n",
        "                 provide_subword_tags: bool = False,\n",
        "                 subword_mask_mode: str = \"first\",\n",
        "                 **kwargs):\n",
        "        self._re_tokenizer = re.compile(r\"[\\w']+|[^\\w ]\")\n",
        "        self.provide_subword_tags = provide_subword_tags\n",
        "        self.mode = kwargs.get('mode')\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.max_subword_length = max_subword_length\n",
        "        self.subword_mask_mode = subword_mask_mode\n",
        "        vocab_file = str(expand_path(vocab_file))\n",
        "        self.tokenizer = FullTokenizer(vocab_file=vocab_file,\n",
        "                                       do_lower_case=do_lower_case)\n",
        "        self.token_masking_prob = token_masking_prob\n",
        "\n",
        "        self.last = None # added\n",
        "        self.topk_tokens = [] # added\n",
        "        for filename in topk_tokens_path: # added\n",
        "            with open(filename, 'r') as f: # added\n",
        "                  tokens = f.read().split(',') # added\n",
        "            self.topk_tokens.extend(tokens) # added\n",
        "        \n",
        "        \n",
        "        self.last = last\n",
        "        \n",
        "\n",
        "    def __call__(self,\n",
        "                 tokens: Union[List[List[str]], List[str]],\n",
        "                 tags: List[List[str]] = None,\n",
        "                 **kwargs):\n",
        "      \n",
        "        if isinstance(tokens[0], str):\n",
        "            tokens = [re.findall(self._re_tokenizer, s) for s in tokens]\n",
        "        subword_tokens, subword_tok_ids, startofword_markers, subword_tags, topk_tok_mask = [], [], [], [], []\n",
        "        for i in range(len(tokens)):\n",
        "            toks = tokens[i]\n",
        "            ys = ['O'] * len(toks) if tags is None else tags[i]\n",
        "            assert len(toks) == len(ys), \\\n",
        "                f\"toks({len(toks)}) should have the same length as ys({len(ys)})\"\n",
        "            sw_toks, sw_marker, sw_ys, tk_masks = \\\n",
        "                self._ner_bert_tokenize(toks,\n",
        "                                        ys,\n",
        "                                        self.topk_tokens, # added\n",
        "                                        self.tokenizer,\n",
        "                                        self.max_subword_length,\n",
        "                                        mode=self.mode,\n",
        "                                        last=self.last,\n",
        "                                        subword_mask_mode=self.subword_mask_mode,\n",
        "                                        token_masking_prob=self.token_masking_prob)\n",
        "            if self.max_seq_length is not None:\n",
        "                if len(sw_toks) > self.max_seq_length:\n",
        "                    raise RuntimeError(f\"input sequence after bert tokenization\"\n",
        "                                       f\" shouldn't exceed {self.max_seq_length} tokens.\")\n",
        "            topk_tok_mask.append(tk_masks) # added\n",
        "            subword_tokens.append(sw_toks)\n",
        "            subword_tok_ids.append(self.tokenizer.convert_tokens_to_ids(sw_toks))\n",
        "            startofword_markers.append(sw_marker)\n",
        "            subword_tags.append(sw_ys)\n",
        "            assert len(sw_marker) == len(sw_toks) == len(subword_tok_ids[-1]) == len(sw_ys), \\\n",
        "                f\"length of sow_marker({len(sw_marker)}), tokens({len(sw_toks)}),\" \\\n",
        "                f\" token ids({len(subword_tok_ids[-1])}) and ys({len(ys)})\" \\\n",
        "                f\" for tokens = `{toks}` should match\"\n",
        "\n",
        "        subword_tok_ids = zero_pad(subword_tok_ids, dtype=int, padding=0)\n",
        "        startofword_markers = zero_pad(startofword_markers, dtype=int, padding=0)\n",
        "        attention_mask = Mask()(subword_tokens)\n",
        "        topk_tok_mask = zero_pad(topk_tok_mask, dtype=int, padding=0) # added\n",
        "\n",
        "\n",
        "        if tags is not None:\n",
        "            if self.provide_subword_tags:\n",
        "                return tokens, subword_tokens, subword_tok_ids, \\\n",
        "                    attention_mask, startofword_markers, subword_tags\n",
        "            else:\n",
        "                nonmasked_tags = [[t for t in ts if t != 'X'] for ts in tags]\n",
        "                for swts, swids, swms, ts in zip(subword_tokens,\n",
        "                                                 subword_tok_ids,\n",
        "                                                 startofword_markers,\n",
        "                                                 nonmasked_tags):\n",
        "                    if (len(swids) != len(swms)) or (len(ts) != sum(swms)):\n",
        "                        log.warning('Not matching lengths of the tokenization!')\n",
        "                        log.warning(f'Tokens len: {len(swts)}\\n Tokens: {swts}')\n",
        "                        log.warning(f'Markers len: {len(swms)}, sum: {sum(swms)}')\n",
        "                        log.warning(f'Masks: {swms}')\n",
        "                        log.warning(f'Tags len: {len(ts)}\\n Tags: {ts}')\n",
        "                return tokens, subword_tokens, subword_tok_ids, \\\n",
        "                    attention_mask, startofword_markers, nonmasked_tags\n",
        "\n",
        "        return tokens, subword_tokens, subword_tok_ids, startofword_markers, attention_mask, topk_tok_mask\n",
        "\n",
        "    @staticmethod\n",
        "    def _ner_bert_tokenize(tokens: List[str],\n",
        "                           tags: List[str],\n",
        "                           topk_tokens: List[str],\n",
        "                           tokenizer: FullTokenizer,\n",
        "                           max_subword_len: int = None,\n",
        "                           mode: str = None,\n",
        "                           last: str = None,\n",
        "                           subword_mask_mode: str = \"first\",\n",
        "                           token_masking_prob: float = None) -> Tuple[List[str], List[int], List[str]]:\n",
        "        do_masking = (mode == 'train') and (token_masking_prob is not None)\n",
        "        do_cutting = (max_subword_len is not None)\n",
        "        tokens_subword = ['[CLS]']\n",
        "        topk_tokens_mask = [] # added\n",
        "        startofword_markers = [0]\n",
        "        tags_subword = ['X']\n",
        "        for token, tag in zip(tokens, tags):\n",
        "            token_marker = int(tag != 'X')\n",
        "            subwords = tokenizer.tokenize(token)\n",
        "            if not subwords or (do_cutting and (len(subwords) > max_subword_len)):\n",
        "                tokens_subword.append('[UNK]')\n",
        "                startofword_markers.append(token_marker)\n",
        "                tags_subword.append(tag)\n",
        "            else:\n",
        "                if do_masking and (random.random() < token_masking_prob):\n",
        "                    tokens_subword.extend(['[MASK]'] * len(subwords))\n",
        "                else:\n",
        "                    tokens_subword.extend(subwords)\n",
        "\n",
        "                if subword_mask_mode == \"last\":\n",
        "                    startofword_markers.extend([0] * (len(subwords) - 1) + [token_marker])\n",
        "                else: #subword_mask_mode=first\n",
        "                    startofword_markers.extend([token_marker] + [0] * (len(subwords) - 1))\n",
        "\n",
        "                if token.lower() in topk_tokens:  # added\n",
        "                    if last == True:  # added\n",
        "                        topk_tokens_mask.extend([0]) # added\n",
        "                    else:\n",
        "                        topk_tokens_mask.extend([1]) # added\n",
        "                else:\n",
        "                    if last == True:   # added\n",
        "                        topk_tokens_mask.extend([1]) # added\n",
        "                    else:\n",
        "                        topk_tokens_mask.extend([0]) # added\n",
        "\n",
        "\n",
        "                tags_subword.extend([tag] + ['X'] * (len(subwords) - 1))\n",
        "                \n",
        "        tokens_subword.append('[SEP]')\n",
        "        # topk_tokens_mask.append(0)\n",
        "        startofword_markers.append(0)\n",
        "        tags_subword.append('X')\n",
        "        return tokens_subword, startofword_markers, tags_subword, topk_tokens_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0czko8L2Iv"
      },
      "source": [
        "## Tagger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uV-LZV1HTH_",
        "outputId": "b52b50e3-7d6f-44b7-fe08-6e53e5a14e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from logging import getLogger\n",
        "from typing import List, Union, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from bert_dp.modeling import BertConfig, BertModel\n",
        "from bert_dp.optimization import AdamWeightDecayOptimizer\n",
        "\n",
        "from deeppavlov.core.commands.utils import expand_path\n",
        "from deeppavlov.core.common.registry import register\n",
        "from deeppavlov.core.layers.tf_layers import bi_rnn\n",
        "from deeppavlov.core.models.tf_model import LRScheduledTFModel\n",
        "\n",
        "log = getLogger(__name__)\n",
        "\n",
        "\n",
        "def token_from_subtoken(units: tf.Tensor, mask: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\" Assemble token level units from subtoken level units\n",
        "    Args:\n",
        "        units: tf.Tensor of shape [batch_size, SUBTOKEN_seq_length, n_features]\n",
        "        mask: mask of token beginnings. For example: for tokens\n",
        "                [[``[CLS]`` ``My``, ``capybara``, ``[SEP]``],\n",
        "                [``[CLS]`` ``Your``, ``aar``, ``##dvark``, ``is``, ``awesome``, ``[SEP]``]]\n",
        "            the mask will be\n",
        "                [[0, 1, 1, 0, 0, 0, 0],\n",
        "                [0, 1, 1, 0, 1, 1, 0]]\n",
        "    Returns:\n",
        "        word_level_units: Units assembled from ones in the mask. For the\n",
        "            example above this units will correspond to the following\n",
        "                [[``My``, ``capybara``],\n",
        "                [``Your`, ``aar``, ``is``, ``awesome``,]]\n",
        "            the shape of this tensor will be [batch_size, TOKEN_seq_length, n_features]\n",
        "    \"\"\"\n",
        "    shape = tf.cast(tf.shape(units), tf.int64)\n",
        "    batch_size = shape[0]\n",
        "    nf = shape[2]\n",
        "    nf_int = units.get_shape().as_list()[-1]\n",
        "\n",
        "    # number of TOKENS in each sentence\n",
        "    token_seq_lengths = tf.cast(tf.reduce_sum(mask, 1), tf.int64)\n",
        "    # for a matrix m =\n",
        "    # [[1, 1, 1],\n",
        "    #  [0, 1, 1],\n",
        "    #  [1, 0, 0]]\n",
        "    # it will be\n",
        "    # [3, 2, 1]\n",
        "\n",
        "    n_words = tf.reduce_sum(token_seq_lengths)\n",
        "    # n_words -> 6\n",
        "\n",
        "    max_token_seq_len = tf.cast(tf.reduce_max(token_seq_lengths), tf.int64)\n",
        "    # max_token_seq_len -> 3\n",
        "\n",
        "    idxs = tf.where(mask)\n",
        "    # for the matrix mentioned above\n",
        "    # tf.where(mask) ->\n",
        "    # [[0, 0],\n",
        "    #  [0, 1]\n",
        "    #  [0, 2],\n",
        "    #  [1, 1],\n",
        "    #  [1, 2]\n",
        "    #  [2, 0]]\n",
        "\n",
        "    sample_ids_in_batch = tf.pad(idxs[:, 0], [[1, 0]])\n",
        "    # for indices\n",
        "    # [[0, 0],\n",
        "    #  [0, 1]\n",
        "    #  [0, 2],\n",
        "    #  [1, 1],\n",
        "    #  [1, 2],\n",
        "    #  [2, 0]]\n",
        "    # it is\n",
        "    # [0, 0, 0, 0, 1, 1, 2]\n",
        "    # padding is for computing change from one sample to another in the batch\n",
        "\n",
        "    a = tf.cast(tf.not_equal(sample_ids_in_batch[1:], sample_ids_in_batch[:-1]), tf.int64)\n",
        "    # for the example above the result of this statement equals\n",
        "    # [0, 0, 0, 1, 0, 1]\n",
        "    # so data samples begin in 3rd and 5th positions (the indexes of ones)\n",
        "\n",
        "    # transforming sample start masks to the sample starts themselves\n",
        "    q = a * tf.cast(tf.range(n_words), tf.int64)\n",
        "    # [0, 0, 0, 3, 0, 5]\n",
        "    count_to_substract = tf.pad(tf.boolean_mask(q, q), [(1, 0)])\n",
        "    # [0, 3, 5]\n",
        "\n",
        "    new_word_indices = tf.cast(tf.range(n_words), tf.int64) - tf.gather(count_to_substract, tf.cumsum(a))\n",
        "    # tf.range(n_words) -> [0, 1, 2, 3, 4, 5]\n",
        "    # tf.cumsum(a) -> [0, 0, 0, 1, 1, 2]\n",
        "    # tf.gather(count_to_substract, tf.cumsum(a)) -> [0, 0, 0, 3, 3, 5]\n",
        "    # new_word_indices -> [0, 1, 2, 3, 4, 5] - [0, 0, 0, 3, 3, 5] = [0, 1, 2, 0, 1, 0]\n",
        "    # new_word_indices is the concatenation of range(word_len(sentence))\n",
        "    # for all sentences in units\n",
        "\n",
        "    n_total_word_elements = tf.cast(batch_size * max_token_seq_len, tf.int32)\n",
        "    word_indices_flat = tf.cast(idxs[:, 0] * max_token_seq_len + new_word_indices, tf.int32)\n",
        "    x_mask = tf.reduce_sum(tf.one_hot(word_indices_flat, n_total_word_elements), 0)\n",
        "    x_mask = tf.cast(x_mask, tf.bool)\n",
        "    # to get absolute indices we add max_token_seq_len:\n",
        "    # idxs[:, 0] * max_token_seq_len -> [0, 0, 0, 1, 1, 2] * 2 = [0, 0, 0, 3, 3, 6]\n",
        "    # word_indices_flat -> [0, 0, 0, 3, 3, 6] + [0, 1, 2, 0, 1, 0] = [0, 1, 2, 3, 4, 6]\n",
        "    # total number of words in the batch (including paddings)\n",
        "    # batch_size * max_token_seq_len -> 3 * 3 = 9\n",
        "    # tf.one_hot(...) ->\n",
        "    # [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
        "    #  [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
        "    #  x_mask -> [1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
        "\n",
        "    full_range = tf.cast(tf.range(batch_size * max_token_seq_len), tf.int32)\n",
        "    # full_range -> [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "    nonword_indices_flat = tf.boolean_mask(full_range, tf.math.logical_not(x_mask))\n",
        "    # # y_idxs -> [5, 7, 8]\n",
        "\n",
        "    # get a sequence of units corresponding to the start subtokens of the words\n",
        "    # size: [n_words, n_features]\n",
        "    elements = tf.gather_nd(units, idxs)\n",
        "\n",
        "    # prepare zeros for paddings\n",
        "    # size: [batch_size * TOKEN_seq_length - n_words, n_features]\n",
        "    paddings = tf.zeros(tf.stack([tf.reduce_sum(max_token_seq_len - token_seq_lengths),\n",
        "                                  nf], 0), tf.float32)\n",
        "\n",
        "    tensor_flat = tf.dynamic_stitch([word_indices_flat, nonword_indices_flat],\n",
        "                                    [elements, paddings])\n",
        "    # tensor_flat -> [x, x, x, x, x, 0, x, 0, 0]\n",
        "\n",
        "    tensor = tf.reshape(tensor_flat, tf.stack([batch_size, max_token_seq_len, nf_int], 0))\n",
        "    # tensor -> [[x, x, x],\n",
        "    #            [x, x, 0],\n",
        "    #            [x, 0, 0]]\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "@register('my_bert_sequence_network')\n",
        "class MyBertSequenceNetwork(LRScheduledTFModel):\n",
        "    \"\"\"\n",
        "    Basic class for BERT-based sequential architectures.\n",
        "    Args:\n",
        "\n",
        "        keep_prob: dropout keep_prob for non-Bert layers\n",
        "        bert_config_file: path to Bert configuration file\n",
        "        pretrained_bert: pretrained Bert checkpoint\n",
        "        attention_probs_keep_prob: keep_prob for Bert self-attention layers\n",
        "        hidden_keep_prob: keep_prob for Bert hidden layers\n",
        "        encoder_layer_ids: list of averaged layers from Bert encoder (layer ids)\n",
        "            optimizer: name of tf.train.* optimizer or None for `AdamWeightDecayOptimizer`\n",
        "            weight_decay_rate: L2 weight decay for `AdamWeightDecayOptimizer`\n",
        "        encoder_dropout: dropout probability of encoder output layer\n",
        "        ema_decay: what exponential moving averaging to use for network parameters, value from 0.0 to 1.0.\n",
        "            Values closer to 1.0 put weight on the parameters history and values closer to 0.0 corresponds put weight\n",
        "            on the current parameters.\n",
        "        ema_variables_on_cpu: whether to put EMA variables to CPU. It may save a lot of GPU memory\n",
        "        freeze_embeddings: set True to not train input embeddings set True to\n",
        "            not train input embeddings set True to not train input embeddings\n",
        "        learning_rate: learning rate of BERT head\n",
        "        bert_learning_rate: learning rate of BERT body\n",
        "        min_learning_rate: min value of learning rate if learning rate decay is used\n",
        "        learning_rate_drop_patience: how many validations with no improvements to wait\n",
        "        learning_rate_drop_div: the divider of the learning rate after `learning_rate_drop_patience` unsuccessful\n",
        "            validations\n",
        "        load_before_drop: whether to load best model before dropping learning rate or not\n",
        "        clip_norm: clip gradients by norm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 keep_prob: float,\n",
        "                 bert_config_file: str,\n",
        "                 pretrained_bert: str = None,\n",
        "                 attention_probs_keep_prob: float = None,\n",
        "                 hidden_keep_prob: float = None,\n",
        "                 encoder_layer_ids: List[int] = (-1,),\n",
        "                 encoder_dropout: float = 0.0,\n",
        "                 optimizer: str = None,\n",
        "                 weight_decay_rate: float = 1e-6,\n",
        "                 ema_decay: float = None,\n",
        "                 ema_variables_on_cpu: bool = True,\n",
        "                 freeze_embeddings: bool = False,\n",
        "                 learning_rate: float = 1e-3,\n",
        "                 bert_learning_rate: float = 2e-5,\n",
        "                 min_learning_rate: float = 1e-07,\n",
        "                 learning_rate_drop_patience: int = 20,\n",
        "                 learning_rate_drop_div: float = 2.0,\n",
        "                 load_before_drop: bool = True,\n",
        "                 clip_norm: float = 1.0,\n",
        "                 **kwargs) -> None:\n",
        "        super().__init__(learning_rate=learning_rate,\n",
        "                         learning_rate_drop_div=learning_rate_drop_div,\n",
        "                         learning_rate_drop_patience=learning_rate_drop_patience,\n",
        "                         load_before_drop=load_before_drop,\n",
        "                         clip_norm=clip_norm,\n",
        "                         **kwargs)\n",
        "        self.keep_prob = keep_prob\n",
        "        self.encoder_layer_ids = encoder_layer_ids\n",
        "        self.encoder_dropout = encoder_dropout\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay_rate = weight_decay_rate\n",
        "        self.ema_decay = ema_decay\n",
        "        self.ema_variables_on_cpu = ema_variables_on_cpu\n",
        "        self.freeze_embeddings = freeze_embeddings\n",
        "        self.bert_learning_rate_multiplier = bert_learning_rate / learning_rate\n",
        "        self.min_learning_rate = min_learning_rate\n",
        "\n",
        "        self.bert_config = BertConfig.from_json_file(str(expand_path(bert_config_file)))\n",
        "\n",
        "        if attention_probs_keep_prob is not None:\n",
        "            self.bert_config.attention_probs_dropout_prob = 1.0 - attention_probs_keep_prob\n",
        "        if hidden_keep_prob is not None:\n",
        "            self.bert_config.hidden_dropout_prob = 1.0 - hidden_keep_prob\n",
        "\n",
        "        self.sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
        "        self.sess_config.gpu_options.allow_growth = True\n",
        "        self.sess = tf.Session(config=self.sess_config)\n",
        "\n",
        "        self._init_graph()\n",
        "\n",
        "        self._init_optimizer()\n",
        "\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        if pretrained_bert is not None:\n",
        "            pretrained_bert = str(expand_path(pretrained_bert))\n",
        "\n",
        "            if tf.train.checkpoint_exists(pretrained_bert) \\\n",
        "                    and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):\n",
        "                log.info('[initializing model with Bert from {}]'.format(pretrained_bert))\n",
        "                # Exclude optimizer and classification variables from saved variables\n",
        "                var_list = self._get_saveable_variables(\n",
        "                    exclude_scopes=('Optimizer', 'learning_rate', 'momentum', 'ner', 'EMA'))\n",
        "                saver = tf.train.Saver(var_list)\n",
        "                saver.restore(self.sess, pretrained_bert)\n",
        "\n",
        "        if self.load_path is not None:\n",
        "            self.load()\n",
        "\n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.init_op)\n",
        "\n",
        "    def _init_graph(self) -> None:\n",
        "        self.seq_lengths = tf.reduce_sum(self.y_masks_ph, axis=1)\n",
        "\n",
        "        self.bert = BertModel(config=self.bert_config,\n",
        "                              is_training=self.is_train_ph,\n",
        "                              input_ids=self.input_ids_ph,\n",
        "                              input_mask=self.input_masks_ph,\n",
        "                              token_type_ids=self.token_types_ph,\n",
        "                              use_one_hot_embeddings=False)\n",
        "        with tf.variable_scope('ner'):\n",
        "            layer_weights = tf.get_variable('layer_weights_',\n",
        "                                            shape=len(self.encoder_layer_ids),\n",
        "                                            initializer=tf.ones_initializer(),\n",
        "                                            trainable=True)\n",
        "            layer_mask = tf.ones_like(layer_weights)\n",
        "            layer_mask = tf.nn.dropout(layer_mask, self.encoder_keep_prob_ph)\n",
        "            layer_weights *= layer_mask\n",
        "            # to prevent zero division\n",
        "            mask_sum = tf.maximum(tf.reduce_sum(layer_mask), 1.0)\n",
        "            layer_weights = tf.unstack(layer_weights / mask_sum)\n",
        "            # TODO: may be stack and reduce_sum is faster\n",
        "            units = sum(w * l for w, l in zip(layer_weights, self.encoder_layers()))\n",
        "            units = tf.nn.dropout(units, keep_prob=self.keep_prob_ph)\n",
        "            # print('init graph var scope ner')\n",
        "        return units\n",
        "\n",
        "    def _get_tag_mask(self) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Returns: tag_mask,\n",
        "            a mask that selects positions corresponding to word tokens (not padding and `CLS`)\n",
        "        \"\"\"\n",
        "        max_length = tf.reduce_max(self.seq_lengths)\n",
        "        one_hot_max_len = tf.one_hot(self.seq_lengths - 1, max_length)\n",
        "        tag_mask = tf.cumsum(one_hot_max_len[:, ::-1], axis=1)[:, ::-1]\n",
        "\n",
        "        return tag_mask\n",
        "\n",
        "    def encoder_layers(self):\n",
        "        \"\"\"\n",
        "        Returns: the output of BERT layers specfied in ``self.encoder_layers_ids``\n",
        "        \"\"\"\n",
        "        return [self.bert.all_encoder_layers[i] for i in self.encoder_layer_ids]\n",
        "\n",
        "    def _init_placeholders(self) -> None:\n",
        "        self.input_ids_ph = tf.placeholder(shape=(None, None),\n",
        "                                           dtype=tf.int32,\n",
        "                                           name='token_indices_ph')\n",
        "        self.input_masks_ph = tf.placeholder(shape=(None, None),\n",
        "                                             dtype=tf.int32,\n",
        "                                             name='token_mask_ph')\n",
        "        self.token_types_ph = \\\n",
        "            tf.placeholder_with_default(tf.zeros_like(self.input_ids_ph, dtype=tf.int32),\n",
        "                                        shape=self.input_ids_ph.shape,\n",
        "                                        name='token_types_ph')\n",
        "        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name='learning_rate_ph')\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='keep_prob_ph')\n",
        "        self.encoder_keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='encoder_keep_prob_ph')\n",
        "        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name='is_train_ph')\n",
        "\n",
        "    def _init_optimizer(self) -> None:\n",
        "        with tf.variable_scope('Optimizer'):\n",
        "            self.global_step = tf.get_variable('global_step',\n",
        "                                               shape=[],\n",
        "                                               dtype=tf.int32,\n",
        "                                               initializer=tf.constant_initializer(0),\n",
        "                                               trainable=False)\n",
        "            # default optimizer for Bert is Adam with fixed L2 regularization\n",
        "\n",
        "        if self.optimizer is None:\n",
        "            self.train_op = \\\n",
        "                self.get_train_op(self.loss,\n",
        "                                  learning_rate=self.learning_rate_ph,\n",
        "                                  optimizer=AdamWeightDecayOptimizer,\n",
        "                                  weight_decay_rate=self.weight_decay_rate,\n",
        "                                  beta_1=0.9,\n",
        "                                  beta_2=0.999,\n",
        "                                  epsilon=1e-6,\n",
        "                                  optimizer_scope_name='Optimizer',\n",
        "                                  exclude_from_weight_decay=[\"LayerNorm\",\n",
        "                                                             \"layer_norm\",\n",
        "                                                             \"bias\",\n",
        "                                                             \"EMA\"])\n",
        "        else:\n",
        "            self.train_op = self.get_train_op(self.loss,\n",
        "                                              learning_rate=self.learning_rate_ph,\n",
        "                                              optimizer_scope_name='Optimizer')\n",
        "\n",
        "        if self.optimizer is None:\n",
        "            with tf.variable_scope('Optimizer'):\n",
        "                new_global_step = self.global_step + 1\n",
        "                self.train_op = tf.group(self.train_op, [self.global_step.assign(new_global_step)])\n",
        "\n",
        "        if self.ema_decay is not None:\n",
        "            _vars = self._get_trainable_variables(exclude_scopes=[\"Optimizer\",\n",
        "                                                                  \"LayerNorm\",\n",
        "                                                                  \"layer_norm\",\n",
        "                                                                  \"bias\",\n",
        "                                                                  \"learning_rate\",\n",
        "                                                                  \"momentum\"])\n",
        "\n",
        "            self.ema = ExponentialMovingAverage(self.ema_decay,\n",
        "                                                variables_on_cpu=self.ema_variables_on_cpu)\n",
        "            self.train_op = self.ema.build(self.train_op, _vars, name=\"EMA\")\n",
        "        else:\n",
        "            self.ema = None\n",
        "\n",
        "    def get_train_op(self, loss: tf.Tensor, learning_rate: Union[tf.Tensor, float], **kwargs) -> tf.Operation:\n",
        "        assert \"learnable_scopes\" not in kwargs, \"learnable scopes unsupported\"\n",
        "        # train_op for bert variables\n",
        "        kwargs['learnable_scopes'] = ('bert/encoder', 'bert/embeddings')\n",
        "        if self.freeze_embeddings:\n",
        "            kwargs['learnable_scopes'] = ('bert/encoder',)\n",
        "        bert_learning_rate = learning_rate * self.bert_learning_rate_multiplier\n",
        "        bert_train_op = super().get_train_op(loss,\n",
        "                                             bert_learning_rate,\n",
        "                                             **kwargs)\n",
        "        # train_op for ner head variables\n",
        "        kwargs['learnable_scopes'] = ('ner',)\n",
        "        # print('1 get train op')\n",
        "        head_train_op = super().get_train_op(loss,\n",
        "                                             learning_rate,\n",
        "                                             **kwargs)\n",
        "        return tf.group(bert_train_op, head_train_op)\n",
        "\n",
        "    def _build_basic_feed_dict(self, input_ids: tf.Tensor, input_masks: tf.Tensor,\n",
        "                               token_types: Optional[tf.Tensor]=None, train: bool=False) -> dict:\n",
        "        \"\"\"Fills the feed_dict with the tensors defined in the basic class.\n",
        "        You need to update this dict by the values of output placeholders\n",
        "        and class-specific network inputs in your derived class.\n",
        "        \"\"\"\n",
        "        # print('1 _build_basic_feed_dict')\n",
        "        feed_dict = {\n",
        "            self.input_ids_ph: input_ids,\n",
        "            self.input_masks_ph: input_masks,\n",
        "        }\n",
        "        if token_types is not None:\n",
        "            feed_dict[self.token_types_ph] = token_types\n",
        "        if train:\n",
        "            # print('1 _build_basic_feed_dict train')\n",
        "            feed_dict.update({\n",
        "                self.learning_rate_ph: max(self.get_learning_rate(), self.min_learning_rate),\n",
        "                self.keep_prob_ph: self.keep_prob,\n",
        "                self.encoder_keep_prob_ph: 1.0 - self.encoder_dropout,\n",
        "                self.is_train_ph: True,\n",
        "            })\n",
        "\n",
        "        return feed_dict\n",
        "\n",
        "    def _build_feed_dict(self, input_ids, input_masks, token_types=None, *args,  **kwargs):\n",
        "        raise NotImplementedError(\"You must implement _build_feed_dict in your derived class.\")\n",
        "\n",
        "    def train_on_batch(self,\n",
        "                       input_ids: Union[List[List[int]], np.ndarray],\n",
        "                       input_masks: Union[List[List[int]], np.ndarray],\n",
        "                      #  topk_tok_mask: Union[List[List[int]], np.ndarray]\n",
        "                       *args, **kwargs) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: batch of indices of subwords\n",
        "            input_masks: batch of masks which determine what should be attended\n",
        "            args: arguments passed  to _build_feed_dict\n",
        "                and corresponding to additional input\n",
        "                and output tensors of the derived class.\n",
        "            kwargs: keyword arguments passed to _build_feed_dict\n",
        "                and corresponding to additional input\n",
        "                and output tensors of the derived class.\n",
        "\n",
        "        Returns:\n",
        "            dict with fields 'loss', 'head_learning_rate', and 'bert_learning_rate'\n",
        "        \"\"\"\n",
        "        # print('1 tr_on_batch1')\n",
        "        feed_dict = self._build_feed_dict(input_ids, input_masks, *args, **kwargs)\n",
        "        # print('1 feed_dict_tr_batch')\n",
        "        # print('1 tr_on_batch2')\n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.switch_to_train_op)\n",
        "        # print('1 sess with loss')\n",
        "        # print(self.topk_tok_mask)\n",
        "        _, loss, lr = self.sess.run([self.train_op, self.loss, self.learning_rate_ph],\n",
        "                                     feed_dict=feed_dict)\n",
        "\n",
        "        return {'loss': loss,\n",
        "                'head_learning_rate': float(lr),\n",
        "                'bert_learning_rate': float(lr) * self.bert_learning_rate_multiplier}\n",
        "\n",
        "    def __call__(self,\n",
        "                 input_ids: Union[List[List[int]], np.ndarray],\n",
        "                 input_masks: Union[List[List[int]], np.ndarray],\n",
        "                 **kwargs) -> Union[List[List[int]], List[np.ndarray]]:\n",
        "        raise NotImplementedError(\"You must implement method __call__ in your derived class.\")\n",
        "\n",
        "    def save(self, exclude_scopes=('Optimizer', 'EMA/BackupVariables')) -> None:\n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.switch_to_train_op)\n",
        "        return super().save(exclude_scopes=exclude_scopes)\n",
        "\n",
        "    def load(self,\n",
        "             exclude_scopes=('Optimizer',\n",
        "                             'learning_rate',\n",
        "                             'momentum',\n",
        "                             'EMA/BackupVariables'),\n",
        "             **kwargs) -> None:\n",
        "        return super().load(exclude_scopes=exclude_scopes, **kwargs)\n",
        "\n",
        "\n",
        "@register('my_bert_sequence_tagger')\n",
        "class MyBertSequenceTagger(MyBertSequenceNetwork):\n",
        "    \"\"\"BERT-based model for text tagging. It predicts a label for every token (not subtoken) in the text.\n",
        "    You can use it for sequence labeling tasks, such as morphological tagging or named entity recognition.\n",
        "    See :class:`deeppavlov.models.bert.bert_sequence_tagger.BertSequenceNetwork`\n",
        "    for the description of inherited parameters.\n",
        "    Args:\n",
        "        n_tags: number of distinct tags\n",
        "        use_crf: whether to use CRF on top or not\n",
        "        use_birnn: whether to use bidirection rnn after BERT layers.\n",
        "            For NER and morphological tagging we usually set it to `False` as otherwise the model overfits\n",
        "        birnn_cell_type: the type of Bidirectional RNN. Either `lstm` or `gru`\n",
        "        birnn_hidden_size: number of hidden units in the BiRNN layer in each direction\n",
        "        return_probas: set this to `True` if you need the probabilities instead of raw answers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_tags: List[str],\n",
        "                 keep_prob: float,\n",
        "                 bert_config_file: str,\n",
        "                 pretrained_bert: str = None,\n",
        "                 attention_probs_keep_prob: float = None,\n",
        "                 hidden_keep_prob: float = None,\n",
        "                 use_crf=False,\n",
        "                 encoder_layer_ids: List[int] = (-1,),\n",
        "                 encoder_dropout: float = 0.0,\n",
        "                 optimizer: str = None,\n",
        "                 weight_decay_rate: float = 1e-6,\n",
        "                 use_birnn: bool = False,\n",
        "                 birnn_cell_type: str = 'lstm',\n",
        "                 birnn_hidden_size: int = 128,\n",
        "                 ema_decay: float = None,\n",
        "                 ema_variables_on_cpu: bool = True,\n",
        "                 return_probas: bool = False,\n",
        "                 freeze_embeddings: bool = False,\n",
        "                 learning_rate: float = 1e-3,\n",
        "                 bert_learning_rate: float = 2e-5,\n",
        "                 min_learning_rate: float = 1e-07,\n",
        "                 learning_rate_drop_patience: int = 20,\n",
        "                 learning_rate_drop_div: float = 2.0,\n",
        "                 load_before_drop: bool = True,\n",
        "                 clip_norm: float = 1.0,\n",
        "                 **kwargs) -> None:\n",
        "        self.n_tags = n_tags\n",
        "        self.use_crf = use_crf\n",
        "        self.use_birnn = use_birnn\n",
        "        self.birnn_cell_type = birnn_cell_type\n",
        "        self.birnn_hidden_size = birnn_hidden_size\n",
        "        self.return_probas = return_probas\n",
        "        super().__init__(keep_prob=keep_prob,\n",
        "                         bert_config_file=bert_config_file,\n",
        "                         pretrained_bert=pretrained_bert,\n",
        "                         attention_probs_keep_prob=attention_probs_keep_prob,\n",
        "                         hidden_keep_prob=hidden_keep_prob,\n",
        "                         encoder_layer_ids=encoder_layer_ids,\n",
        "                         encoder_dropout=encoder_dropout,\n",
        "                         optimizer=optimizer,\n",
        "                         weight_decay_rate=weight_decay_rate,\n",
        "                         ema_decay=ema_decay,\n",
        "                         ema_variables_on_cpu=ema_variables_on_cpu,\n",
        "                         freeze_embeddings=freeze_embeddings,\n",
        "                         learning_rate=learning_rate,\n",
        "                         bert_learning_rate=bert_learning_rate,\n",
        "                         min_learning_rate=min_learning_rate,\n",
        "                         learning_rate_drop_div=learning_rate_drop_div,\n",
        "                         learning_rate_drop_patience=learning_rate_drop_patience,\n",
        "                         load_before_drop=load_before_drop,\n",
        "                         clip_norm=clip_norm,\n",
        "                         **kwargs)\n",
        "\n",
        "    def _init_graph(self) -> None:\n",
        "        self._init_placeholders()\n",
        "\n",
        "        units = super()._init_graph()\n",
        "\n",
        "        with tf.variable_scope('ner'):\n",
        "            if self.use_birnn:\n",
        "                units, _ = bi_rnn(units,\n",
        "                                  self.birnn_hidden_size,\n",
        "                                  cell_type=self.birnn_cell_type,\n",
        "                                  seq_lengths=self.seq_lengths,\n",
        "                                  name='birnn')\n",
        "                units = tf.concat(units, -1)\n",
        "            # TODO: maybe add one more layer?\n",
        "            logits = tf.layers.dense(units, units=self.n_tags, name=\"output_dense\")\n",
        "            self.logits = token_from_subtoken(logits, self.y_masks_ph) #token_ids of startwords?\n",
        "\n",
        "            # CRF\n",
        "            if self.use_crf:\n",
        "                transition_params = tf.get_variable('Transition_Params',\n",
        "                                                    shape=[self.n_tags, self.n_tags],\n",
        "                                                    initializer=tf.zeros_initializer())\n",
        "                log_likelihood, transition_params = \\\n",
        "                    tf.contrib.crf.crf_log_likelihood(self.logits,\n",
        "                                                      self.y_ph,\n",
        "                                                      self.seq_lengths,\n",
        "                                                      transition_params)\n",
        "                loss_tensor = -log_likelihood\n",
        "                self._transition_params = transition_params\n",
        "\n",
        "            self.y_predictions = tf.argmax(self.logits, -1)\n",
        "            self.y_probas = tf.nn.softmax(self.logits, axis=2)\n",
        "\n",
        "        with tf.variable_scope(\"loss\"):\n",
        "            tag_mask = self._get_tag_mask()\n",
        "            y_mask = tf.cast(tag_mask, tf.float32)\n",
        "            if self.use_crf:\n",
        "                self.loss = tf.reduce_mean(loss_tensor)\n",
        "            else:                \n",
        "                self.loss = tf.losses.sparse_softmax_cross_entropy(labels=self.y_ph,\n",
        "                                                                   logits=self.logits,\n",
        "                                                                   weights=self.topk_masks_ph)  #instead of y_mask\n",
        "\n",
        "\n",
        "    def _init_placeholders(self) -> None:\n",
        "        super()._init_placeholders()\n",
        "        self.y_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='y_ph')\n",
        "        self.y_masks_ph = tf.placeholder(shape=(None, None),\n",
        "                                         dtype=tf.int32,\n",
        "                                         name='y_mask_ph')\n",
        "        self.topk_masks_ph = tf.placeholder(shape=(None, None),  # added\n",
        "                                         dtype=tf.int32,\n",
        "                                         name='topk_mask_ph')\n",
        "\n",
        "    def _decode_crf(self, feed_dict: Dict[tf.Tensor, np.ndarray]) -> List[np.ndarray]:\n",
        "        logits, trans_params, mask, seq_lengths = self.sess.run([self.logits,\n",
        "                                                                 self._transition_params,\n",
        "                                                                 self.y_masks_ph,\n",
        "                                                                 self.seq_lengths],\n",
        "                                                                feed_dict=feed_dict)\n",
        "        # iterate over the sentences because no batching in viterbi_decode\n",
        "        y_pred = []\n",
        "        for logit, sequence_length in zip(logits, seq_lengths):\n",
        "            logit = logit[:int(sequence_length)]  # keep only the valid steps\n",
        "            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
        "            y_pred += [viterbi_seq]\n",
        "        return y_pred\n",
        "\n",
        "    def _build_feed_dict(self, input_ids, input_masks, y_masks, topk_tok_mask, y=None):\n",
        "        feed_dict = self._build_basic_feed_dict(input_ids, input_masks, train=(y is not None))\n",
        "\n",
        "        if y is not None:\n",
        "            max_len = 0\n",
        "            for seq in topk_tok_mask:\n",
        "                if len(seq) > max_len:\n",
        "                    max_len = len(seq)\n",
        "            feed_dict[self.topk_masks_ph] = topk_tok_mask # added            \n",
        "            feed_dict[self.y_ph] = y\n",
        "        feed_dict[self.y_masks_ph] = y_masks\n",
        "\n",
        "        return feed_dict\n",
        "\n",
        "    def __call__(self,\n",
        "                 input_ids: Union[List[List[int]], np.ndarray],\n",
        "                 input_masks: Union[List[List[int]], np.ndarray],\n",
        "                 y_masks: Union[List[List[int]], np.ndarray],\n",
        "                 topk_tok_mask: Union[List[List[int]], np.ndarray]) -> Union[List[List[int]], List[np.ndarray]]:\n",
        "        \"\"\" Predicts tag indices for a given subword tokens batch\n",
        "        Args:\n",
        "            input_ids: indices of the subwords\n",
        "            input_masks: mask that determines where to attend and where not to\n",
        "            y_masks: mask which determines the first subword units in the the word\n",
        "\n",
        "        Added: \n",
        "            topk_tok_mask: mask that determines where to attend and where not to\n",
        "        Returns:\n",
        "            Label indices or class probabilities for each token (not subtoken)\n",
        "        # \"\"\"\n",
        "        \n",
        "        feed_dict = self._build_feed_dict(input_ids, input_masks, y_masks, topk_tok_mask)\n",
        "       \n",
        "        if self.ema:\n",
        "            self.sess.run(self.ema.switch_to_test_op)\n",
        "        if not self.return_probas:\n",
        "            if self.use_crf:\n",
        "                pred = self._decode_crf(feed_dict)\n",
        "            else:\n",
        "                pred, seq_lengths = self.sess.run([self.y_predictions, self.seq_lengths], feed_dict=feed_dict)\n",
        "                pred = [p[:l] for l, p in zip(seq_lengths, pred)]\n",
        "        else:\n",
        "            pred = self.sess.run(self.y_probas, feed_dict=feed_dict)\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "class ExponentialMovingAverage:\n",
        "    def __init__(self,\n",
        "                 decay: float = 0.999,\n",
        "                 variables_on_cpu: bool = True) -> None:\n",
        "        self.decay = decay\n",
        "        self.ema = tf.train.ExponentialMovingAverage(decay=decay)\n",
        "        self.var_device_name = '/cpu:0' if variables_on_cpu else None\n",
        "        self.train_mode = None\n",
        "\n",
        "    def build(self,\n",
        "              minimize_op: tf.Tensor,\n",
        "              update_vars: List[tf.Variable] = None,\n",
        "              name: str = \"EMA\") -> tf.Tensor:\n",
        "        with tf.variable_scope(name):\n",
        "            if update_vars is None:\n",
        "                update_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "\n",
        "            with tf.control_dependencies([minimize_op]):\n",
        "                minimize_op = self.ema.apply(update_vars)\n",
        "\n",
        "            with tf.device(self.var_device_name):\n",
        "                # Make backup variables\n",
        "                with tf.variable_scope('BackupVariables'):\n",
        "                    backup_vars = [tf.get_variable(var.op.name,\n",
        "                                                   dtype=var.value().dtype,\n",
        "                                                   trainable=False,\n",
        "                                                   initializer=var.initialized_value())\n",
        "                                   for var in update_vars]\n",
        "\n",
        "                def ema_to_weights():\n",
        "                    return tf.group(*(tf.assign(var, self.ema.average(var).read_value())\n",
        "                                      for var in update_vars))\n",
        "\n",
        "                def save_weight_backups():\n",
        "                    return tf.group(*(tf.assign(bck, var.read_value())\n",
        "                                      for var, bck in zip(update_vars, backup_vars)))\n",
        "\n",
        "                def restore_weight_backups():\n",
        "                    return tf.group(*(tf.assign(var, bck.read_value())\n",
        "                                      for var, bck in zip(update_vars, backup_vars)))\n",
        "\n",
        "                train_switch_op = restore_weight_backups()\n",
        "                with tf.control_dependencies([save_weight_backups()]):\n",
        "                    test_switch_op = ema_to_weights()\n",
        "\n",
        "            self.train_switch_op = train_switch_op\n",
        "            self.test_switch_op = test_switch_op\n",
        "            self.do_nothing_op = tf.no_op()\n",
        "\n",
        "        return minimize_op\n",
        "\n",
        "    @property\n",
        "    def init_op(self) -> tf.Operation:\n",
        "        self.train_mode = False\n",
        "        return self.test_switch_op\n",
        "\n",
        "    @property\n",
        "    def switch_to_train_op(self) -> tf.Operation:\n",
        "        assert self.train_mode is not None, \"ema variables aren't initialized\"\n",
        "        if not self.train_mode:\n",
        "            # log.info(\"switching to train mode\")\n",
        "            self.train_mode = True\n",
        "            return self.train_switch_op\n",
        "        return self.do_nothing_op\n",
        "\n",
        "    @property\n",
        "    def switch_to_test_op(self) -> tf.Operation:\n",
        "        assert self.train_mode is not None, \"ema variables aren't initialized\"\n",
        "        if self.train_mode:\n",
        "            # log.info(\"switching to test mode\")\n",
        "            self.train_mode = False\n",
        "            return self.test_switch_op\n",
        "        return self.do_nothing_op"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrMdYc1dG7eO"
      },
      "source": [
        "## Mask_ys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Component that masks tokens for the evaluation, so the metrics are counted considering certain group of tokens. By masking here I mean just forming new lists of tokens without the irrelevant ones."
      ],
      "metadata": {
        "id": "_yquqwCeE63b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oS5h0kWtGx2e"
      },
      "outputs": [],
      "source": [
        "@register('mask_ys')\n",
        "class mask_ys(Component):\n",
        "    def __init__(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, y, topk_tok_mask, y_predicted, *args, **kwargs):\n",
        "\n",
        "        y_predicted_masked = []\n",
        "        y_masked = []\n",
        "        \n",
        "        for i in range(len(y_predicted)):\n",
        "            line_preds = []\n",
        "            line_true = []\n",
        "            for j in range(len(y_predicted[i])):\n",
        "                if topk_tok_mask[i][j] == 1:\n",
        "                    line_preds.append(y_predicted[i][j])\n",
        "                    line_true.append(y[i][j])\n",
        "            y_predicted_masked.append(np.array(line_preds))\n",
        "            y_masked.append(np.array(line_true))\n",
        "\n",
        "        return y_masked, y_predicted_masked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XSodQDbIMDo"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to specify in config:\n",
        "- ['dataset_reader']['data_path'] - path to datafolder\n",
        "- ['dataset_reader']['language'] - language according to deeppavlov's config \n",
        "- ['metadata']['variables']['MODELS_PATH'] - path to general folder devoted to certain dataset\n",
        "- ['train']['evaluation_targets'] = valid, ['dataset_reader']['data_types'] = ['train', 'dev'], if there is no test file\n",
        "- ['metadata']['variables']['DATA_PATH'] - path to datafolder\n",
        "\n",
        "will be specified below:\n",
        "- ['metadata']['variables']['WORK_PATH'] - path to certain model folder\n",
        "- ['chainer']['pipe'][1]['topk_tokens_path'] - path to the group of tokens to consider\n"
      ],
      "metadata": {
        "id": "yYptObzp3DO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d-rIu6PaIb6J"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import json\n",
        "from deeppavlov import build_model, configs, train_model, evaluate_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TUJPGa0qMu86"
      },
      "outputs": [],
      "source": [
        "base_config = json.load(open('./base_config.json'))\n",
        "\n",
        "base_config['metadata']['variables']['DATA_PATH'] = datafolder_path\n",
        "base_config['metadata']['variables']['MODELS_PATH'] = '{ROOT_PATH}/drive/MyDrive/models_diploma/GramEval_social'\n",
        "base_config['train']['evaluation_targets'] = ['valid']\n",
        "base_config['dataset_reader']['data_types'] = ['train', 'dev']\n",
        "base_config['dataset_reader']['language'] = language_conf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##From Scratch Models"
      ],
      "metadata": {
        "id": "_6HdtWbaGTiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###top100 "
      ],
      "metadata": {
        "id": "msN4Q1KmT5Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_top100'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "oAPZjNClGYkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False) \n"
      ],
      "metadata": {
        "id": "1nwPq2KxGefG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66249af3-c6ed-4fc1-990f-f30f2c79eb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:47:01.174 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:47:01.688 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From <ipython-input-6-5405f03ac0b9>:54: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-5405f03ac0b9>:228: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:47:20.77 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-23 13:47:22.114 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.0, \"accuracy\": 0.0341}, \"time_spent\": \"0:00:03\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:178: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:47:45.179 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0 to 0.6349\n",
            "2022-05-23 13:47:45.184 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:47:45.189 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6349, \"accuracy\": 0.3864}, \"time_spent\": \"0:00:26\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 0, \"patience_limit\": 30}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:211: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:48:09.346 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6349 to 0.7664\n",
            "2022-05-23 13:48:09.348 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:48:09.356 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7664, \"accuracy\": 0.5568}, \"time_spent\": \"0:00:50\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:48:33.676 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7664 to 0.8454\n",
            "2022-05-23 13:48:33.677 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:48:33.685 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8454, \"accuracy\": 0.6591}, \"time_spent\": \"0:01:14\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:48:47.898 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8454 to 0.8586\n",
            "2022-05-23 13:48:47.900 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:48:47.910 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8586, \"accuracy\": 0.6705}, \"time_spent\": \"0:01:28\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9556, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:49:04.306 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8586 to 0.875\n",
            "2022-05-23 13:49:04.307 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:49:04.319 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.875, \"accuracy\": 0.7045}, \"time_spent\": \"0:01:45\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:49:30.29 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8717, \"accuracy\": 0.7045}, \"time_spent\": \"0:02:10\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:49:51.225 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.875 to 0.8914\n",
            "2022-05-23 13:49:51.229 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:49:51.235 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.75}, \"time_spent\": \"0:02:32\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:50:14.581 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8849, \"accuracy\": 0.7159}, \"time_spent\": \"0:02:55\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:50:17.303 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8783, \"accuracy\": 0.7159}, \"time_spent\": \"0:02:58\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:50:38.369 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8914 to 0.8947\n",
            "2022-05-23 13:50:38.370 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:50:38.378 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:03:19\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:51:03.657 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:03:44\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:51:24.916 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8882, \"accuracy\": 0.7273}, \"time_spent\": \"0:04:05\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:51:32.630 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8947 to 0.898\n",
            "2022-05-23 13:51:32.631 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:51:32.638 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7614}, \"time_spent\": \"0:04:13\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28679, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:51:50.398 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.75}, \"time_spent\": \"0:04:31\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:52:11.768 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7727}, \"time_spent\": \"0:04:52\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:52:32.931 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.7386}, \"time_spent\": \"0:05:13\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:52:49.590 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.898 to 0.9013\n",
            "2022-05-23 13:52:49.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:52:49.598 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7727}, \"time_spent\": \"0:05:30\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38257, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:52:58.273 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9013 to 0.9046\n",
            "2022-05-23 13:52:58.275 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 13:52:58.282 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7727}, \"time_spent\": \"0:05:39\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:53:24.234 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8816, \"accuracy\": 0.7159}, \"time_spent\": \"0:06:05\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:53:45.525 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8816, \"accuracy\": 0.7273}, \"time_spent\": \"0:06:26\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:54:06.675 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.75}, \"time_spent\": \"0:06:47\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:54:11.738 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7614}, \"time_spent\": \"0:06:52\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47813, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:54:27.900 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8882, \"accuracy\": 0.75}, \"time_spent\": \"0:07:08\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:54:49.17 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7727}, \"time_spent\": \"0:07:29\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:55:10.232 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.75}, \"time_spent\": \"0:07:51\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:55:23.974 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.7386}, \"time_spent\": \"0:08:04\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57380, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:55:31.602 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7614}, \"time_spent\": \"0:08:12\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:55:52.680 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:08:33\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:56:13.761 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.75}, \"time_spent\": \"0:08:54\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:56:34.898 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7614}, \"time_spent\": \"0:09:15\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:56:37.929 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.7386}, \"time_spent\": \"0:09:18\", \"epochs_done\": 24, \"batches_seen\": 2100, \"train_examples_seen\": 66936, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:56:56.278 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8849, \"accuracy\": 0.7159}, \"time_spent\": \"0:09:37\", \"epochs_done\": 25, \"batches_seen\": 2175, \"train_examples_seen\": 69325, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:57:17.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7614}, \"time_spent\": \"0:09:58\", \"epochs_done\": 26, \"batches_seen\": 2262, \"train_examples_seen\": 72098, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:57:38.496 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7386}, \"time_spent\": \"0:10:19\", \"epochs_done\": 27, \"batches_seen\": 2349, \"train_examples_seen\": 74871, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:57:50.878 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8849, \"accuracy\": 0.7045}, \"time_spent\": \"0:10:31\", \"epochs_done\": 27, \"batches_seen\": 2400, \"train_examples_seen\": 76503, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:57:59.961 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:10:40\", \"epochs_done\": 28, \"batches_seen\": 2436, \"train_examples_seen\": 77644, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:58:21.100 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:02\", \"epochs_done\": 29, \"batches_seen\": 2523, \"train_examples_seen\": 80417, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:58:42.203 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8816, \"accuracy\": 0.7159}, \"time_spent\": \"0:11:23\", \"epochs_done\": 30, \"batches_seen\": 2610, \"train_examples_seen\": 83190, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:59:03.317 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7273}, \"time_spent\": \"0:11:44\", \"epochs_done\": 31, \"batches_seen\": 2697, \"train_examples_seen\": 85963, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:59:05.407 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7273}, \"time_spent\": \"0:11:46\", \"epochs_done\": 31, \"batches_seen\": 2700, \"train_examples_seen\": 86048, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:59:24.649 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.75}, \"time_spent\": \"0:12:05\", \"epochs_done\": 32, \"batches_seen\": 2784, \"train_examples_seen\": 88736, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 13:59:45.782 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:12:26\", \"epochs_done\": 33, \"batches_seen\": 2871, \"train_examples_seen\": 91509, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:00:06.876 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8882, \"accuracy\": 0.7273}, \"time_spent\": \"0:12:47\", \"epochs_done\": 34, \"batches_seen\": 2958, \"train_examples_seen\": 94282, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:00:17.358 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8882, \"accuracy\": 0.7273}, \"time_spent\": \"0:12:58\", \"epochs_done\": 34, \"batches_seen\": 3000, \"train_examples_seen\": 95615, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:00:28.256 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:13:09\", \"epochs_done\": 35, \"batches_seen\": 3045, \"train_examples_seen\": 97055, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:00:49.394 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7273}, \"time_spent\": \"0:13:30\", \"epochs_done\": 36, \"batches_seen\": 3132, \"train_examples_seen\": 99828, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:01:10.495 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:13:51\", \"epochs_done\": 37, \"batches_seen\": 3219, \"train_examples_seen\": 102601, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:01:29.501 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9046\n",
            "2022-05-23 14:01:29.509 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:01:31.823 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n",
            "2022-05-23 14:01:31.824 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 308: Ran out of patience\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7614}, \"time_spent\": \"0:14:10\", \"epochs_done\": 37, \"batches_seen\": 3300, \"train_examples_seen\": 105182, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:01:32.364 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/tag.dict]\n",
            "2022-05-23 14:01:45.689 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:01:47.388 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7727}, \"time_spent\": \"0:00:02\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:01:48.911 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/tag.dict]\n",
            "2022-05-23 14:02:04.38 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top100/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:02:05.730 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###top1000"
      ],
      "metadata": {
        "id": "DavKW8gHT1vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_top1000'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "X7pxTy9oT97h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2VKaif8UFps",
        "outputId": "1ff18215-551c-4eb1-ba7a-66a8106ca97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:03:17.257 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-23 14:03:17.848 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:03:36.416 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-23 14:03:37.658 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.0, \"accuracy\": 0.1136}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:04:02.247 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0 to 0.1538\n",
            "2022-05-23 14:04:02.248 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:04:02.255 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.1538, \"accuracy\": 0.1932}, \"time_spent\": \"0:00:26\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:04:28.242 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.1538 to 0.2179\n",
            "2022-05-23 14:04:28.246 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:04:28.251 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.2179, \"accuracy\": 0.2273}, \"time_spent\": \"0:00:52\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:04:54.175 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.2179 to 0.3205\n",
            "2022-05-23 14:04:54.176 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:04:54.187 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.3205, \"accuracy\": 0.3068}, \"time_spent\": \"0:01:18\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:05:08.626 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.3205 to 0.4103\n",
            "2022-05-23 14:05:08.627 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:05:08.637 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.4103, \"accuracy\": 0.3523}, \"time_spent\": \"0:01:33\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9556, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:05:25.819 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.4103 to 0.5321\n",
            "2022-05-23 14:05:25.820 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:05:25.831 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.5321, \"accuracy\": 0.4545}, \"time_spent\": \"0:01:50\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:05:52.205 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.5321 to 0.6154\n",
            "2022-05-23 14:05:52.206 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:05:52.213 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6154, \"accuracy\": 0.5341}, \"time_spent\": \"0:02:16\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:06:17.908 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6154 to 0.6538\n",
            "2022-05-23 14:06:17.912 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:06:17.918 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6538, \"accuracy\": 0.5909}, \"time_spent\": \"0:02:42\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:06:41.708 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6538 to 0.6859\n",
            "2022-05-23 14:06:41.709 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:06:41.723 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6859, \"accuracy\": 0.6136}, \"time_spent\": \"0:03:06\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:06:48.93 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6859 to 0.6923\n",
            "2022-05-23 14:06:48.94 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:06:48.102 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6923, \"accuracy\": 0.625}, \"time_spent\": \"0:03:12\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:07:14.541 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6923 to 0.7115\n",
            "2022-05-23 14:07:14.542 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:07:14.548 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7115, \"accuracy\": 0.6364}, \"time_spent\": \"0:03:39\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:07:40.548 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7115 to 0.7179\n",
            "2022-05-23 14:07:40.549 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:07:40.557 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7179, \"accuracy\": 0.6477}, \"time_spent\": \"0:04:05\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:08:07.104 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6987, \"accuracy\": 0.625}, \"time_spent\": \"0:04:31\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:08:16.297 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7179 to 0.7308\n",
            "2022-05-23 14:08:16.301 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:08:16.306 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7308, \"accuracy\": 0.6477}, \"time_spent\": \"0:04:40\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28690, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:08:33.347 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7308 to 0.7372\n",
            "2022-05-23 14:08:33.349 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:08:33.359 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7372, \"accuracy\": 0.6705}, \"time_spent\": \"0:04:57\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:08:59.991 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7372 to 0.7436\n",
            "2022-05-23 14:08:59.995 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:09:00.0 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7436, \"accuracy\": 0.6818}, \"time_spent\": \"0:05:24\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:09:26.692 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7436, \"accuracy\": 0.6591}, \"time_spent\": \"0:05:51\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:09:44.175 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7436 to 0.7692\n",
            "2022-05-23 14:09:44.177 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:09:44.185 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7692, \"accuracy\": 0.6932}, \"time_spent\": \"0:06:08\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38246, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:09:53.627 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7692 to 0.7821\n",
            "2022-05-23 14:09:53.628 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:09:53.636 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7821, \"accuracy\": 0.6932}, \"time_spent\": \"0:06:18\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:10:21.256 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7821, \"accuracy\": 0.7045}, \"time_spent\": \"0:06:45\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:10:43.91 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7821, \"accuracy\": 0.7045}, \"time_spent\": \"0:07:07\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:11:04.691 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7756, \"accuracy\": 0.6932}, \"time_spent\": \"0:07:29\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:11:11.134 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7821, \"accuracy\": 0.7045}, \"time_spent\": \"0:07:35\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47813, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:11:26.460 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7756, \"accuracy\": 0.6932}, \"time_spent\": \"0:07:51\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:11:48.8 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7821 to 0.7885\n",
            "2022-05-23 14:11:48.9 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:11:48.18 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7885, \"accuracy\": 0.7159}, \"time_spent\": \"0:08:12\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:12:14.362 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7885, \"accuracy\": 0.7159}, \"time_spent\": \"0:08:38\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:12:29.538 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7885 to 0.8013\n",
            "2022-05-23 14:12:29.540 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:12:29.548 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:08:54\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57380, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:12:41.530 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:09:06\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:13:03.606 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7273}, \"time_spent\": \"0:09:28\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:13:25.253 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8013 to 0.8077\n",
            "2022-05-23 14:13:25.254 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:13:25.258 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:09:49\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:13:52.95 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.75}, \"time_spent\": \"0:10:16\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:13:56.992 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.75}, \"time_spent\": \"0:10:21\", \"epochs_done\": 24, \"batches_seen\": 2100, \"train_examples_seen\": 66936, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:14:14.0 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:10:38\", \"epochs_done\": 25, \"batches_seen\": 2175, \"train_examples_seen\": 69325, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:14:35.553 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8077 to 0.8141\n",
            "2022-05-23 14:14:35.559 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:14:35.565 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:00\", \"epochs_done\": 26, \"batches_seen\": 2262, \"train_examples_seen\": 72098, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:15:01.763 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:26\", \"epochs_done\": 27, \"batches_seen\": 2349, \"train_examples_seen\": 74871, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:15:14.843 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:11:39\", \"epochs_done\": 27, \"batches_seen\": 2400, \"train_examples_seen\": 76492, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:15:23.738 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:48\", \"epochs_done\": 28, \"batches_seen\": 2436, \"train_examples_seen\": 77644, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:15:45.472 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:12:10\", \"epochs_done\": 29, \"batches_seen\": 2523, \"train_examples_seen\": 80417, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:16:06.956 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7885, \"accuracy\": 0.7159}, \"time_spent\": \"0:12:31\", \"epochs_done\": 30, \"batches_seen\": 2610, \"train_examples_seen\": 83190, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:16:28.470 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:12:53\", \"epochs_done\": 31, \"batches_seen\": 2697, \"train_examples_seen\": 85963, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:16:30.89 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:12:54\", \"epochs_done\": 31, \"batches_seen\": 2700, \"train_examples_seen\": 86059, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:16:50.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7159}, \"time_spent\": \"0:13:14\", \"epochs_done\": 32, \"batches_seen\": 2784, \"train_examples_seen\": 88736, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:17:11.965 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:13:36\", \"epochs_done\": 33, \"batches_seen\": 2871, \"train_examples_seen\": 91509, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:17:33.508 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8141 to 0.8269\n",
            "2022-05-23 14:17:33.509 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:17:33.521 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7386}, \"time_spent\": \"0:13:58\", \"epochs_done\": 34, \"batches_seen\": 2958, \"train_examples_seen\": 94282, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:17:49.478 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:14:14\", \"epochs_done\": 34, \"batches_seen\": 3000, \"train_examples_seen\": 95615, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:18:00.832 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:14:25\", \"epochs_done\": 35, \"batches_seen\": 3045, \"train_examples_seen\": 97055, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:18:22.526 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:14:47\", \"epochs_done\": 36, \"batches_seen\": 3132, \"train_examples_seen\": 99828, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:18:44.153 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:15:08\", \"epochs_done\": 37, \"batches_seen\": 3219, \"train_examples_seen\": 102601, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:19:04.502 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:15:29\", \"epochs_done\": 37, \"batches_seen\": 3300, \"train_examples_seen\": 105182, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:19:06.22 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:15:30\", \"epochs_done\": 38, \"batches_seen\": 3306, \"train_examples_seen\": 105374, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:19:27.707 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:15:52\", \"epochs_done\": 39, \"batches_seen\": 3393, \"train_examples_seen\": 108147, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:19:49.447 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:16:14\", \"epochs_done\": 40, \"batches_seen\": 3480, \"train_examples_seen\": 110920, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:20:11.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:16:35\", \"epochs_done\": 41, \"batches_seen\": 3567, \"train_examples_seen\": 113693, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:20:18.763 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.75}, \"time_spent\": \"0:16:43\", \"epochs_done\": 41, \"batches_seen\": 3600, \"train_examples_seen\": 114749, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:20:33.25 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:16:57\", \"epochs_done\": 42, \"batches_seen\": 3654, \"train_examples_seen\": 116466, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:20:54.795 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:17:19\", \"epochs_done\": 43, \"batches_seen\": 3741, \"train_examples_seen\": 119239, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:21:16.469 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8269 to 0.8333\n",
            "2022-05-23 14:21:16.470 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:21:16.479 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.75}, \"time_spent\": \"0:17:41\", \"epochs_done\": 44, \"batches_seen\": 3828, \"train_examples_seen\": 122012, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:21:38.347 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7159}, \"time_spent\": \"0:18:02\", \"epochs_done\": 44, \"batches_seen\": 3900, \"train_examples_seen\": 124305, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:21:43.90 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:18:07\", \"epochs_done\": 45, \"batches_seen\": 3915, \"train_examples_seen\": 124785, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:22:04.883 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:18:29\", \"epochs_done\": 46, \"batches_seen\": 4002, \"train_examples_seen\": 127558, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:22:26.543 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.7614}, \"time_spent\": \"0:18:51\", \"epochs_done\": 47, \"batches_seen\": 4089, \"train_examples_seen\": 130331, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:22:48.154 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:19:12\", \"epochs_done\": 48, \"batches_seen\": 4176, \"train_examples_seen\": 133104, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:22:56.402 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:19:20\", \"epochs_done\": 48, \"batches_seen\": 4200, \"train_examples_seen\": 133872, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:23:10.42 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.75}, \"time_spent\": \"0:19:34\", \"epochs_done\": 49, \"batches_seen\": 4263, \"train_examples_seen\": 135877, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:23:31.693 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.7386}, \"time_spent\": \"0:19:56\", \"epochs_done\": 50, \"batches_seen\": 4350, \"train_examples_seen\": 138650, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:23:53.470 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7727}, \"time_spent\": \"0:20:18\", \"epochs_done\": 51, \"batches_seen\": 4437, \"train_examples_seen\": 141423, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:24:09.124 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7727}, \"time_spent\": \"0:20:33\", \"epochs_done\": 51, \"batches_seen\": 4500, \"train_examples_seen\": 143428, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:24:15.377 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:20:39\", \"epochs_done\": 52, \"batches_seen\": 4524, \"train_examples_seen\": 144196, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:24:37.28 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:21:01\", \"epochs_done\": 53, \"batches_seen\": 4611, \"train_examples_seen\": 146969, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:24:58.675 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7273}, \"time_spent\": \"0:21:23\", \"epochs_done\": 54, \"batches_seen\": 4698, \"train_examples_seen\": 149742, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:25:20.319 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.7159}, \"time_spent\": \"0:21:44\", \"epochs_done\": 55, \"batches_seen\": 4785, \"train_examples_seen\": 152515, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:25:25.81 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7159}, \"time_spent\": \"0:21:49\", \"epochs_done\": 55, \"batches_seen\": 4800, \"train_examples_seen\": 152984, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:25:42.213 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:22:06\", \"epochs_done\": 56, \"batches_seen\": 4872, \"train_examples_seen\": 155288, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:26:03.840 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:22:28\", \"epochs_done\": 57, \"batches_seen\": 4959, \"train_examples_seen\": 158061, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:26:25.480 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:22:50\", \"epochs_done\": 58, \"batches_seen\": 5046, \"train_examples_seen\": 160834, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:26:39.311 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8333 to 0.8397\n",
            "2022-05-23 14:26:39.312 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:26:39.321 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8397, \"accuracy\": 0.7614}, \"time_spent\": \"0:23:03\", \"epochs_done\": 58, \"batches_seen\": 5100, \"train_examples_seen\": 162551, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:26:51.911 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7614}, \"time_spent\": \"0:23:16\", \"epochs_done\": 59, \"batches_seen\": 5133, \"train_examples_seen\": 163607, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:27:13.924 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:23:38\", \"epochs_done\": 60, \"batches_seen\": 5220, \"train_examples_seen\": 166380, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:27:15.352 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/tag.dict]\n",
            "2022-05-23 14:27:29.383 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:27:31.230 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8397, \"accuracy\": 0.7614}, \"time_spent\": \"0:00:02\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:27:32.849 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/tag.dict]\n",
            "2022-05-23 14:27:49.194 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:27:50.983 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other"
      ],
      "metadata": {
        "id": "jjcuynC5jpoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_other'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt', '{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "\n",
        "base_config['chainer']['pipe'][1]['last'] = True"
      ],
      "metadata": {
        "id": "WqkYhAsajvnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItzRPmPxjwkT",
        "outputId": "e5b560eb-255e-4c29-f7e5-e8aeb5142eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:28:02.544 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-23 14:28:02.923 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:28:20.498 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-23 14:28:21.814 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.0018, \"accuracy\": 0.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:28:45.983 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0018 to 0.5106\n",
            "2022-05-23 14:28:45.984 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:28:45.993 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.5106, \"accuracy\": 0.0795}, \"time_spent\": \"0:00:26\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:29:11.523 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.5106 to 0.6338\n",
            "2022-05-23 14:29:11.525 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:29:11.532 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6338, \"accuracy\": 0.1136}, \"time_spent\": \"0:00:52\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:29:38.226 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6338 to 0.6972\n",
            "2022-05-23 14:29:38.227 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:29:38.234 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6972, \"accuracy\": 0.1477}, \"time_spent\": \"0:01:18\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:29:51.715 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6972 to 0.7394\n",
            "2022-05-23 14:29:51.717 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:29:51.726 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7394, \"accuracy\": 0.1705}, \"time_spent\": \"0:01:32\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9556, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:30:08.604 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7394 to 0.7641\n",
            "2022-05-23 14:30:08.606 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:30:08.617 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7641, \"accuracy\": 0.2614}, \"time_spent\": \"0:01:49\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:30:34.746 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7641 to 0.787\n",
            "2022-05-23 14:30:34.750 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:30:34.755 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.787, \"accuracy\": 0.3182}, \"time_spent\": \"0:02:15\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:31:00.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.787 to 0.8151\n",
            "2022-05-23 14:31:00.132 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:31:00.145 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8151, \"accuracy\": 0.3864}, \"time_spent\": \"0:02:40\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:31:23.878 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8151 to 0.8257\n",
            "2022-05-23 14:31:23.882 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:31:23.887 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8257, \"accuracy\": 0.4091}, \"time_spent\": \"0:03:04\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:31:29.887 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8257 to 0.8345\n",
            "2022-05-23 14:31:29.888 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:31:29.896 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8345, \"accuracy\": 0.4205}, \"time_spent\": \"0:03:10\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:31:56.38 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.831, \"accuracy\": 0.4205}, \"time_spent\": \"0:03:36\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:32:17.159 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8345 to 0.8486\n",
            "2022-05-23 14:32:17.161 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:32:17.169 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8486, \"accuracy\": 0.4773}, \"time_spent\": \"0:03:57\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:32:42.726 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8486 to 0.8697\n",
            "2022-05-23 14:32:42.727 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:32:42.734 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8697, \"accuracy\": 0.5455}, \"time_spent\": \"0:04:23\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:32:54.557 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8662, \"accuracy\": 0.5227}, \"time_spent\": \"0:04:35\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28679, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:33:08.683 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8697 to 0.875\n",
            "2022-05-23 14:33:08.687 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:33:08.693 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.875, \"accuracy\": 0.5568}, \"time_spent\": \"0:04:49\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:33:34.350 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.875 to 0.882\n",
            "2022-05-23 14:33:34.351 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:33:34.360 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.882, \"accuracy\": 0.5795}, \"time_spent\": \"0:05:14\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:34:00.286 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.882 to 0.8926\n",
            "2022-05-23 14:34:00.291 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:34:00.296 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8926, \"accuracy\": 0.5909}, \"time_spent\": \"0:05:40\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:34:23.36 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8926 to 0.8961\n",
            "2022-05-23 14:34:23.38 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:34:23.45 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8961, \"accuracy\": 0.6136}, \"time_spent\": \"0:06:03\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38246, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:34:31.567 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8908, \"accuracy\": 0.6023}, \"time_spent\": \"0:06:12\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:34:53.501 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8961 to 0.8996\n",
            "2022-05-23 14:34:53.502 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:34:53.513 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6023}, \"time_spent\": \"0:06:33\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:35:20.295 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8961, \"accuracy\": 0.6023}, \"time_spent\": \"0:07:00\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:35:41.987 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6023}, \"time_spent\": \"0:07:22\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:35:48.494 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.5909}, \"time_spent\": \"0:07:28\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47802, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:36:04.12 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8944, \"accuracy\": 0.5909}, \"time_spent\": \"0:07:44\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:36:25.675 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8996 to 0.9049\n",
            "2022-05-23 14:36:25.676 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:36:25.683 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.625}, \"time_spent\": \"0:08:06\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:36:51.960 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9049 to 0.9067\n",
            "2022-05-23 14:36:51.965 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:36:51.971 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6364}, \"time_spent\": \"0:08:32\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:37:12.194 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.625}, \"time_spent\": \"0:08:52\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57369, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:37:18.682 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9067 to 0.9085\n",
            "2022-05-23 14:37:18.686 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:37:18.691 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.6477}, \"time_spent\": \"0:08:59\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:37:45.200 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.5795}, \"time_spent\": \"0:09:25\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:38:06.977 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8961, \"accuracy\": 0.6023}, \"time_spent\": \"0:09:47\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:38:28.729 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.625}, \"time_spent\": \"0:10:09\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:38:32.587 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.6364}, \"time_spent\": \"0:10:13\", \"epochs_done\": 24, \"batches_seen\": 2100, \"train_examples_seen\": 66936, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:38:50.700 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.6364}, \"time_spent\": \"0:10:31\", \"epochs_done\": 25, \"batches_seen\": 2175, \"train_examples_seen\": 69325, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:39:12.385 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6023}, \"time_spent\": \"0:10:52\", \"epochs_done\": 26, \"batches_seen\": 2262, \"train_examples_seen\": 72098, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:39:34.92 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.625}, \"time_spent\": \"0:11:14\", \"epochs_done\": 27, \"batches_seen\": 2349, \"train_examples_seen\": 74871, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:39:46.848 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6477}, \"time_spent\": \"0:11:27\", \"epochs_done\": 27, \"batches_seen\": 2400, \"train_examples_seen\": 76492, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:39:56.20 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.6136}, \"time_spent\": \"0:11:36\", \"epochs_done\": 28, \"batches_seen\": 2436, \"train_examples_seen\": 77644, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:40:17.672 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.6364}, \"time_spent\": \"0:11:58\", \"epochs_done\": 29, \"batches_seen\": 2523, \"train_examples_seen\": 80417, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:40:39.367 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.5909}, \"time_spent\": \"0:12:19\", \"epochs_done\": 30, \"batches_seen\": 2610, \"train_examples_seen\": 83190, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:41:01.96 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6364}, \"time_spent\": \"0:12:41\", \"epochs_done\": 31, \"batches_seen\": 2697, \"train_examples_seen\": 85963, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:41:02.578 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6477}, \"time_spent\": \"0:12:43\", \"epochs_done\": 31, \"batches_seen\": 2700, \"train_examples_seen\": 86059, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:41:23.51 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.6136}, \"time_spent\": \"0:13:03\", \"epochs_done\": 32, \"batches_seen\": 2784, \"train_examples_seen\": 88736, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:41:44.727 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.625}, \"time_spent\": \"0:13:25\", \"epochs_done\": 33, \"batches_seen\": 2871, \"train_examples_seen\": 91509, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:42:06.437 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9085 to 0.919\n",
            "2022-05-23 14:42:06.438 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:42:06.447 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.919, \"accuracy\": 0.6477}, \"time_spent\": \"0:13:46\", \"epochs_done\": 34, \"batches_seen\": 2958, \"train_examples_seen\": 94282, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:42:22.627 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9155, \"accuracy\": 0.6705}, \"time_spent\": \"0:14:03\", \"epochs_done\": 34, \"batches_seen\": 3000, \"train_examples_seen\": 95615, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:42:33.97 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9155, \"accuracy\": 0.6591}, \"time_spent\": \"0:14:13\", \"epochs_done\": 35, \"batches_seen\": 3045, \"train_examples_seen\": 97055, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:42:54.879 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6136}, \"time_spent\": \"0:14:35\", \"epochs_done\": 36, \"batches_seen\": 3132, \"train_examples_seen\": 99828, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:43:16.544 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.912, \"accuracy\": 0.6477}, \"time_spent\": \"0:14:57\", \"epochs_done\": 37, \"batches_seen\": 3219, \"train_examples_seen\": 102601, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:43:36.844 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8961, \"accuracy\": 0.5909}, \"time_spent\": \"0:15:17\", \"epochs_done\": 37, \"batches_seen\": 3300, \"train_examples_seen\": 105182, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:43:38.490 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.5909}, \"time_spent\": \"0:15:18\", \"epochs_done\": 38, \"batches_seen\": 3306, \"train_examples_seen\": 105374, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:44:00.188 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8961, \"accuracy\": 0.6023}, \"time_spent\": \"0:15:40\", \"epochs_done\": 39, \"batches_seen\": 3393, \"train_examples_seen\": 108147, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:44:21.932 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.625}, \"time_spent\": \"0:16:02\", \"epochs_done\": 40, \"batches_seen\": 3480, \"train_examples_seen\": 110920, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:44:43.588 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.6023}, \"time_spent\": \"0:16:24\", \"epochs_done\": 41, \"batches_seen\": 3567, \"train_examples_seen\": 113693, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:44:53.269 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.912, \"accuracy\": 0.6364}, \"time_spent\": \"0:16:33\", \"epochs_done\": 41, \"batches_seen\": 3600, \"train_examples_seen\": 114738, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:45:05.502 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.6023}, \"time_spent\": \"0:16:46\", \"epochs_done\": 42, \"batches_seen\": 3654, \"train_examples_seen\": 116466, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:45:27.187 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.6023}, \"time_spent\": \"0:17:07\", \"epochs_done\": 43, \"batches_seen\": 3741, \"train_examples_seen\": 119239, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:45:48.854 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6364}, \"time_spent\": \"0:17:29\", \"epochs_done\": 44, \"batches_seen\": 3828, \"train_examples_seen\": 122012, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:46:06.837 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.6136}, \"time_spent\": \"0:17:47\", \"epochs_done\": 44, \"batches_seen\": 3900, \"train_examples_seen\": 124305, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:46:10.908 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.625}, \"time_spent\": \"0:17:51\", \"epochs_done\": 45, \"batches_seen\": 3915, \"train_examples_seen\": 124785, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:46:32.675 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6136}, \"time_spent\": \"0:18:13\", \"epochs_done\": 46, \"batches_seen\": 4002, \"train_examples_seen\": 127558, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:46:54.496 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.5909}, \"time_spent\": \"0:18:34\", \"epochs_done\": 47, \"batches_seen\": 4089, \"train_examples_seen\": 130331, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:47:16.212 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.6023}, \"time_spent\": \"0:18:56\", \"epochs_done\": 48, \"batches_seen\": 4176, \"train_examples_seen\": 133104, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:47:22.773 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.625}, \"time_spent\": \"0:19:03\", \"epochs_done\": 48, \"batches_seen\": 4200, \"train_examples_seen\": 133872, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:47:38.283 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.6591}, \"time_spent\": \"0:19:18\", \"epochs_done\": 49, \"batches_seen\": 4263, \"train_examples_seen\": 135877, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:48:00.175 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.5682}, \"time_spent\": \"0:19:40\", \"epochs_done\": 50, \"batches_seen\": 4350, \"train_examples_seen\": 138650, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:48:21.864 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.5909}, \"time_spent\": \"0:20:02\", \"epochs_done\": 51, \"batches_seen\": 4437, \"train_examples_seen\": 141423, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:48:38.158 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.5909}, \"time_spent\": \"0:20:18\", \"epochs_done\": 51, \"batches_seen\": 4500, \"train_examples_seen\": 143428, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:48:43.786 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8961, \"accuracy\": 0.5682}, \"time_spent\": \"0:20:24\", \"epochs_done\": 52, \"batches_seen\": 4524, \"train_examples_seen\": 144196, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:49:05.556 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8908, \"accuracy\": 0.5682}, \"time_spent\": \"0:20:46\", \"epochs_done\": 53, \"batches_seen\": 4611, \"train_examples_seen\": 146969, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:49:27.361 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.5909}, \"time_spent\": \"0:21:07\", \"epochs_done\": 54, \"batches_seen\": 4698, \"train_examples_seen\": 149742, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:49:49.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8944, \"accuracy\": 0.5795}, \"time_spent\": \"0:21:29\", \"epochs_done\": 55, \"batches_seen\": 4785, \"train_examples_seen\": 152515, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:49:53.878 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6136}, \"time_spent\": \"0:21:34\", \"epochs_done\": 55, \"batches_seen\": 4800, \"train_examples_seen\": 152995, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:50:11.174 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6136}, \"time_spent\": \"0:21:51\", \"epochs_done\": 56, \"batches_seen\": 4872, \"train_examples_seen\": 155288, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:50:32.943 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n",
            "2022-05-23 14:50:32.953 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:50:35.734 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.6023}, \"time_spent\": \"0:22:13\", \"epochs_done\": 57, \"batches_seen\": 4959, \"train_examples_seen\": 158061, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:50:36.566 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-23 14:50:37.188 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/tag.dict]\n",
            "2022-05-23 14:50:51.399 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:50:53.162 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.919, \"accuracy\": 0.6477}, \"time_spent\": \"0:00:02\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:50:54.800 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/tag.dict]\n",
            "2022-05-23 14:51:11.116 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/fs_models/model_other/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:51:12.880 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline General"
      ],
      "metadata": {
        "id": "bhyIG3at48Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Scratch General Model to compare with"
      ],
      "metadata": {
        "id": "y2XkriFeXPqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_file = open('empty_file.txt', 'w') #take tokens apart from the ones in this file => all\n"
      ],
      "metadata": {
        "id": "0jV-yjM347qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/baseline'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{ROOT_PATH}/empty_file.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "base_config['chainer']['pipe'][1]['last'] = True #take all tokens"
      ],
      "metadata": {
        "id": "NwCGpbKVZ8Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_model(base_config, download=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD-XSLchbULm",
        "outputId": "d8ed275e-f14b-40a6-d8cd-fb5ca24185c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:51:32.209 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-23 14:51:32.604 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:51:50.17 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-23 14:51:51.363 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.0019, \"accuracy\": 0.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:52:16.61 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0019 to 0.3813\n",
            "2022-05-23 14:52:16.62 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:52:16.69 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.3813, \"accuracy\": 0.0}, \"time_spent\": \"0:00:27\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:52:42.119 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.3813 to 0.6128\n",
            "2022-05-23 14:52:42.120 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:52:42.127 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.6128, \"accuracy\": 0.0}, \"time_spent\": \"0:00:53\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:53:07.890 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6128 to 0.7023\n",
            "2022-05-23 14:53:07.891 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:53:07.899 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7023, \"accuracy\": 0.0455}, \"time_spent\": \"0:01:18\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:53:23.168 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7023 to 0.7198\n",
            "2022-05-23 14:53:23.169 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:53:23.180 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7198, \"accuracy\": 0.0568}, \"time_spent\": \"0:01:34\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9567, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:53:38.160 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7198 to 0.7481\n",
            "2022-05-23 14:53:38.161 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:53:38.171 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7481, \"accuracy\": 0.0682}, \"time_spent\": \"0:01:49\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:54:04.759 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7481 to 0.7821\n",
            "2022-05-23 14:54:04.760 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:54:04.766 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7821, \"accuracy\": 0.125}, \"time_spent\": \"0:02:15\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:54:30.407 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7821 to 0.8152\n",
            "2022-05-23 14:54:30.408 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:54:30.417 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8152, \"accuracy\": 0.1932}, \"time_spent\": \"0:02:41\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:54:54.176 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8152 to 0.8307\n",
            "2022-05-23 14:54:54.178 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:54:54.185 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8307, \"accuracy\": 0.2386}, \"time_spent\": \"0:03:05\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:55:00.617 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8249, \"accuracy\": 0.2386}, \"time_spent\": \"0:03:11\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:55:22.179 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8307 to 0.8356\n",
            "2022-05-23 14:55:22.180 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:55:22.187 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8356, \"accuracy\": 0.2614}, \"time_spent\": \"0:03:33\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:55:48.60 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8356 to 0.856\n",
            "2022-05-23 14:55:48.61 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:55:48.69 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.856, \"accuracy\": 0.2614}, \"time_spent\": \"0:03:59\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:56:14.601 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.856 to 0.8706\n",
            "2022-05-23 14:56:14.605 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:56:14.612 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8706, \"accuracy\": 0.3409}, \"time_spent\": \"0:04:25\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:56:26.296 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8599, \"accuracy\": 0.2955}, \"time_spent\": \"0:04:37\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28690, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:56:40.712 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8667, \"accuracy\": 0.3068}, \"time_spent\": \"0:04:51\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:57:02.150 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8609, \"accuracy\": 0.2841}, \"time_spent\": \"0:05:13\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:57:23.355 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8706 to 0.8755\n",
            "2022-05-23 14:57:23.356 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:57:23.364 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8755, \"accuracy\": 0.3068}, \"time_spent\": \"0:05:34\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:57:44.394 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8755 to 0.8833\n",
            "2022-05-23 14:57:44.398 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:57:44.403 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8833, \"accuracy\": 0.3409}, \"time_spent\": \"0:05:55\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38257, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:57:53.659 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8784, \"accuracy\": 0.3182}, \"time_spent\": \"0:06:04\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:58:15.759 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8794, \"accuracy\": 0.3409}, \"time_spent\": \"0:06:26\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:58:37.175 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8833 to 0.8862\n",
            "2022-05-23 14:58:37.176 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:58:37.183 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8862, \"accuracy\": 0.3295}, \"time_spent\": \"0:06:48\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:59:02.760 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8862, \"accuracy\": 0.3409}, \"time_spent\": \"0:07:13\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:59:08.526 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8862 to 0.8872\n",
            "2022-05-23 14:59:08.528 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:59:08.535 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8872, \"accuracy\": 0.3523}, \"time_spent\": \"0:07:19\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47813, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:59:29.421 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8872 to 0.8911\n",
            "2022-05-23 14:59:29.422 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:59:29.429 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8911, \"accuracy\": 0.3636}, \"time_spent\": \"0:07:40\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 14:59:55.378 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8911 to 0.8959\n",
            "2022-05-23 14:59:55.379 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 14:59:55.386 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8959, \"accuracy\": 0.3523}, \"time_spent\": \"0:08:06\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:00:21.745 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8911, \"accuracy\": 0.3523}, \"time_spent\": \"0:08:32\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:00:36.672 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8959 to 0.8988\n",
            "2022-05-23 15:00:36.676 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 15:00:36.682 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8988, \"accuracy\": 0.3409}, \"time_spent\": \"0:08:47\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57380, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:00:47.813 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8852, \"accuracy\": 0.3295}, \"time_spent\": \"0:08:58\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:01:09.443 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3636}, \"time_spent\": \"0:09:20\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:01:30.847 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.375}, \"time_spent\": \"0:09:41\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:01:52.176 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3636}, \"time_spent\": \"0:10:03\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:01:56.750 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8911, \"accuracy\": 0.3523}, \"time_spent\": \"0:10:07\", \"epochs_done\": 24, \"batches_seen\": 2100, \"train_examples_seen\": 66936, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:02:13.753 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8988, \"accuracy\": 0.4091}, \"time_spent\": \"0:10:24\", \"epochs_done\": 25, \"batches_seen\": 2175, \"train_examples_seen\": 69325, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:02:35.118 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.892, \"accuracy\": 0.375}, \"time_spent\": \"0:10:46\", \"epochs_done\": 26, \"batches_seen\": 2262, \"train_examples_seen\": 72098, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:02:56.534 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.892, \"accuracy\": 0.3636}, \"time_spent\": \"0:11:07\", \"epochs_done\": 27, \"batches_seen\": 2349, \"train_examples_seen\": 74871, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:03:09.54 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8891, \"accuracy\": 0.3523}, \"time_spent\": \"0:11:20\", \"epochs_done\": 27, \"batches_seen\": 2400, \"train_examples_seen\": 76503, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:03:18.119 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.3636}, \"time_spent\": \"0:11:29\", \"epochs_done\": 28, \"batches_seen\": 2436, \"train_examples_seen\": 77644, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:03:39.458 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8959, \"accuracy\": 0.3636}, \"time_spent\": \"0:11:50\", \"epochs_done\": 29, \"batches_seen\": 2523, \"train_examples_seen\": 80417, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:04:00.818 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8988 to 0.9027\n",
            "2022-05-23 15:04:00.822 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 15:04:00.827 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9027, \"accuracy\": 0.4091}, \"time_spent\": \"0:12:11\", \"epochs_done\": 30, \"batches_seen\": 2610, \"train_examples_seen\": 83190, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:04:27.329 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.3977}, \"time_spent\": \"0:12:38\", \"epochs_done\": 31, \"batches_seen\": 2697, \"train_examples_seen\": 85963, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:04:28.806 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8959, \"accuracy\": 0.3864}, \"time_spent\": \"0:12:39\", \"epochs_done\": 31, \"batches_seen\": 2700, \"train_examples_seen\": 86059, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:04:49.97 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.3864}, \"time_spent\": \"0:13:00\", \"epochs_done\": 32, \"batches_seen\": 2784, \"train_examples_seen\": 88736, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:05:10.488 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.893, \"accuracy\": 0.3864}, \"time_spent\": \"0:13:21\", \"epochs_done\": 33, \"batches_seen\": 2871, \"train_examples_seen\": 91509, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:05:31.830 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3977}, \"time_spent\": \"0:13:42\", \"epochs_done\": 34, \"batches_seen\": 2958, \"train_examples_seen\": 94282, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:05:42.160 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8881, \"accuracy\": 0.3636}, \"time_spent\": \"0:13:53\", \"epochs_done\": 34, \"batches_seen\": 3000, \"train_examples_seen\": 95626, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:05:53.432 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8998, \"accuracy\": 0.375}, \"time_spent\": \"0:14:04\", \"epochs_done\": 35, \"batches_seen\": 3045, \"train_examples_seen\": 97055, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:06:14.811 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9008, \"accuracy\": 0.4318}, \"time_spent\": \"0:14:25\", \"epochs_done\": 36, \"batches_seen\": 3132, \"train_examples_seen\": 99828, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:06:36.193 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3864}, \"time_spent\": \"0:14:47\", \"epochs_done\": 37, \"batches_seen\": 3219, \"train_examples_seen\": 102601, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:06:56.338 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8911, \"accuracy\": 0.4205}, \"time_spent\": \"0:15:07\", \"epochs_done\": 37, \"batches_seen\": 3300, \"train_examples_seen\": 105182, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:06:57.819 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.892, \"accuracy\": 0.4205}, \"time_spent\": \"0:15:08\", \"epochs_done\": 38, \"batches_seen\": 3306, \"train_examples_seen\": 105374, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:07:19.162 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.4318}, \"time_spent\": \"0:15:30\", \"epochs_done\": 39, \"batches_seen\": 3393, \"train_examples_seen\": 108147, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:07:40.521 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.4205}, \"time_spent\": \"0:15:51\", \"epochs_done\": 40, \"batches_seen\": 3480, \"train_examples_seen\": 110920, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:08:01.955 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.4318}, \"time_spent\": \"0:16:12\", \"epochs_done\": 41, \"batches_seen\": 3567, \"train_examples_seen\": 113693, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:08:11.383 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.893, \"accuracy\": 0.3636}, \"time_spent\": \"0:16:22\", \"epochs_done\": 41, \"batches_seen\": 3600, \"train_examples_seen\": 114738, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:08:23.673 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3977}, \"time_spent\": \"0:16:34\", \"epochs_done\": 42, \"batches_seen\": 3654, \"train_examples_seen\": 116466, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:08:45.158 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8881, \"accuracy\": 0.3409}, \"time_spent\": \"0:16:56\", \"epochs_done\": 43, \"batches_seen\": 3741, \"train_examples_seen\": 119239, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:09:06.616 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.3977}, \"time_spent\": \"0:17:17\", \"epochs_done\": 44, \"batches_seen\": 3828, \"train_examples_seen\": 122012, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:09:23.952 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.4091}, \"time_spent\": \"0:17:34\", \"epochs_done\": 44, \"batches_seen\": 3900, \"train_examples_seen\": 124305, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:09:28.226 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.3636}, \"time_spent\": \"0:17:39\", \"epochs_done\": 45, \"batches_seen\": 3915, \"train_examples_seen\": 124785, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:09:49.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.4091}, \"time_spent\": \"0:18:00\", \"epochs_done\": 46, \"batches_seen\": 4002, \"train_examples_seen\": 127558, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:10:10.935 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.892, \"accuracy\": 0.3977}, \"time_spent\": \"0:18:21\", \"epochs_done\": 47, \"batches_seen\": 4089, \"train_examples_seen\": 130331, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:10:32.271 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8969, \"accuracy\": 0.4205}, \"time_spent\": \"0:18:43\", \"epochs_done\": 48, \"batches_seen\": 4176, \"train_examples_seen\": 133104, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:10:38.986 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8901, \"accuracy\": 0.3977}, \"time_spent\": \"0:18:49\", \"epochs_done\": 48, \"batches_seen\": 4200, \"train_examples_seen\": 133872, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:10:53.886 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3864}, \"time_spent\": \"0:19:04\", \"epochs_done\": 49, \"batches_seen\": 4263, \"train_examples_seen\": 135877, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:11:15.261 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8979, \"accuracy\": 0.4318}, \"time_spent\": \"0:19:26\", \"epochs_done\": 50, \"batches_seen\": 4350, \"train_examples_seen\": 138650, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:11:36.665 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8901, \"accuracy\": 0.375}, \"time_spent\": \"0:19:47\", \"epochs_done\": 51, \"batches_seen\": 4437, \"train_examples_seen\": 141423, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:11:51.826 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3864}, \"time_spent\": \"0:20:02\", \"epochs_done\": 51, \"batches_seen\": 4500, \"train_examples_seen\": 143439, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:11:58.272 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.894, \"accuracy\": 0.3864}, \"time_spent\": \"0:20:09\", \"epochs_done\": 52, \"batches_seen\": 4524, \"train_examples_seen\": 144196, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:12:19.686 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9027\n",
            "2022-05-23 15:12:19.703 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:12:22.492 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8852, \"accuracy\": 0.3409}, \"time_spent\": \"0:20:30\", \"epochs_done\": 53, \"batches_seen\": 4611, \"train_examples_seen\": 146969, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:12:23.272 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-23 15:12:23.861 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/tag.dict]\n",
            "2022-05-23 15:12:38.28 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:12:39.922 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9027, \"accuracy\": 0.4091}, \"time_spent\": \"0:00:02\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:12:41.518 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/tag.dict]\n",
            "2022-05-23 15:12:59.759 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:13:01.655 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FineTune Models"
      ],
      "metadata": {
        "id": "6OGAEZQpBVZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load baseline general model and fit it on groups separately"
      ],
      "metadata": {
        "id": "pXFjfVeTSdzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_config['chainer']['pipe'][3]['load_path'] = '{MODELS_PATH}/baseline/model'"
      ],
      "metadata": {
        "id": "HQVGHaTTTdJt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top100 "
      ],
      "metadata": {
        "id": "4KxssxMlvDsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_top100'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "LrDJnvqMrgAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAVNphDswarw",
        "outputId": "f60447c0-b4f0-4a5b-f7e9-51863e888486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:13:43.873 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-23 15:13:44.245 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top100/tag.dict]\n",
            "2022-05-23 15:14:02.336 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:14:04.187 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-23 15:14:05.401 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7955}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:14:30.250 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:00:27\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:14:51.731 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7727}, \"time_spent\": \"0:00:48\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:15:13.63 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7727}, \"time_spent\": \"0:01:09\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:15:23.210 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7841}, \"time_spent\": \"0:01:20\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9567, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:15:34.295 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7727}, \"time_spent\": \"0:01:31\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:15:55.430 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7841}, \"time_spent\": \"0:01:52\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:16:16.692 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7614}, \"time_spent\": \"0:02:13\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:16:35.576 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.75}, \"time_spent\": \"0:02:32\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:16:38.223 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:02:35\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:16:59.400 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:02:56\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:17:20.490 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:03:17\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:17:41.629 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7273}, \"time_spent\": \"0:03:38\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:17:49.662 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.75}, \"time_spent\": \"0:03:46\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28679, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:18:02.979 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7727}, \"time_spent\": \"0:03:59\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:18:24.137 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:04:20\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:18:45.339 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7727}, \"time_spent\": \"0:04:42\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:19:02.360 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:04:59\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38246, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:19:06.727 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7841}, \"time_spent\": \"0:05:03\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:19:27.897 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.7727}, \"time_spent\": \"0:05:24\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:19:49.69 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7727}, \"time_spent\": \"0:05:45\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:20:10.197 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9112 to 0.9145\n",
            "2022-05-23 15:20:10.198 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 15:20:10.211 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9145, \"accuracy\": 0.7955}, \"time_spent\": \"0:06:07\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:20:20.256 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:06:17\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47813, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:20:35.846 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7727}, \"time_spent\": \"0:06:32\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:20:57.115 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7386}, \"time_spent\": \"0:06:53\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:21:18.267 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7614}, \"time_spent\": \"0:07:15\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:21:34.346 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.75}, \"time_spent\": \"0:07:31\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57369, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:21:39.798 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.7273}, \"time_spent\": \"0:07:36\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:22:01.90 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:07:57\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:22:22.283 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9145, \"accuracy\": 0.7841}, \"time_spent\": \"0:08:19\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:22:43.460 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.75}, \"time_spent\": \"0:08:40\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:22:46.791 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8882, \"accuracy\": 0.7159}, \"time_spent\": \"0:08:43\", \"epochs_done\": 24, \"batches_seen\": 2100, \"train_examples_seen\": 66936, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:23:05.1 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9145, \"accuracy\": 0.7955}, \"time_spent\": \"0:09:01\", \"epochs_done\": 25, \"batches_seen\": 2175, \"train_examples_seen\": 69325, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:23:26.258 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7841}, \"time_spent\": \"0:09:23\", \"epochs_done\": 26, \"batches_seen\": 2262, \"train_examples_seen\": 72098, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:23:47.539 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9145 to 0.9211\n",
            "2022-05-23 15:23:47.540 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 15:23:47.547 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top100/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9211, \"accuracy\": 0.8182}, \"time_spent\": \"0:09:44\", \"epochs_done\": 27, \"batches_seen\": 2349, \"train_examples_seen\": 74871, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:24:04.799 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:10:01\", \"epochs_done\": 27, \"batches_seen\": 2400, \"train_examples_seen\": 76492, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:24:13.270 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7727}, \"time_spent\": \"0:10:10\", \"epochs_done\": 28, \"batches_seen\": 2436, \"train_examples_seen\": 77644, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:24:34.516 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:10:31\", \"epochs_done\": 29, \"batches_seen\": 2523, \"train_examples_seen\": 80417, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:24:55.710 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7727}, \"time_spent\": \"0:10:52\", \"epochs_done\": 30, \"batches_seen\": 2610, \"train_examples_seen\": 83190, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:25:16.954 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.75}, \"time_spent\": \"0:11:13\", \"epochs_done\": 31, \"batches_seen\": 2697, \"train_examples_seen\": 85963, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:25:18.237 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.75}, \"time_spent\": \"0:11:15\", \"epochs_done\": 31, \"batches_seen\": 2700, \"train_examples_seen\": 86059, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:25:38.313 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:35\", \"epochs_done\": 32, \"batches_seen\": 2784, \"train_examples_seen\": 88736, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:25:59.450 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7273}, \"time_spent\": \"0:11:56\", \"epochs_done\": 33, \"batches_seen\": 2871, \"train_examples_seen\": 91509, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:26:20.569 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:12:17\", \"epochs_done\": 34, \"batches_seen\": 2958, \"train_examples_seen\": 94282, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:26:30.778 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7386}, \"time_spent\": \"0:12:27\", \"epochs_done\": 34, \"batches_seen\": 3000, \"train_examples_seen\": 95615, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:26:42.59 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9112, \"accuracy\": 0.7614}, \"time_spent\": \"0:12:38\", \"epochs_done\": 35, \"batches_seen\": 3045, \"train_examples_seen\": 97055, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:27:03.319 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:13:00\", \"epochs_done\": 36, \"batches_seen\": 3132, \"train_examples_seen\": 99828, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:27:24.528 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7386}, \"time_spent\": \"0:13:21\", \"epochs_done\": 37, \"batches_seen\": 3219, \"train_examples_seen\": 102601, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:27:43.974 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:13:40\", \"epochs_done\": 37, \"batches_seen\": 3300, \"train_examples_seen\": 105182, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:27:45.965 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.75}, \"time_spent\": \"0:13:42\", \"epochs_done\": 38, \"batches_seen\": 3306, \"train_examples_seen\": 105374, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:28:07.120 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:14:03\", \"epochs_done\": 39, \"batches_seen\": 3393, \"train_examples_seen\": 108147, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:28:28.291 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:14:25\", \"epochs_done\": 40, \"batches_seen\": 3480, \"train_examples_seen\": 110920, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:28:49.567 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.7386}, \"time_spent\": \"0:14:46\", \"epochs_done\": 41, \"batches_seen\": 3567, \"train_examples_seen\": 113693, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:28:58.404 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9046, \"accuracy\": 0.75}, \"time_spent\": \"0:14:55\", \"epochs_done\": 41, \"batches_seen\": 3600, \"train_examples_seen\": 114749, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:29:11.16 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.898, \"accuracy\": 0.7386}, \"time_spent\": \"0:15:07\", \"epochs_done\": 42, \"batches_seen\": 3654, \"train_examples_seen\": 116466, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:29:32.183 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8947, \"accuracy\": 0.75}, \"time_spent\": \"0:15:28\", \"epochs_done\": 43, \"batches_seen\": 3741, \"train_examples_seen\": 119239, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:29:53.322 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9145, \"accuracy\": 0.7841}, \"time_spent\": \"0:15:50\", \"epochs_done\": 44, \"batches_seen\": 3828, \"train_examples_seen\": 122012, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:30:10.424 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9079, \"accuracy\": 0.7614}, \"time_spent\": \"0:16:07\", \"epochs_done\": 44, \"batches_seen\": 3900, \"train_examples_seen\": 124305, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:30:14.779 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7614}, \"time_spent\": \"0:16:11\", \"epochs_done\": 45, \"batches_seen\": 3915, \"train_examples_seen\": 124785, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:30:36.67 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7614}, \"time_spent\": \"0:16:32\", \"epochs_done\": 46, \"batches_seen\": 4002, \"train_examples_seen\": 127558, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 15:30:57.330 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9013, \"accuracy\": 0.7614}, \"time_spent\": \"0:16:54\", \"epochs_done\": 47, \"batches_seen\": 4089, \"train_examples_seen\": 130331, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top1000"
      ],
      "metadata": {
        "id": "mpMTEudm7d9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_top1000'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "base_config['chainer']['pipe'][1]['last'] = False"
      ],
      "metadata": {
        "id": "Fg97uNC57dvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj99XN_z7l7C",
        "outputId": "e2a2c4b7-2df2-43d8-f8a4-0f6e4bc69618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:01:33.233 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-23 03:01:33.609 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-23 03:01:33.644 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-23 03:01:52.436 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:01:54.245 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-23 03:01:55.412 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:02:19.707 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7159}, \"time_spent\": \"0:00:26\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:02:40.806 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7159}, \"time_spent\": \"0:00:47\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:03:02.58 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7045}, \"time_spent\": \"0:01:08\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:03:12.359 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7045}, \"time_spent\": \"0:01:19\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9567, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:03:23.668 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7159}, \"time_spent\": \"0:01:30\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:03:45.120 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8077 to 0.8141\n",
            "2022-05-23 03:03:45.122 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 03:03:45.129 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7273}, \"time_spent\": \"0:01:51\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:04:10.930 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7159}, \"time_spent\": \"0:02:17\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:04:30.844 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7885, \"accuracy\": 0.7159}, \"time_spent\": \"0:02:37\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:04:32.742 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7821, \"accuracy\": 0.7159}, \"time_spent\": \"0:02:39\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:04:54.490 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:03:01\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:05:16.296 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:03:23\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:05:38.122 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:03:44\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:05:45.486 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.7949, \"accuracy\": 0.7159}, \"time_spent\": \"0:03:52\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28690, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:06:00.351 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8141 to 0.8269\n",
            "2022-05-23 03:06:00.352 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 03:06:00.358 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:04:07\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:06:26.455 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:04:33\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:06:48.334 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:04:55\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:07:04.627 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:05:11\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38246, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:07:10.535 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8269 to 0.8333\n",
            "2022-05-23 03:07:10.537 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 03:07:10.544 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7614}, \"time_spent\": \"0:05:17\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:07:36.648 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:05:43\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:07:58.579 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:06:05\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:08:20.511 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:06:27\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:08:26.962 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:06:33\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47813, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:08:42.740 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:06:49\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:09:04.707 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:07:11\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:09:26.694 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.75}, \"time_spent\": \"0:07:33\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:09:41.245 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:07:47\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57380, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:09:48.938 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:07:55\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:10:10.889 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:08:17\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:10:32.812 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:08:39\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:10:54.781 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:09:01\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:10:58.24 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7614}, \"time_spent\": \"0:09:04\", \"epochs_done\": 24, \"batches_seen\": 2100, \"train_examples_seen\": 66936, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:11:16.968 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:09:23\", \"epochs_done\": 25, \"batches_seen\": 2175, \"train_examples_seen\": 69325, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:11:38.983 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:09:45\", \"epochs_done\": 26, \"batches_seen\": 2262, \"train_examples_seen\": 72098, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:12:00.971 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:10:07\", \"epochs_done\": 27, \"batches_seen\": 2349, \"train_examples_seen\": 74871, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:12:13.387 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:10:20\", \"epochs_done\": 27, \"batches_seen\": 2400, \"train_examples_seen\": 76503, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:12:23.130 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.7386}, \"time_spent\": \"0:10:29\", \"epochs_done\": 28, \"batches_seen\": 2436, \"train_examples_seen\": 77644, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:12:45.108 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:10:51\", \"epochs_done\": 29, \"batches_seen\": 2523, \"train_examples_seen\": 80417, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:13:07.71 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8333 to 0.8397\n",
            "2022-05-23 03:13:07.73 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n",
            "2022-05-23 03:13:07.81 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8397, \"accuracy\": 0.7614}, \"time_spent\": \"0:11:13\", \"epochs_done\": 30, \"batches_seen\": 2610, \"train_examples_seen\": 83190, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:13:33.284 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:40\", \"epochs_done\": 31, \"batches_seen\": 2697, \"train_examples_seen\": 85963, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:13:34.990 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.7386}, \"time_spent\": \"0:11:41\", \"epochs_done\": 31, \"batches_seen\": 2700, \"train_examples_seen\": 86059, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:13:55.747 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7386}, \"time_spent\": \"0:12:02\", \"epochs_done\": 32, \"batches_seen\": 2784, \"train_examples_seen\": 88736, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:14:17.696 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:12:24\", \"epochs_done\": 33, \"batches_seen\": 2871, \"train_examples_seen\": 91509, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:14:39.588 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:12:46\", \"epochs_done\": 34, \"batches_seen\": 2958, \"train_examples_seen\": 94282, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:14:49.798 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:12:56\", \"epochs_done\": 34, \"batches_seen\": 3000, \"train_examples_seen\": 95626, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:15:01.804 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7273}, \"time_spent\": \"0:13:08\", \"epochs_done\": 35, \"batches_seen\": 3045, \"train_examples_seen\": 97055, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:15:23.795 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7159}, \"time_spent\": \"0:13:30\", \"epochs_done\": 36, \"batches_seen\": 3132, \"train_examples_seen\": 99828, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:15:45.760 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:13:52\", \"epochs_done\": 37, \"batches_seen\": 3219, \"train_examples_seen\": 102601, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:16:06.277 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.75}, \"time_spent\": \"0:14:13\", \"epochs_done\": 37, \"batches_seen\": 3300, \"train_examples_seen\": 105182, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:16:07.964 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:14:14\", \"epochs_done\": 38, \"batches_seen\": 3306, \"train_examples_seen\": 105374, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:16:29.932 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.75}, \"time_spent\": \"0:14:36\", \"epochs_done\": 39, \"batches_seen\": 3393, \"train_examples_seen\": 108147, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:16:51.914 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.75}, \"time_spent\": \"0:14:58\", \"epochs_done\": 40, \"batches_seen\": 3480, \"train_examples_seen\": 110920, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:17:13.912 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7727}, \"time_spent\": \"0:15:20\", \"epochs_done\": 41, \"batches_seen\": 3567, \"train_examples_seen\": 113693, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:17:22.503 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7727}, \"time_spent\": \"0:15:29\", \"epochs_done\": 41, \"batches_seen\": 3600, \"train_examples_seen\": 114738, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:17:36.139 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8397, \"accuracy\": 0.7727}, \"time_spent\": \"0:15:42\", \"epochs_done\": 42, \"batches_seen\": 3654, \"train_examples_seen\": 116466, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:17:58.107 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.75}, \"time_spent\": \"0:16:04\", \"epochs_done\": 43, \"batches_seen\": 3741, \"train_examples_seen\": 119239, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:18:20.130 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8141, \"accuracy\": 0.75}, \"time_spent\": \"0:16:26\", \"epochs_done\": 44, \"batches_seen\": 3828, \"train_examples_seen\": 122012, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:18:38.360 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:16:45\", \"epochs_done\": 44, \"batches_seen\": 3900, \"train_examples_seen\": 124305, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:18:42.357 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8333, \"accuracy\": 0.7614}, \"time_spent\": \"0:16:49\", \"epochs_done\": 45, \"batches_seen\": 3915, \"train_examples_seen\": 124785, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:19:04.281 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:17:11\", \"epochs_done\": 46, \"batches_seen\": 4002, \"train_examples_seen\": 127558, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:19:26.267 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8397, \"accuracy\": 0.7841}, \"time_spent\": \"0:17:33\", \"epochs_done\": 47, \"batches_seen\": 4089, \"train_examples_seen\": 130331, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:19:48.235 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:17:54\", \"epochs_done\": 48, \"batches_seen\": 4176, \"train_examples_seen\": 133104, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:19:55.288 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.75}, \"time_spent\": \"0:18:02\", \"epochs_done\": 48, \"batches_seen\": 4200, \"train_examples_seen\": 133872, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:20:10.458 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.7614}, \"time_spent\": \"0:18:17\", \"epochs_done\": 49, \"batches_seen\": 4263, \"train_examples_seen\": 135877, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:20:32.394 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8013, \"accuracy\": 0.7159}, \"time_spent\": \"0:18:39\", \"epochs_done\": 50, \"batches_seen\": 4350, \"train_examples_seen\": 138650, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:20:54.355 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8205, \"accuracy\": 0.7386}, \"time_spent\": \"0:19:01\", \"epochs_done\": 51, \"batches_seen\": 4437, \"train_examples_seen\": 141423, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:21:11.624 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:19:18\", \"epochs_done\": 51, \"batches_seen\": 4500, \"train_examples_seen\": 143428, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:21:16.580 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:19:23\", \"epochs_done\": 52, \"batches_seen\": 4524, \"train_examples_seen\": 144196, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:21:38.533 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8397\n",
            "2022-05-23 03:21:38.543 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:21:40.989 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8269, \"accuracy\": 0.75}, \"time_spent\": \"0:19:45\", \"epochs_done\": 53, \"batches_seen\": 4611, \"train_examples_seen\": 146969, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:21:41.543 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-23 03:21:42.54 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-23 03:21:42.66 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model' differs from save path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model' in 'infer' mode for MyBertSequenceTagger.\n",
            "2022-05-23 03:21:57.393 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:21:59.216 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8077, \"accuracy\": 0.7273}, \"time_spent\": \"0:00:02\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:22:00.801 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/tag.dict]\n",
            "2022-05-23 03:22:17.662 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_top1000/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-23 03:22:19.477 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top1000+"
      ],
      "metadata": {
        "id": "txfdOKICAuMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### dir for my models\n",
        "base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_other'\n",
        "base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt', '{MODELS_PATH}/freq_groups/1.txt']\n",
        "base_config['train']['validation_patience'] = 30\n",
        "base_config['train']['epochs'] = 60\n",
        "base_config['chainer']['pipe'][1]['last'] = True"
      ],
      "metadata": {
        "id": "OTIym1LtAwdv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(base_config, download=False)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPRnK0N5A24R",
        "outputId": "74a962e9-3976-4202-8f03-3da1c78edb28"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:23:47.213 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2022-05-24 04:23:47.594 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_other/tag.dict]\n",
            "2022-05-24 04:23:47.630 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_other/tag.dict]\n",
            "2022-05-24 04:24:01.438 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:24:03.239 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2022-05-24 04:24:04.372 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.919, \"accuracy\": 0.6477}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:24:28.249 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.6136}, \"time_spent\": \"0:00:25\", \"epochs_done\": 1, \"batches_seen\": 87, \"train_examples_seen\": 2773, \"impatience\": 1, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:24:48.848 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6136}, \"time_spent\": \"0:00:46\", \"epochs_done\": 2, \"batches_seen\": 174, \"train_examples_seen\": 5546, \"impatience\": 2, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:25:09.710 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.625}, \"time_spent\": \"0:01:07\", \"epochs_done\": 3, \"batches_seen\": 261, \"train_examples_seen\": 8319, \"impatience\": 3, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:25:19.748 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6364}, \"time_spent\": \"0:01:17\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 9556, \"impatience\": 4, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:25:31.258 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.5909}, \"time_spent\": \"0:01:29\", \"epochs_done\": 4, \"batches_seen\": 348, \"train_examples_seen\": 11092, \"impatience\": 5, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:25:52.814 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.6477}, \"time_spent\": \"0:01:50\", \"epochs_done\": 5, \"batches_seen\": 435, \"train_examples_seen\": 13865, \"impatience\": 6, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:26:14.756 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.6136}, \"time_spent\": \"0:02:12\", \"epochs_done\": 6, \"batches_seen\": 522, \"train_examples_seen\": 16638, \"impatience\": 7, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:26:33.470 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.5909}, \"time_spent\": \"0:02:31\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 19123, \"impatience\": 8, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:26:37.161 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9155, \"accuracy\": 0.6477}, \"time_spent\": \"0:02:34\", \"epochs_done\": 7, \"batches_seen\": 609, \"train_examples_seen\": 19411, \"impatience\": 9, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:26:59.200 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9014, \"accuracy\": 0.5909}, \"time_spent\": \"0:02:56\", \"epochs_done\": 8, \"batches_seen\": 696, \"train_examples_seen\": 22184, \"impatience\": 10, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:27:21.172 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6136}, \"time_spent\": \"0:03:18\", \"epochs_done\": 9, \"batches_seen\": 783, \"train_examples_seen\": 24957, \"impatience\": 11, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:27:43.169 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9155, \"accuracy\": 0.6818}, \"time_spent\": \"0:03:40\", \"epochs_done\": 10, \"batches_seen\": 870, \"train_examples_seen\": 27730, \"impatience\": 12, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:27:50.401 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.912, \"accuracy\": 0.625}, \"time_spent\": \"0:03:48\", \"epochs_done\": 10, \"batches_seen\": 900, \"train_examples_seen\": 28690, \"impatience\": 13, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:28:05.568 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8996, \"accuracy\": 0.6136}, \"time_spent\": \"0:04:03\", \"epochs_done\": 11, \"batches_seen\": 957, \"train_examples_seen\": 30503, \"impatience\": 14, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:28:27.585 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.912, \"accuracy\": 0.6591}, \"time_spent\": \"0:04:25\", \"epochs_done\": 12, \"batches_seen\": 1044, \"train_examples_seen\": 33276, \"impatience\": 15, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:28:49.617 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.6136}, \"time_spent\": \"0:04:47\", \"epochs_done\": 13, \"batches_seen\": 1131, \"train_examples_seen\": 36049, \"impatience\": 16, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:29:07.544 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6591}, \"time_spent\": \"0:05:05\", \"epochs_done\": 13, \"batches_seen\": 1200, \"train_examples_seen\": 38246, \"impatience\": 17, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:29:11.861 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.6364}, \"time_spent\": \"0:05:09\", \"epochs_done\": 14, \"batches_seen\": 1218, \"train_examples_seen\": 38822, \"impatience\": 18, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:29:33.920 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.6364}, \"time_spent\": \"0:05:31\", \"epochs_done\": 15, \"batches_seen\": 1305, \"train_examples_seen\": 41595, \"impatience\": 19, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:29:55.870 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.912, \"accuracy\": 0.6477}, \"time_spent\": \"0:05:53\", \"epochs_done\": 16, \"batches_seen\": 1392, \"train_examples_seen\": 44368, \"impatience\": 20, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:30:17.851 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.6477}, \"time_spent\": \"0:06:15\", \"epochs_done\": 17, \"batches_seen\": 1479, \"train_examples_seen\": 47141, \"impatience\": 21, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:30:23.462 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9049, \"accuracy\": 0.6477}, \"time_spent\": \"0:06:21\", \"epochs_done\": 17, \"batches_seen\": 1500, \"train_examples_seen\": 47802, \"impatience\": 22, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:30:40.191 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9067, \"accuracy\": 0.6023}, \"time_spent\": \"0:06:37\", \"epochs_done\": 18, \"batches_seen\": 1566, \"train_examples_seen\": 49914, \"impatience\": 23, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:31:02.136 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.625}, \"time_spent\": \"0:06:59\", \"epochs_done\": 19, \"batches_seen\": 1653, \"train_examples_seen\": 52687, \"impatience\": 24, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:31:24.118 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9085, \"accuracy\": 0.6023}, \"time_spent\": \"0:07:21\", \"epochs_done\": 20, \"batches_seen\": 1740, \"train_examples_seen\": 55460, \"impatience\": 25, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:31:40.325 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9032, \"accuracy\": 0.625}, \"time_spent\": \"0:07:38\", \"epochs_done\": 20, \"batches_seen\": 1800, \"train_examples_seen\": 57369, \"impatience\": 26, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:31:46.402 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9102, \"accuracy\": 0.6591}, \"time_spent\": \"0:07:44\", \"epochs_done\": 21, \"batches_seen\": 1827, \"train_examples_seen\": 58233, \"impatience\": 27, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:32:08.400 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9173, \"accuracy\": 0.6705}, \"time_spent\": \"0:08:06\", \"epochs_done\": 22, \"batches_seen\": 1914, \"train_examples_seen\": 61006, \"impatience\": 28, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:32:30.496 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.9102, \"accuracy\": 0.6136}, \"time_spent\": \"0:08:28\", \"epochs_done\": 23, \"batches_seen\": 2001, \"train_examples_seen\": 63779, \"impatience\": 29, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:32:52.441 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.919\n",
            "2022-05-24 04:32:52.948 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.8944, \"accuracy\": 0.5909}, \"time_spent\": \"0:08:50\", \"epochs_done\": 24, \"batches_seen\": 2088, \"train_examples_seen\": 66552, \"impatience\": 30, \"patience_limit\": 30}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:32:53.471 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n",
            "2022-05-24 04:32:53.950 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_other/tag.dict]\n",
            "2022-05-24 04:32:53.962 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model' differs from save path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_other/model' in 'infer' mode for MyBertSequenceTagger.\n",
            "2022-05-24 04:33:10.154 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/baseline/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:33:11.911 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 88, \"metrics\": {\"per_token_accuracy\": 0.919, \"accuracy\": 0.6477}, \"time_spent\": \"0:00:02\"}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:33:13.512 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_social/finetuned_models/model_other/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-24 04:33:31.107 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IUjZMZXtb89p",
        "89m2jMJMcJky",
        "EGRf5xGxcaHF",
        "YGxpVfS4ccbj",
        "Br3NWTQEcnXL",
        "bb-UPIUPczCA",
        "hcMJpEuZLzPh",
        "Qa0czko8L2Iv",
        "rrMdYc1dG7eO",
        "_6HdtWbaGTiY",
        "msN4Q1KmT5Za",
        "DavKW8gHT1vg",
        "jjcuynC5jpoi",
        "bhyIG3at48Wp",
        "mpMTEudm7d9j",
        "txfdOKICAuMK"
      ],
      "name": "GramEval_social_main_2305.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}