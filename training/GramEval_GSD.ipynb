{"cells":[{"cell_type":"markdown","source":["# Packages"],"metadata":{"id":"IUjZMZXtb89p"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"QmES4yFcEMAc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1653442714148,"user_tz":-180,"elapsed":56640,"user":{"displayName":"Zhenya Egorova","userId":"03866717224318332006"}},"outputId":"548202ae-2b4c-4367-f295-4b69f8e01d10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deeppavlov\n","  Downloading deeppavlov-0.17.3-py3-none-any.whl (878 kB)\n","\u001b[K     |████████████████████████████████| 878 kB 7.1 MB/s \n","\u001b[?25hCollecting requests==2.22.0\n","  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 6.5 MB/s \n","\u001b[?25hCollecting fastapi==0.47.1\n","  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[?25hCollecting pydantic==1.3\n","  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n","\u001b[K     |████████████████████████████████| 7.3 MB 19.8 MB/s \n","\u001b[?25hCollecting pymorphy2==0.8\n","  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 4.2 MB/s \n","\u001b[?25hCollecting overrides==2.7.0\n","  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n","Collecting pandas==0.25.3\n","  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 52.2 MB/s \n","\u001b[?25hCollecting uvloop==0.14.0\n","  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 57.5 MB/s \n","\u001b[?25hCollecting prometheus-client==0.7.1\n","  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n","Collecting filelock==3.0.12\n","  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n","Collecting Cython==0.29.14\n","  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 49.1 MB/s \n","\u001b[?25hCollecting ruamel.yaml==0.15.100\n","  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n","\u001b[K     |████████████████████████████████| 654 kB 53.7 MB/s \n","\u001b[?25hCollecting sacremoses==0.0.35\n","  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n","\u001b[K     |████████████████████████████████| 859 kB 56.9 MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.2\n","  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n","\u001b[K     |████████████████████████████████| 6.7 MB 31.7 MB/s \n","\u001b[?25hCollecting nltk==3.4.5\n","  Downloading nltk-3.4.5.zip (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 21.4 MB/s \n","\u001b[?25hCollecting numpy==1.18.0\n","  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 62.0 MB/s \n","\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n","Collecting tqdm==4.62.0\n","  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 4.6 MB/s \n","\u001b[?25hCollecting rusenttokenize==0.0.5\n","  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n","Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 40.8 MB/s \n","\u001b[?25hCollecting pytz==2019.1\n","  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n","\u001b[K     |████████████████████████████████| 510 kB 2.7 MB/s \n","\u001b[?25hCollecting pytelegrambotapi==3.6.7\n","  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 4.6 MB/s \n","\u001b[?25hCollecting pymorphy2-dicts-ru\n","  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n","\u001b[K     |████████████████████████████████| 8.2 MB 44.1 MB/s \n","\u001b[?25hCollecting aio-pika==6.4.1\n","  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 25 kB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n","Collecting pyopenssl==22.0.0\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n","\u001b[?25hCollecting uvicorn==0.11.7\n","  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[?25hCollecting aiormq<4,>=3.2.0\n","  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n","Collecting yarl\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 49.6 MB/s \n","\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n","  Downloading starlette-0.12.9.tar.gz (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n","Collecting pymorphy2-dicts<3.0,>=2.4\n","  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 33.0 MB/s \n","\u001b[?25hCollecting dawg-python>=0.7\n","  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n","Collecting cryptography>=35.0\n","  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 41.1 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n","Collecting idna<2.9,>=2.5\n","  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n","Collecting websockets==8.*\n","  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.7 MB/s \n","\u001b[?25hCollecting h11<0.10,>=0.8\n","  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 2.7 MB/s \n","\u001b[?25hCollecting httptools==0.1.*\n","  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n","\u001b[K     |████████████████████████████████| 219 kB 73.1 MB/s \n","\u001b[?25hCollecting pamqp==2.3.0\n","  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n","Collecting multidict>=4.0\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.2.0)\n","Building wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449923 sha256=9daa87dd69f1767cdb802ed73969dc9b6445a4c6fc0b6088bf260d503540952f\n","  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5603 sha256=2120d8786a6c35db515638334f83fd9bf95ae7a558ec53c2838a3c9a552e4187\n","  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n","  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41405 sha256=c0ba4ab0961d102f974500a8a3b5bf1dfed19d0b0f085af9ad72396e812ac223\n","  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n","  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=3301aedc7bc53e3f5081113232690face4260506d98a5bcdb69b464b0edb8170\n","  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=353eac133cfcc55dda01887c14f2e406a93a48b6a31cd76139312838255090a4\n","  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n","  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=40525b083fb59d850fe801b799832307bc8d6ab16e2952d13be8186e001f958f\n","  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n","Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n","Installing collected packages: multidict, idna, yarl, pamqp, numpy, websockets, uvloop, tqdm, starlette, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, filelock, fastapi, Cython, aio-pika, deeppavlov\n","  Attempting uninstall: idna\n","    Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.64.0\n","    Uninstalling tqdm-4.64.0:\n","      Successfully uninstalled tqdm-4.64.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pytz\n","    Found existing installation: pytz 2022.1\n","    Uninstalling pytz-2022.1:\n","      Successfully uninstalled pytz-2022.1\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","  Attempting uninstall: prometheus-client\n","    Found existing installation: prometheus-client 0.14.1\n","    Uninstalling prometheus-client-0.14.1:\n","      Successfully uninstalled prometheus-client-0.14.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.7.0\n","    Uninstalling filelock-3.7.0:\n","      Successfully uninstalled filelock-3.7.0\n","  Attempting uninstall: Cython\n","    Found existing installation: Cython 0.29.30\n","    Uninstalling Cython-0.29.30:\n","      Successfully uninstalled Cython-0.29.30\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n","xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n","tensorflow 2.8.0+zzzcolab20220506162203 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n","kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n","jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n","jax 0.3.8 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n","google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n","fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-37.0.2 dawg-python-0.7.2 deeppavlov-0.17.3 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-6.0.2 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-22.0.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.62.0 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.7.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["# %%capture\n","! pip install deeppavlov"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"034KTVnxF3XJ"},"outputs":[],"source":["%%capture\n","!pip install tensorflow-gpu==1.15.2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eU8RW0YGEVwp"},"outputs":[],"source":["%%capture\n","! python -m deeppavlov install morpho_ru_syntagrus_bert\n","! pip install pyconll\n"]},{"cell_type":"code","source":["%%capture\n","! pip install icecream"],"metadata":{"id":"Gx8hhIJUcTZ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from icecream import ic\n","import os"],"metadata":{"id":"mcApbpo4chwC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qooinGiRdBr6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70f3f43c-9327-41a0-926c-4fd9ca46a1db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Data and model"],"metadata":{"id":"89m2jMJMcJky"}},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"EGRf5xGxcaHF"}},{"cell_type":"markdown","source":["Download data and save it to data folder"],"metadata":{"id":"SJCVFsWl2Gew"}},{"cell_type":"code","source":["%%capture\n","! wget https://raw.githubusercontent.com/dialogue-evaluation/GramEval2020/master/dataTrain/GramEval2020-GSD-train.conllu\n","! wget https://raw.githubusercontent.com/dialogue-evaluation/GramEval2020/master/dataOpenTest/GramEval2020-GSD-wiki-dev.conllu"],"metadata":{"id":"QSp0IJv8HKFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.makedirs('/content/data/GramEval/GSD')\n","os.rename(\"/content/GramEval2020-GSD-train.conllu\", \"/content/data/GramEval/GSD/ru_gsd-ud-train.conllu\")\n","os.rename(\"/content/GramEval2020-GSD-wiki-dev.conllu\", \"/content/data/GramEval/GSD/ru_gsd-ud-dev.conllu\")\n"],"metadata":{"id":"TP8FjD91HUK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datafolder_path = '/content/data/GramEval/GSD' #path to datafolder\n","models_path = '/content/drive/MyDrive/models_diploma/GramEval_GSD'\n","language_conf = 'ru_gsd'"],"metadata":{"id":"RcoH8ReSsFt_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RuBERT"],"metadata":{"id":"YGxpVfS4ccbj"}},{"cell_type":"markdown","source":["download bert model, don't know why though"],"metadata":{"id":"4CvyP2TR2T4S"}},{"cell_type":"code","source":["%%capture\n","!wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz"],"metadata":{"id":"q9slJMLbv_nI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tarfile\n","\n","file = tarfile.open('./rubert_cased_L-12_H-768_A-12_v1.tar.gz')\n","  \n","# extracting file\n","file.extractall('./downloads/bert_models')\n","  \n","file.close()"],"metadata":{"id":"A2mPT-j1weEV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Count and split tokens by frequency"],"metadata":{"id":"Br3NWTQEcnXL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RY5Ou00JEc3t"},"outputs":[],"source":["from utils import divide_by_freq\n","\n","top100, top1000, other = divide_by_freq(datafolder_path+'/ru_poetry-ud-train.conllu')\n","\n","os.makedirs(models_path + '/freq_groups')\n","\n","for i, x in enumerate([top100, top1000, other]):\n","    file_path = models_path + '/freq_groups' + '/{}.txt'.format(i)\n","    with open(file_path, 'w') as f:\n","        f.write(','.join(x))\n"]},{"cell_type":"markdown","source":["# Components"],"metadata":{"id":"bb-UPIUPczCA"}},{"cell_type":"markdown","metadata":{"id":"hcMJpEuZLzPh"},"source":["## Preprocessor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYynb_4rKLUD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"79c86f76-6fa9-4be2-da85-334bac252ecc"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package perluniprops to /root/nltk_data...\n","[nltk_data]   Package perluniprops is already up-to-date!\n","[nltk_data] Downloading package nonbreaking_prefixes to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"]}],"source":["import re\n","import random\n","from logging import getLogger\n","from typing import Tuple, List, Optional, Union\n","\n","from deeppavlov.core.common.registry import register\n","from bert_dp.preprocessing import convert_examples_to_features, InputExample, InputFeatures\n","from bert_dp.tokenization import FullTokenizer\n","\n","from deeppavlov.core.commands.utils import expand_path\n","from deeppavlov.core.data.utils import zero_pad\n","from deeppavlov.core.models.component import Component\n","from deeppavlov.models.preprocessors.mask import Mask\n","\n","\n","@register('my_bert_ner_preprocessor')\n","class MyBertNerPreprocessor(Component):\n","    \"\"\"Takes tokens and splits them into bert subtokens, encodes subtokens with their indices.\n","    Creates a mask of subtokens (one for the first subtoken, zero for the others).\n","    If tags are provided, calculates tags for subtokens.\n","    Args:\n","        vocab_file: path to vocabulary\n","        do_lower_case: set True if lowercasing is needed\n","        max_seq_length: max sequence length in subtokens, including [SEP] and [CLS] tokens\n","        max_subword_length: replace token to <unk> if it's length is larger than this\n","            (defaults to None, which is equal to +infinity)\n","        token_masking_prob: probability of masking token while training\n","        provide_subword_tags: output tags for subwords or for words\n","        subword_mask_mode: subword to select inside word tokens, can be \"first\" or \"last\"\n","            (default=\"first\")\n","    Attributes:\n","        max_seq_length: max sequence length in subtokens, including [SEP] and [CLS] tokens\n","        max_subword_length: rmax lenght of a bert subtoken\n","        tokenizer: instance of Bert FullTokenizer\n","\n","    !!Added: \n","        topk_tokens: path to file with tokens to consider in topk_tokens_mask in train mode\n","        if list of files is passed,  condiser all the tokens apart from the ones included in the files\n","    \"\"\"\n","\n","    def __init__(self,\n","                 vocab_file: str,\n","                 topk_tokens_path: List[str] = None, # added\n","                 last: bool = False,\n","                 do_lower_case: bool = False,\n","                 max_seq_length: int = 512,\n","                 max_subword_length: int = None,\n","                 token_masking_prob: float = 0.0,\n","                 provide_subword_tags: bool = False,\n","                 subword_mask_mode: str = \"first\",\n","                 **kwargs):\n","        self._re_tokenizer = re.compile(r\"[\\w']+|[^\\w ]\")\n","        self.provide_subword_tags = provide_subword_tags\n","        self.mode = kwargs.get('mode')\n","        self.max_seq_length = max_seq_length\n","        self.max_subword_length = max_subword_length\n","        self.subword_mask_mode = subword_mask_mode\n","        vocab_file = str(expand_path(vocab_file))\n","        self.tokenizer = FullTokenizer(vocab_file=vocab_file,\n","                                       do_lower_case=do_lower_case)\n","        self.token_masking_prob = token_masking_prob\n","\n","        self.last = None # added\n","        self.topk_tokens = [] # added\n","        for filename in topk_tokens_path: # added\n","            with open(filename, 'r') as f: # added\n","                  tokens = f.read().split(',') # added\n","            self.topk_tokens.extend(tokens) # added\n","        \n","        \n","        self.last = last\n","        \n","\n","    def __call__(self,\n","                 tokens: Union[List[List[str]], List[str]],\n","                 tags: List[List[str]] = None,\n","                 **kwargs):\n","      \n","        if isinstance(tokens[0], str):\n","            tokens = [re.findall(self._re_tokenizer, s) for s in tokens]\n","        subword_tokens, subword_tok_ids, startofword_markers, subword_tags, topk_tok_mask = [], [], [], [], []\n","        for i in range(len(tokens)):\n","            toks = tokens[i]\n","            ys = ['O'] * len(toks) if tags is None else tags[i]\n","            assert len(toks) == len(ys), \\\n","                f\"toks({len(toks)}) should have the same length as ys({len(ys)})\"\n","            sw_toks, sw_marker, sw_ys, tk_masks = \\\n","                self._ner_bert_tokenize(toks,\n","                                        ys,\n","                                        self.topk_tokens, # added\n","                                        self.tokenizer,\n","                                        self.max_subword_length,\n","                                        mode=self.mode,\n","                                        last=self.last,\n","                                        subword_mask_mode=self.subword_mask_mode,\n","                                        token_masking_prob=self.token_masking_prob)\n","            if self.max_seq_length is not None:\n","                if len(sw_toks) > self.max_seq_length:\n","                    raise RuntimeError(f\"input sequence after bert tokenization\"\n","                                       f\" shouldn't exceed {self.max_seq_length} tokens.\")\n","            topk_tok_mask.append(tk_masks) # added\n","            subword_tokens.append(sw_toks)\n","            subword_tok_ids.append(self.tokenizer.convert_tokens_to_ids(sw_toks))\n","            startofword_markers.append(sw_marker)\n","            subword_tags.append(sw_ys)\n","            assert len(sw_marker) == len(sw_toks) == len(subword_tok_ids[-1]) == len(sw_ys), \\\n","                f\"length of sow_marker({len(sw_marker)}), tokens({len(sw_toks)}),\" \\\n","                f\" token ids({len(subword_tok_ids[-1])}) and ys({len(ys)})\" \\\n","                f\" for tokens = `{toks}` should match\"\n","\n","        subword_tok_ids = zero_pad(subword_tok_ids, dtype=int, padding=0)\n","        startofword_markers = zero_pad(startofword_markers, dtype=int, padding=0)\n","        attention_mask = Mask()(subword_tokens)\n","        topk_tok_mask = zero_pad(topk_tok_mask, dtype=int, padding=0) # added\n","\n","\n","        if tags is not None:\n","            if self.provide_subword_tags:\n","                return tokens, subword_tokens, subword_tok_ids, \\\n","                    attention_mask, startofword_markers, subword_tags\n","            else:\n","                nonmasked_tags = [[t for t in ts if t != 'X'] for ts in tags]\n","                for swts, swids, swms, ts in zip(subword_tokens,\n","                                                 subword_tok_ids,\n","                                                 startofword_markers,\n","                                                 nonmasked_tags):\n","                    if (len(swids) != len(swms)) or (len(ts) != sum(swms)):\n","                        log.warning('Not matching lengths of the tokenization!')\n","                        log.warning(f'Tokens len: {len(swts)}\\n Tokens: {swts}')\n","                        log.warning(f'Markers len: {len(swms)}, sum: {sum(swms)}')\n","                        log.warning(f'Masks: {swms}')\n","                        log.warning(f'Tags len: {len(ts)}\\n Tags: {ts}')\n","                return tokens, subword_tokens, subword_tok_ids, \\\n","                    attention_mask, startofword_markers, nonmasked_tags\n","\n","        return tokens, subword_tokens, subword_tok_ids, startofword_markers, attention_mask, topk_tok_mask\n","\n","    @staticmethod\n","    def _ner_bert_tokenize(tokens: List[str],\n","                           tags: List[str],\n","                           topk_tokens: List[str],\n","                           tokenizer: FullTokenizer,\n","                           max_subword_len: int = None,\n","                           mode: str = None,\n","                           last: str = None,\n","                           subword_mask_mode: str = \"first\",\n","                           token_masking_prob: float = None) -> Tuple[List[str], List[int], List[str]]:\n","        do_masking = (mode == 'train') and (token_masking_prob is not None)\n","        do_cutting = (max_subword_len is not None)\n","        tokens_subword = ['[CLS]']\n","        topk_tokens_mask = [] # added\n","        startofword_markers = [0]\n","        tags_subword = ['X']\n","        for token, tag in zip(tokens, tags):\n","            token_marker = int(tag != 'X')\n","            subwords = tokenizer.tokenize(token)\n","            if not subwords or (do_cutting and (len(subwords) > max_subword_len)):\n","                tokens_subword.append('[UNK]')\n","                startofword_markers.append(token_marker)\n","                tags_subword.append(tag)\n","            else:\n","                if do_masking and (random.random() < token_masking_prob):\n","                    tokens_subword.extend(['[MASK]'] * len(subwords))\n","                else:\n","                    tokens_subword.extend(subwords)\n","\n","                if subword_mask_mode == \"last\":\n","                    startofword_markers.extend([0] * (len(subwords) - 1) + [token_marker])\n","                else: #subword_mask_mode=first\n","                    startofword_markers.extend([token_marker] + [0] * (len(subwords) - 1))\n","\n","                if token.lower() in topk_tokens:  # added\n","                    if last == True:  # added\n","                        topk_tokens_mask.extend([0]) # added\n","                    else:\n","                        topk_tokens_mask.extend([1]) # added\n","                else:\n","                    if last == True:   # added\n","                        topk_tokens_mask.extend([1]) # added\n","                    else:\n","                        topk_tokens_mask.extend([0]) # added\n","\n","\n","                tags_subword.extend([tag] + ['X'] * (len(subwords) - 1))\n","                \n","        tokens_subword.append('[SEP]')\n","        # topk_tokens_mask.append(0)\n","        startofword_markers.append(0)\n","        tags_subword.append('X')\n","        return tokens_subword, startofword_markers, tags_subword, topk_tokens_mask\n"]},{"cell_type":"markdown","metadata":{"id":"Qa0czko8L2Iv"},"source":["## Tagger\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uV-LZV1HTH_","outputId":"904e466e-ce69-4eb1-ed97-0019cb044960"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"]}],"source":["from logging import getLogger\n","from typing import List, Union, Dict, Optional\n","\n","import numpy as np\n","import tensorflow as tf\n","from bert_dp.modeling import BertConfig, BertModel\n","from bert_dp.optimization import AdamWeightDecayOptimizer\n","\n","from deeppavlov.core.commands.utils import expand_path\n","from deeppavlov.core.common.registry import register\n","from deeppavlov.core.layers.tf_layers import bi_rnn\n","from deeppavlov.core.models.tf_model import LRScheduledTFModel\n","\n","log = getLogger(__name__)\n","\n","\n","def token_from_subtoken(units: tf.Tensor, mask: tf.Tensor) -> tf.Tensor:\n","    \"\"\" Assemble token level units from subtoken level units\n","    Args:\n","        units: tf.Tensor of shape [batch_size, SUBTOKEN_seq_length, n_features]\n","        mask: mask of token beginnings. For example: for tokens\n","                [[``[CLS]`` ``My``, ``capybara``, ``[SEP]``],\n","                [``[CLS]`` ``Your``, ``aar``, ``##dvark``, ``is``, ``awesome``, ``[SEP]``]]\n","            the mask will be\n","                [[0, 1, 1, 0, 0, 0, 0],\n","                [0, 1, 1, 0, 1, 1, 0]]\n","    Returns:\n","        word_level_units: Units assembled from ones in the mask. For the\n","            example above this units will correspond to the following\n","                [[``My``, ``capybara``],\n","                [``Your`, ``aar``, ``is``, ``awesome``,]]\n","            the shape of this tensor will be [batch_size, TOKEN_seq_length, n_features]\n","    \"\"\"\n","    shape = tf.cast(tf.shape(units), tf.int64)\n","    batch_size = shape[0]\n","    nf = shape[2]\n","    nf_int = units.get_shape().as_list()[-1]\n","\n","    # number of TOKENS in each sentence\n","    token_seq_lengths = tf.cast(tf.reduce_sum(mask, 1), tf.int64)\n","    # for a matrix m =\n","    # [[1, 1, 1],\n","    #  [0, 1, 1],\n","    #  [1, 0, 0]]\n","    # it will be\n","    # [3, 2, 1]\n","\n","    n_words = tf.reduce_sum(token_seq_lengths)\n","    # n_words -> 6\n","\n","    max_token_seq_len = tf.cast(tf.reduce_max(token_seq_lengths), tf.int64)\n","    # max_token_seq_len -> 3\n","\n","    idxs = tf.where(mask)\n","    # for the matrix mentioned above\n","    # tf.where(mask) ->\n","    # [[0, 0],\n","    #  [0, 1]\n","    #  [0, 2],\n","    #  [1, 1],\n","    #  [1, 2]\n","    #  [2, 0]]\n","\n","    sample_ids_in_batch = tf.pad(idxs[:, 0], [[1, 0]])\n","    # for indices\n","    # [[0, 0],\n","    #  [0, 1]\n","    #  [0, 2],\n","    #  [1, 1],\n","    #  [1, 2],\n","    #  [2, 0]]\n","    # it is\n","    # [0, 0, 0, 0, 1, 1, 2]\n","    # padding is for computing change from one sample to another in the batch\n","\n","    a = tf.cast(tf.not_equal(sample_ids_in_batch[1:], sample_ids_in_batch[:-1]), tf.int64)\n","    # for the example above the result of this statement equals\n","    # [0, 0, 0, 1, 0, 1]\n","    # so data samples begin in 3rd and 5th positions (the indexes of ones)\n","\n","    # transforming sample start masks to the sample starts themselves\n","    q = a * tf.cast(tf.range(n_words), tf.int64)\n","    # [0, 0, 0, 3, 0, 5]\n","    count_to_substract = tf.pad(tf.boolean_mask(q, q), [(1, 0)])\n","    # [0, 3, 5]\n","\n","    new_word_indices = tf.cast(tf.range(n_words), tf.int64) - tf.gather(count_to_substract, tf.cumsum(a))\n","    # tf.range(n_words) -> [0, 1, 2, 3, 4, 5]\n","    # tf.cumsum(a) -> [0, 0, 0, 1, 1, 2]\n","    # tf.gather(count_to_substract, tf.cumsum(a)) -> [0, 0, 0, 3, 3, 5]\n","    # new_word_indices -> [0, 1, 2, 3, 4, 5] - [0, 0, 0, 3, 3, 5] = [0, 1, 2, 0, 1, 0]\n","    # new_word_indices is the concatenation of range(word_len(sentence))\n","    # for all sentences in units\n","\n","    n_total_word_elements = tf.cast(batch_size * max_token_seq_len, tf.int32)\n","    word_indices_flat = tf.cast(idxs[:, 0] * max_token_seq_len + new_word_indices, tf.int32)\n","    x_mask = tf.reduce_sum(tf.one_hot(word_indices_flat, n_total_word_elements), 0)\n","    x_mask = tf.cast(x_mask, tf.bool)\n","    # to get absolute indices we add max_token_seq_len:\n","    # idxs[:, 0] * max_token_seq_len -> [0, 0, 0, 1, 1, 2] * 2 = [0, 0, 0, 3, 3, 6]\n","    # word_indices_flat -> [0, 0, 0, 3, 3, 6] + [0, 1, 2, 0, 1, 0] = [0, 1, 2, 3, 4, 6]\n","    # total number of words in the batch (including paddings)\n","    # batch_size * max_token_seq_len -> 3 * 3 = 9\n","    # tf.one_hot(...) ->\n","    # [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","    #  [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","    #  [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","    #  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","    #  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","    #  [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n","    #  x_mask -> [1, 1, 1, 1, 1, 0, 1, 0, 0]\n","\n","    full_range = tf.cast(tf.range(batch_size * max_token_seq_len), tf.int32)\n","    # full_range -> [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","    nonword_indices_flat = tf.boolean_mask(full_range, tf.math.logical_not(x_mask))\n","    # # y_idxs -> [5, 7, 8]\n","\n","    # get a sequence of units corresponding to the start subtokens of the words\n","    # size: [n_words, n_features]\n","    elements = tf.gather_nd(units, idxs)\n","\n","    # prepare zeros for paddings\n","    # size: [batch_size * TOKEN_seq_length - n_words, n_features]\n","    paddings = tf.zeros(tf.stack([tf.reduce_sum(max_token_seq_len - token_seq_lengths),\n","                                  nf], 0), tf.float32)\n","\n","    tensor_flat = tf.dynamic_stitch([word_indices_flat, nonword_indices_flat],\n","                                    [elements, paddings])\n","    # tensor_flat -> [x, x, x, x, x, 0, x, 0, 0]\n","\n","    tensor = tf.reshape(tensor_flat, tf.stack([batch_size, max_token_seq_len, nf_int], 0))\n","    # tensor -> [[x, x, x],\n","    #            [x, x, 0],\n","    #            [x, 0, 0]]\n","\n","    return tensor\n","\n","\n","@register('my_bert_sequence_network')\n","class MyBertSequenceNetwork(LRScheduledTFModel):\n","    \"\"\"\n","    Basic class for BERT-based sequential architectures.\n","    Args:\n","\n","        keep_prob: dropout keep_prob for non-Bert layers\n","        bert_config_file: path to Bert configuration file\n","        pretrained_bert: pretrained Bert checkpoint\n","        attention_probs_keep_prob: keep_prob for Bert self-attention layers\n","        hidden_keep_prob: keep_prob for Bert hidden layers\n","        encoder_layer_ids: list of averaged layers from Bert encoder (layer ids)\n","            optimizer: name of tf.train.* optimizer or None for `AdamWeightDecayOptimizer`\n","            weight_decay_rate: L2 weight decay for `AdamWeightDecayOptimizer`\n","        encoder_dropout: dropout probability of encoder output layer\n","        ema_decay: what exponential moving averaging to use for network parameters, value from 0.0 to 1.0.\n","            Values closer to 1.0 put weight on the parameters history and values closer to 0.0 corresponds put weight\n","            on the current parameters.\n","        ema_variables_on_cpu: whether to put EMA variables to CPU. It may save a lot of GPU memory\n","        freeze_embeddings: set True to not train input embeddings set True to\n","            not train input embeddings set True to not train input embeddings\n","        learning_rate: learning rate of BERT head\n","        bert_learning_rate: learning rate of BERT body\n","        min_learning_rate: min value of learning rate if learning rate decay is used\n","        learning_rate_drop_patience: how many validations with no improvements to wait\n","        learning_rate_drop_div: the divider of the learning rate after `learning_rate_drop_patience` unsuccessful\n","            validations\n","        load_before_drop: whether to load best model before dropping learning rate or not\n","        clip_norm: clip gradients by norm\n","    \"\"\"\n","\n","    def __init__(self,\n","                 keep_prob: float,\n","                 bert_config_file: str,\n","                 pretrained_bert: str = None,\n","                 attention_probs_keep_prob: float = None,\n","                 hidden_keep_prob: float = None,\n","                 encoder_layer_ids: List[int] = (-1,),\n","                 encoder_dropout: float = 0.0,\n","                 optimizer: str = None,\n","                 weight_decay_rate: float = 1e-6,\n","                 ema_decay: float = None,\n","                 ema_variables_on_cpu: bool = True,\n","                 freeze_embeddings: bool = False,\n","                 learning_rate: float = 1e-3,\n","                 bert_learning_rate: float = 2e-5,\n","                 min_learning_rate: float = 1e-07,\n","                 learning_rate_drop_patience: int = 20,\n","                 learning_rate_drop_div: float = 2.0,\n","                 load_before_drop: bool = True,\n","                 clip_norm: float = 1.0,\n","                 **kwargs) -> None:\n","        super().__init__(learning_rate=learning_rate,\n","                         learning_rate_drop_div=learning_rate_drop_div,\n","                         learning_rate_drop_patience=learning_rate_drop_patience,\n","                         load_before_drop=load_before_drop,\n","                         clip_norm=clip_norm,\n","                         **kwargs)\n","        self.keep_prob = keep_prob\n","        self.encoder_layer_ids = encoder_layer_ids\n","        self.encoder_dropout = encoder_dropout\n","        self.optimizer = optimizer\n","        self.weight_decay_rate = weight_decay_rate\n","        self.ema_decay = ema_decay\n","        self.ema_variables_on_cpu = ema_variables_on_cpu\n","        self.freeze_embeddings = freeze_embeddings\n","        self.bert_learning_rate_multiplier = bert_learning_rate / learning_rate\n","        self.min_learning_rate = min_learning_rate\n","\n","        self.bert_config = BertConfig.from_json_file(str(expand_path(bert_config_file)))\n","\n","        if attention_probs_keep_prob is not None:\n","            self.bert_config.attention_probs_dropout_prob = 1.0 - attention_probs_keep_prob\n","        if hidden_keep_prob is not None:\n","            self.bert_config.hidden_dropout_prob = 1.0 - hidden_keep_prob\n","\n","        self.sess_config = tf.ConfigProto(allow_soft_placement=True)\n","        self.sess_config.gpu_options.allow_growth = True\n","        self.sess = tf.Session(config=self.sess_config)\n","\n","        self._init_graph()\n","\n","        self._init_optimizer()\n","\n","        self.sess.run(tf.global_variables_initializer())\n","\n","        if pretrained_bert is not None:\n","            pretrained_bert = str(expand_path(pretrained_bert))\n","\n","            if tf.train.checkpoint_exists(pretrained_bert) \\\n","                    and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):\n","                log.info('[initializing model with Bert from {}]'.format(pretrained_bert))\n","                # Exclude optimizer and classification variables from saved variables\n","                var_list = self._get_saveable_variables(\n","                    exclude_scopes=('Optimizer', 'learning_rate', 'momentum', 'ner', 'EMA'))\n","                saver = tf.train.Saver(var_list)\n","                saver.restore(self.sess, pretrained_bert)\n","\n","        if self.load_path is not None:\n","            self.load()\n","\n","        if self.ema:\n","            self.sess.run(self.ema.init_op)\n","\n","    def _init_graph(self) -> None:\n","        self.seq_lengths = tf.reduce_sum(self.y_masks_ph, axis=1)\n","\n","        self.bert = BertModel(config=self.bert_config,\n","                              is_training=self.is_train_ph,\n","                              input_ids=self.input_ids_ph,\n","                              input_mask=self.input_masks_ph,\n","                              token_type_ids=self.token_types_ph,\n","                              use_one_hot_embeddings=False)\n","        with tf.variable_scope('ner'):\n","            layer_weights = tf.get_variable('layer_weights_',\n","                                            shape=len(self.encoder_layer_ids),\n","                                            initializer=tf.ones_initializer(),\n","                                            trainable=True)\n","            layer_mask = tf.ones_like(layer_weights)\n","            layer_mask = tf.nn.dropout(layer_mask, self.encoder_keep_prob_ph)\n","            layer_weights *= layer_mask\n","            # to prevent zero division\n","            mask_sum = tf.maximum(tf.reduce_sum(layer_mask), 1.0)\n","            layer_weights = tf.unstack(layer_weights / mask_sum)\n","            # TODO: may be stack and reduce_sum is faster\n","            units = sum(w * l for w, l in zip(layer_weights, self.encoder_layers()))\n","            units = tf.nn.dropout(units, keep_prob=self.keep_prob_ph)\n","            # print('init graph var scope ner')\n","        return units\n","\n","    def _get_tag_mask(self) -> tf.Tensor:\n","        \"\"\"\n","        Returns: tag_mask,\n","            a mask that selects positions corresponding to word tokens (not padding and `CLS`)\n","        \"\"\"\n","        max_length = tf.reduce_max(self.seq_lengths)\n","        one_hot_max_len = tf.one_hot(self.seq_lengths - 1, max_length)\n","        tag_mask = tf.cumsum(one_hot_max_len[:, ::-1], axis=1)[:, ::-1]\n","\n","        return tag_mask\n","\n","    def encoder_layers(self):\n","        \"\"\"\n","        Returns: the output of BERT layers specfied in ``self.encoder_layers_ids``\n","        \"\"\"\n","        return [self.bert.all_encoder_layers[i] for i in self.encoder_layer_ids]\n","\n","    def _init_placeholders(self) -> None:\n","        self.input_ids_ph = tf.placeholder(shape=(None, None),\n","                                           dtype=tf.int32,\n","                                           name='token_indices_ph')\n","        self.input_masks_ph = tf.placeholder(shape=(None, None),\n","                                             dtype=tf.int32,\n","                                             name='token_mask_ph')\n","        self.token_types_ph = \\\n","            tf.placeholder_with_default(tf.zeros_like(self.input_ids_ph, dtype=tf.int32),\n","                                        shape=self.input_ids_ph.shape,\n","                                        name='token_types_ph')\n","        self.learning_rate_ph = tf.placeholder_with_default(0.0, shape=[], name='learning_rate_ph')\n","        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='keep_prob_ph')\n","        self.encoder_keep_prob_ph = tf.placeholder_with_default(1.0, shape=[], name='encoder_keep_prob_ph')\n","        self.is_train_ph = tf.placeholder_with_default(False, shape=[], name='is_train_ph')\n","\n","    def _init_optimizer(self) -> None:\n","        with tf.variable_scope('Optimizer'):\n","            self.global_step = tf.get_variable('global_step',\n","                                               shape=[],\n","                                               dtype=tf.int32,\n","                                               initializer=tf.constant_initializer(0),\n","                                               trainable=False)\n","            # default optimizer for Bert is Adam with fixed L2 regularization\n","\n","        if self.optimizer is None:\n","            self.train_op = \\\n","                self.get_train_op(self.loss,\n","                                  learning_rate=self.learning_rate_ph,\n","                                  optimizer=AdamWeightDecayOptimizer,\n","                                  weight_decay_rate=self.weight_decay_rate,\n","                                  beta_1=0.9,\n","                                  beta_2=0.999,\n","                                  epsilon=1e-6,\n","                                  optimizer_scope_name='Optimizer',\n","                                  exclude_from_weight_decay=[\"LayerNorm\",\n","                                                             \"layer_norm\",\n","                                                             \"bias\",\n","                                                             \"EMA\"])\n","        else:\n","            self.train_op = self.get_train_op(self.loss,\n","                                              learning_rate=self.learning_rate_ph,\n","                                              optimizer_scope_name='Optimizer')\n","\n","        if self.optimizer is None:\n","            with tf.variable_scope('Optimizer'):\n","                new_global_step = self.global_step + 1\n","                self.train_op = tf.group(self.train_op, [self.global_step.assign(new_global_step)])\n","\n","        if self.ema_decay is not None:\n","            _vars = self._get_trainable_variables(exclude_scopes=[\"Optimizer\",\n","                                                                  \"LayerNorm\",\n","                                                                  \"layer_norm\",\n","                                                                  \"bias\",\n","                                                                  \"learning_rate\",\n","                                                                  \"momentum\"])\n","\n","            self.ema = ExponentialMovingAverage(self.ema_decay,\n","                                                variables_on_cpu=self.ema_variables_on_cpu)\n","            self.train_op = self.ema.build(self.train_op, _vars, name=\"EMA\")\n","        else:\n","            self.ema = None\n","\n","    def get_train_op(self, loss: tf.Tensor, learning_rate: Union[tf.Tensor, float], **kwargs) -> tf.Operation:\n","        assert \"learnable_scopes\" not in kwargs, \"learnable scopes unsupported\"\n","        # train_op for bert variables\n","        kwargs['learnable_scopes'] = ('bert/encoder', 'bert/embeddings')\n","        if self.freeze_embeddings:\n","            kwargs['learnable_scopes'] = ('bert/encoder',)\n","        bert_learning_rate = learning_rate * self.bert_learning_rate_multiplier\n","        bert_train_op = super().get_train_op(loss,\n","                                             bert_learning_rate,\n","                                             **kwargs)\n","        # train_op for ner head variables\n","        kwargs['learnable_scopes'] = ('ner',)\n","        # print('1 get train op')\n","        head_train_op = super().get_train_op(loss,\n","                                             learning_rate,\n","                                             **kwargs)\n","        return tf.group(bert_train_op, head_train_op)\n","\n","    def _build_basic_feed_dict(self, input_ids: tf.Tensor, input_masks: tf.Tensor,\n","                               token_types: Optional[tf.Tensor]=None, train: bool=False) -> dict:\n","        \"\"\"Fills the feed_dict with the tensors defined in the basic class.\n","        You need to update this dict by the values of output placeholders\n","        and class-specific network inputs in your derived class.\n","        \"\"\"\n","        # print('1 _build_basic_feed_dict')\n","        feed_dict = {\n","            self.input_ids_ph: input_ids,\n","            self.input_masks_ph: input_masks,\n","        }\n","        if token_types is not None:\n","            feed_dict[self.token_types_ph] = token_types\n","        if train:\n","            # print('1 _build_basic_feed_dict train')\n","            feed_dict.update({\n","                self.learning_rate_ph: max(self.get_learning_rate(), self.min_learning_rate),\n","                self.keep_prob_ph: self.keep_prob,\n","                self.encoder_keep_prob_ph: 1.0 - self.encoder_dropout,\n","                self.is_train_ph: True,\n","            })\n","\n","        return feed_dict\n","\n","    def _build_feed_dict(self, input_ids, input_masks, token_types=None, *args,  **kwargs):\n","        raise NotImplementedError(\"You must implement _build_feed_dict in your derived class.\")\n","\n","    def train_on_batch(self,\n","                       input_ids: Union[List[List[int]], np.ndarray],\n","                       input_masks: Union[List[List[int]], np.ndarray],\n","                      #  topk_tok_mask: Union[List[List[int]], np.ndarray]\n","                       *args, **kwargs) -> Dict[str, float]:\n","        \"\"\"\n","        Args:\n","            input_ids: batch of indices of subwords\n","            input_masks: batch of masks which determine what should be attended\n","            args: arguments passed  to _build_feed_dict\n","                and corresponding to additional input\n","                and output tensors of the derived class.\n","            kwargs: keyword arguments passed to _build_feed_dict\n","                and corresponding to additional input\n","                and output tensors of the derived class.\n","\n","        Returns:\n","            dict with fields 'loss', 'head_learning_rate', and 'bert_learning_rate'\n","        \"\"\"\n","        # print('1 tr_on_batch1')\n","        feed_dict = self._build_feed_dict(input_ids, input_masks, *args, **kwargs)\n","        # print('1 feed_dict_tr_batch')\n","        # print('1 tr_on_batch2')\n","        if self.ema:\n","            self.sess.run(self.ema.switch_to_train_op)\n","        # print('1 sess with loss')\n","        # print(self.topk_tok_mask)\n","        _, loss, lr = self.sess.run([self.train_op, self.loss, self.learning_rate_ph],\n","                                     feed_dict=feed_dict)\n","\n","        return {'loss': loss,\n","                'head_learning_rate': float(lr),\n","                'bert_learning_rate': float(lr) * self.bert_learning_rate_multiplier}\n","\n","    def __call__(self,\n","                 input_ids: Union[List[List[int]], np.ndarray],\n","                 input_masks: Union[List[List[int]], np.ndarray],\n","                 **kwargs) -> Union[List[List[int]], List[np.ndarray]]:\n","        raise NotImplementedError(\"You must implement method __call__ in your derived class.\")\n","\n","    def save(self, exclude_scopes=('Optimizer', 'EMA/BackupVariables')) -> None:\n","        if self.ema:\n","            self.sess.run(self.ema.switch_to_train_op)\n","        return super().save(exclude_scopes=exclude_scopes)\n","\n","    def load(self,\n","             exclude_scopes=('Optimizer',\n","                             'learning_rate',\n","                             'momentum',\n","                             'EMA/BackupVariables'),\n","             **kwargs) -> None:\n","        return super().load(exclude_scopes=exclude_scopes, **kwargs)\n","\n","\n","@register('my_bert_sequence_tagger')\n","class MyBertSequenceTagger(MyBertSequenceNetwork):\n","    \"\"\"BERT-based model for text tagging. It predicts a label for every token (not subtoken) in the text.\n","    You can use it for sequence labeling tasks, such as morphological tagging or named entity recognition.\n","    See :class:`deeppavlov.models.bert.bert_sequence_tagger.BertSequenceNetwork`\n","    for the description of inherited parameters.\n","    Args:\n","        n_tags: number of distinct tags\n","        use_crf: whether to use CRF on top or not\n","        use_birnn: whether to use bidirection rnn after BERT layers.\n","            For NER and morphological tagging we usually set it to `False` as otherwise the model overfits\n","        birnn_cell_type: the type of Bidirectional RNN. Either `lstm` or `gru`\n","        birnn_hidden_size: number of hidden units in the BiRNN layer in each direction\n","        return_probas: set this to `True` if you need the probabilities instead of raw answers\n","    \"\"\"\n","\n","    def __init__(self,\n","                 n_tags: List[str],\n","                 keep_prob: float,\n","                 bert_config_file: str,\n","                 pretrained_bert: str = None,\n","                 attention_probs_keep_prob: float = None,\n","                 hidden_keep_prob: float = None,\n","                 use_crf=False,\n","                 encoder_layer_ids: List[int] = (-1,),\n","                 encoder_dropout: float = 0.0,\n","                 optimizer: str = None,\n","                 weight_decay_rate: float = 1e-6,\n","                 use_birnn: bool = False,\n","                 birnn_cell_type: str = 'lstm',\n","                 birnn_hidden_size: int = 128,\n","                 ema_decay: float = None,\n","                 ema_variables_on_cpu: bool = True,\n","                 return_probas: bool = False,\n","                 freeze_embeddings: bool = False,\n","                 learning_rate: float = 1e-3,\n","                 bert_learning_rate: float = 2e-5,\n","                 min_learning_rate: float = 1e-07,\n","                 learning_rate_drop_patience: int = 20,\n","                 learning_rate_drop_div: float = 2.0,\n","                 load_before_drop: bool = True,\n","                 clip_norm: float = 1.0,\n","                 **kwargs) -> None:\n","        self.n_tags = n_tags\n","        self.use_crf = use_crf\n","        self.use_birnn = use_birnn\n","        self.birnn_cell_type = birnn_cell_type\n","        self.birnn_hidden_size = birnn_hidden_size\n","        self.return_probas = return_probas\n","        super().__init__(keep_prob=keep_prob,\n","                         bert_config_file=bert_config_file,\n","                         pretrained_bert=pretrained_bert,\n","                         attention_probs_keep_prob=attention_probs_keep_prob,\n","                         hidden_keep_prob=hidden_keep_prob,\n","                         encoder_layer_ids=encoder_layer_ids,\n","                         encoder_dropout=encoder_dropout,\n","                         optimizer=optimizer,\n","                         weight_decay_rate=weight_decay_rate,\n","                         ema_decay=ema_decay,\n","                         ema_variables_on_cpu=ema_variables_on_cpu,\n","                         freeze_embeddings=freeze_embeddings,\n","                         learning_rate=learning_rate,\n","                         bert_learning_rate=bert_learning_rate,\n","                         min_learning_rate=min_learning_rate,\n","                         learning_rate_drop_div=learning_rate_drop_div,\n","                         learning_rate_drop_patience=learning_rate_drop_patience,\n","                         load_before_drop=load_before_drop,\n","                         clip_norm=clip_norm,\n","                         **kwargs)\n","\n","    def _init_graph(self) -> None:\n","        self._init_placeholders()\n","\n","        units = super()._init_graph()\n","\n","        with tf.variable_scope('ner'):\n","            if self.use_birnn:\n","                units, _ = bi_rnn(units,\n","                                  self.birnn_hidden_size,\n","                                  cell_type=self.birnn_cell_type,\n","                                  seq_lengths=self.seq_lengths,\n","                                  name='birnn')\n","                units = tf.concat(units, -1)\n","            # TODO: maybe add one more layer?\n","            logits = tf.layers.dense(units, units=self.n_tags, name=\"output_dense\")\n","            self.logits = token_from_subtoken(logits, self.y_masks_ph) #token_ids of startwords?\n","\n","            # CRF\n","            if self.use_crf:\n","                transition_params = tf.get_variable('Transition_Params',\n","                                                    shape=[self.n_tags, self.n_tags],\n","                                                    initializer=tf.zeros_initializer())\n","                log_likelihood, transition_params = \\\n","                    tf.contrib.crf.crf_log_likelihood(self.logits,\n","                                                      self.y_ph,\n","                                                      self.seq_lengths,\n","                                                      transition_params)\n","                loss_tensor = -log_likelihood\n","                self._transition_params = transition_params\n","\n","            self.y_predictions = tf.argmax(self.logits, -1)\n","            self.y_probas = tf.nn.softmax(self.logits, axis=2)\n","\n","        with tf.variable_scope(\"loss\"):\n","            tag_mask = self._get_tag_mask()\n","            y_mask = tf.cast(tag_mask, tf.float32)\n","            if self.use_crf:\n","                self.loss = tf.reduce_mean(loss_tensor)\n","            else:                \n","                self.loss = tf.losses.sparse_softmax_cross_entropy(labels=self.y_ph,\n","                                                                   logits=self.logits,\n","                                                                   weights=self.topk_masks_ph)  #instead of y_mask\n","\n","\n","    def _init_placeholders(self) -> None:\n","        super()._init_placeholders()\n","        self.y_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='y_ph')\n","        self.y_masks_ph = tf.placeholder(shape=(None, None),\n","                                         dtype=tf.int32,\n","                                         name='y_mask_ph')\n","        self.topk_masks_ph = tf.placeholder(shape=(None, None),  # added\n","                                         dtype=tf.int32,\n","                                         name='topk_mask_ph')\n","\n","    def _decode_crf(self, feed_dict: Dict[tf.Tensor, np.ndarray]) -> List[np.ndarray]:\n","        logits, trans_params, mask, seq_lengths = self.sess.run([self.logits,\n","                                                                 self._transition_params,\n","                                                                 self.y_masks_ph,\n","                                                                 self.seq_lengths],\n","                                                                feed_dict=feed_dict)\n","        # iterate over the sentences because no batching in viterbi_decode\n","        y_pred = []\n","        for logit, sequence_length in zip(logits, seq_lengths):\n","            logit = logit[:int(sequence_length)]  # keep only the valid steps\n","            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n","            y_pred += [viterbi_seq]\n","        return y_pred\n","\n","    def _build_feed_dict(self, input_ids, input_masks, y_masks, topk_tok_mask, y=None):\n","        feed_dict = self._build_basic_feed_dict(input_ids, input_masks, train=(y is not None))\n","\n","        if y is not None:\n","            max_len = 0\n","            for seq in topk_tok_mask:\n","                if len(seq) > max_len:\n","                    max_len = len(seq)\n","            feed_dict[self.topk_masks_ph] = topk_tok_mask # added            \n","            feed_dict[self.y_ph] = y\n","        feed_dict[self.y_masks_ph] = y_masks\n","\n","        return feed_dict\n","\n","    def __call__(self,\n","                 input_ids: Union[List[List[int]], np.ndarray],\n","                 input_masks: Union[List[List[int]], np.ndarray],\n","                 y_masks: Union[List[List[int]], np.ndarray],\n","                 topk_tok_mask: Union[List[List[int]], np.ndarray]) -> Union[List[List[int]], List[np.ndarray]]:\n","        \"\"\" Predicts tag indices for a given subword tokens batch\n","        Args:\n","            input_ids: indices of the subwords\n","            input_masks: mask that determines where to attend and where not to\n","            y_masks: mask which determines the first subword units in the the word\n","\n","        Added: \n","            topk_tok_mask: mask that determines where to attend and where not to\n","        Returns:\n","            Label indices or class probabilities for each token (not subtoken)\n","        # \"\"\"\n","        \n","        feed_dict = self._build_feed_dict(input_ids, input_masks, y_masks, topk_tok_mask)\n","       \n","        if self.ema:\n","            self.sess.run(self.ema.switch_to_test_op)\n","        if not self.return_probas:\n","            if self.use_crf:\n","                pred = self._decode_crf(feed_dict)\n","            else:\n","                pred, seq_lengths = self.sess.run([self.y_predictions, self.seq_lengths], feed_dict=feed_dict)\n","                pred = [p[:l] for l, p in zip(seq_lengths, pred)]\n","        else:\n","            pred = self.sess.run(self.y_probas, feed_dict=feed_dict)\n","\n","        return pred\n","\n","\n","class ExponentialMovingAverage:\n","    def __init__(self,\n","                 decay: float = 0.999,\n","                 variables_on_cpu: bool = True) -> None:\n","        self.decay = decay\n","        self.ema = tf.train.ExponentialMovingAverage(decay=decay)\n","        self.var_device_name = '/cpu:0' if variables_on_cpu else None\n","        self.train_mode = None\n","\n","    def build(self,\n","              minimize_op: tf.Tensor,\n","              update_vars: List[tf.Variable] = None,\n","              name: str = \"EMA\") -> tf.Tensor:\n","        with tf.variable_scope(name):\n","            if update_vars is None:\n","                update_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n","\n","            with tf.control_dependencies([minimize_op]):\n","                minimize_op = self.ema.apply(update_vars)\n","\n","            with tf.device(self.var_device_name):\n","                # Make backup variables\n","                with tf.variable_scope('BackupVariables'):\n","                    backup_vars = [tf.get_variable(var.op.name,\n","                                                   dtype=var.value().dtype,\n","                                                   trainable=False,\n","                                                   initializer=var.initialized_value())\n","                                   for var in update_vars]\n","\n","                def ema_to_weights():\n","                    return tf.group(*(tf.assign(var, self.ema.average(var).read_value())\n","                                      for var in update_vars))\n","\n","                def save_weight_backups():\n","                    return tf.group(*(tf.assign(bck, var.read_value())\n","                                      for var, bck in zip(update_vars, backup_vars)))\n","\n","                def restore_weight_backups():\n","                    return tf.group(*(tf.assign(var, bck.read_value())\n","                                      for var, bck in zip(update_vars, backup_vars)))\n","\n","                train_switch_op = restore_weight_backups()\n","                with tf.control_dependencies([save_weight_backups()]):\n","                    test_switch_op = ema_to_weights()\n","\n","            self.train_switch_op = train_switch_op\n","            self.test_switch_op = test_switch_op\n","            self.do_nothing_op = tf.no_op()\n","\n","        return minimize_op\n","\n","    @property\n","    def init_op(self) -> tf.Operation:\n","        self.train_mode = False\n","        return self.test_switch_op\n","\n","    @property\n","    def switch_to_train_op(self) -> tf.Operation:\n","        assert self.train_mode is not None, \"ema variables aren't initialized\"\n","        if not self.train_mode:\n","            # log.info(\"switching to train mode\")\n","            self.train_mode = True\n","            return self.train_switch_op\n","        return self.do_nothing_op\n","\n","    @property\n","    def switch_to_test_op(self) -> tf.Operation:\n","        assert self.train_mode is not None, \"ema variables aren't initialized\"\n","        if self.train_mode:\n","            # log.info(\"switching to test mode\")\n","            self.train_mode = False\n","            return self.test_switch_op\n","        return self.do_nothing_op"]},{"cell_type":"markdown","metadata":{"id":"rrMdYc1dG7eO"},"source":["## Mask_ys"]},{"cell_type":"markdown","source":["Component that masks tokens for the evaluation, so the metrics are counted considering certain group of tokens. By masking here I mean just forming new lists of tokens without the irrelevant ones."],"metadata":{"id":"_yquqwCeE63b"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oS5h0kWtGx2e"},"outputs":[],"source":["@register('mask_ys')\n","class mask_ys(Component):\n","    def __init__(self, **kwargs):\n","        pass\n","\n","    def __call__(self, y, topk_tok_mask, y_predicted, *args, **kwargs):\n","\n","        y_predicted_masked = []\n","        y_masked = []\n","        \n","        for i in range(len(y_predicted)):\n","            line_preds = []\n","            line_true = []\n","            for j in range(len(y_predicted[i])):\n","                if topk_tok_mask[i][j] == 1:\n","                    line_preds.append(y_predicted[i][j])\n","                    line_true.append(y[i][j])\n","            y_predicted_masked.append(np.array(line_preds))\n","            y_masked.append(np.array(line_true))\n","\n","        return y_masked, y_predicted_masked"]},{"cell_type":"markdown","metadata":{"id":"4XSodQDbIMDo"},"source":["# Training"]},{"cell_type":"markdown","source":["need to specify in config:\n","- ['dataset_reader']['data_path'] - path to datafolder\n","- ['dataset_reader']['language'] - language according to deeppavlov's config \n","- ['metadata']['variables']['MODELS_PATH'] - path to general folder devoted to certain dataset\n","- ['train']['evaluation_targets'] = valid, ['dataset_reader']['data_types'] = ['train', 'dev'], if there is no test file\n","- ['metadata']['variables']['DATA_PATH'] - path to datafolder\n","\n","will be specified below:\n","- ['metadata']['variables']['WORK_PATH'] - path to certain model folder\n","- ['chainer']['pipe'][1]['topk_tokens_path'] - path to the group of tokens to consider\n"],"metadata":{"id":"yYptObzp3DO-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-rIu6PaIb6J"},"outputs":[],"source":["import copy\n","\n","import json\n","from deeppavlov import build_model, configs, train_model, evaluate_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUJPGa0qMu86"},"outputs":[],"source":["base_config = json.load(open('./base_config.json'))\n","\n","base_config['metadata']['variables']['DATA_PATH'] = datafolder_path\n","base_config['metadata']['variables']['MODELS_PATH'] = '{ROOT_PATH}/drive/MyDrive/models_diploma/GramEval_GSD'\n","base_config['train']['evaluation_targets'] = ['valid']\n","base_config['dataset_reader']['data_types'] = ['train', 'dev']\n","base_config['dataset_reader']['language'] = language_conf\n","\n","base_config['train']['batch_size'] = 8"]},{"cell_type":"markdown","source":["##From Scratch Models"],"metadata":{"id":"_6HdtWbaGTiY"}},{"cell_type":"markdown","source":["###top100 "],"metadata":{"id":"msN4Q1KmT5Za"}},{"cell_type":"code","source":["### dir for my models\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_top100'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt']\n","base_config['train']['epochs'] = 60\n","base_config['train']['validation_patience'] = 30\n","\n","base_config['chainer']['pipe'][1]['last'] = False"],"metadata":{"id":"oAPZjNClGYkm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = train_model(base_config, download=False) \n"],"metadata":{"id":"1nwPq2KxGefG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3381bbe-926d-40d5-87ee-184a64d82616"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 19:53:32.608 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:53:33.17 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/tag.dict]\n","2022-05-23 19:53:33.383 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/tag.dict]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n","\n","WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n","WARNING:tensorflow:From <ipython-input-3-5405f03ac0b9>:54: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From <ipython-input-3-5405f03ac0b9>:228: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:53:51.252 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 19:53:52.922 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.0, \"accuracy\": 0.0727}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/trainers/nn_trainer.py:178: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:54:30.310 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0 to 0.8276\n","2022-05-23 19:54:30.311 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:54:30.320 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8276, \"accuracy\": 0.4909}, \"time_spent\": \"0:00:39\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2400, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:55:10.216 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8276 to 0.9267\n","2022-05-23 19:55:10.224 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:55:10.231 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9267, \"accuracy\": 0.7273}, \"time_spent\": \"0:01:19\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:55:16.739 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9267\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9181, \"accuracy\": 0.7091}, \"time_spent\": \"0:01:26\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 1, \"patience_limit\": 30}}\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:211: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:55:50.17 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9267 to 0.9397\n","2022-05-23 19:55:50.19 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:55:50.32 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9397, \"accuracy\": 0.7455}, \"time_spent\": \"0:01:59\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7198, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:56:28.639 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9397 to 0.9483\n","2022-05-23 19:56:28.641 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:56:28.650 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9483, \"accuracy\": 0.7818}, \"time_spent\": \"0:02:38\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:56:38.213 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9483\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9353, \"accuracy\": 0.7273}, \"time_spent\": \"0:02:47\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:57:08.804 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9483 to 0.9526\n","2022-05-23 19:57:08.806 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:57:08.814 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9526, \"accuracy\": 0.8}, \"time_spent\": \"0:03:18\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11998, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:57:47.403 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9526 to 0.9569\n","2022-05-23 19:57:47.405 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:57:47.417 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:03:57\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14398, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:58:00.88 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9569\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:04:09\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:58:28.321 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9569 to 0.9655\n","2022-05-23 19:58:28.322 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 19:58:28.334 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:04:38\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16797, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:59:08.252 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:05:17\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:59:17.889 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:05:27\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 19:59:42.606 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:05:52\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21596, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:00:16.609 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:06:26\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23995, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:00:29.660 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:06:39\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:00:51.856 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:07:01\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26395, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:01:26.606 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9526, \"accuracy\": 0.8}, \"time_spent\": \"0:07:36\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:01:41.355 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:07:51\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:02:00.897 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:08:10\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31194, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:02:35.366 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:08:45\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33593, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:02:53.328 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:09:03\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:03:11.597 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:09:21\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35992, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:03:45.612 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:09:55\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38392, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:04:05.426 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9655\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:10:15\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:04:19.756 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9655 to 0.9698\n","2022-05-23 20:04:19.764 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:04:19.769 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:10:29\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:04:59.438 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:11:09\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43191, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:05:21.847 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:11:31\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:05:34.299 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:11:44\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:06:08.937 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:12:18\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47990, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:06:33.664 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:12:43\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:06:43.875 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:12:53\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:07:17.339 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:13:27\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52790, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:07:45.707 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:13:55\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:07:53.435 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:14:03\", \"epochs_done\": 11, \"batches_seen\": 6900, \"train_examples_seen\": 55189, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:08:28.75 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:14:37\", \"epochs_done\": 11, \"batches_seen\": 7200, \"train_examples_seen\": 57588, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:08:57.600 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:15:07\", \"epochs_done\": 12, \"batches_seen\": 7464, \"train_examples_seen\": 59700, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:09:03.111 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:15:12\", \"epochs_done\": 12, \"batches_seen\": 7500, \"train_examples_seen\": 59987, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:09:36.718 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:15:46\", \"epochs_done\": 12, \"batches_seen\": 7800, \"train_examples_seen\": 62387, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:10:09.417 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:16:19\", \"epochs_done\": 13, \"batches_seen\": 8086, \"train_examples_seen\": 64675, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:10:11.664 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:16:21\", \"epochs_done\": 13, \"batches_seen\": 8100, \"train_examples_seen\": 64787, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:10:46.15 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:16:55\", \"epochs_done\": 13, \"batches_seen\": 8400, \"train_examples_seen\": 67186, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:11:20.270 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:17:30\", \"epochs_done\": 13, \"batches_seen\": 8700, \"train_examples_seen\": 69586, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:11:21.322 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:17:31\", \"epochs_done\": 14, \"batches_seen\": 8708, \"train_examples_seen\": 69650, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:11:55.417 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:18:05\", \"epochs_done\": 14, \"batches_seen\": 9000, \"train_examples_seen\": 71986, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:12:29.480 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:18:39\", \"epochs_done\": 14, \"batches_seen\": 9300, \"train_examples_seen\": 74385, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:12:33.0 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:18:42\", \"epochs_done\": 15, \"batches_seen\": 9330, \"train_examples_seen\": 74625, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:13:03.938 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:19:13\", \"epochs_done\": 15, \"batches_seen\": 9600, \"train_examples_seen\": 76784, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:13:38.571 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:19:48\", \"epochs_done\": 15, \"batches_seen\": 9900, \"train_examples_seen\": 79184, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:13:44.622 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:19:54\", \"epochs_done\": 16, \"batches_seen\": 9952, \"train_examples_seen\": 79600, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:14:13.222 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:20:22\", \"epochs_done\": 16, \"batches_seen\": 10200, \"train_examples_seen\": 81584, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:14:47.943 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:20:57\", \"epochs_done\": 16, \"batches_seen\": 10500, \"train_examples_seen\": 83983, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:14:56.259 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:21:06\", \"epochs_done\": 17, \"batches_seen\": 10574, \"train_examples_seen\": 84575, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:15:22.971 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:21:32\", \"epochs_done\": 17, \"batches_seen\": 10800, \"train_examples_seen\": 86382, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:15:56.280 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:22:06\", \"epochs_done\": 17, \"batches_seen\": 11100, \"train_examples_seen\": 88782, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:16:08.32 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n","2022-05-23 20:16:08.53 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:16:10.449 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.944, \"accuracy\": 0.7818}, \"time_spent\": \"0:22:17\", \"epochs_done\": 18, \"batches_seen\": 11196, \"train_examples_seen\": 89550, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:16:11.11 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n","2022-05-23 20:16:11.590 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/tag.dict]\n","2022-05-23 20:16:25.202 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:16:27.12 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:16:28.611 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/tag.dict]\n","2022-05-23 20:16:43.783 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top100/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:16:45.537 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]},{"cell_type":"markdown","source":["###top1000"],"metadata":{"id":"DavKW8gHT1vg"}},{"cell_type":"code","source":["### dir for my models\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_top1000'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt']\n","base_config['train']['validation_patience'] = 30\n","base_config['train']['epochs'] = 60\n","\n","base_config['chainer']['pipe'][1]['last'] = False"],"metadata":{"id":"X7pxTy9oT97h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = train_model(base_config, download=False) \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2VKaif8UFps","outputId":"4d7afb91-a8b1-43e3-c62b-9576ad4098e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 20:17:55.223 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n","2022-05-23 20:17:55.610 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/tag.dict]\n","2022-05-23 20:17:56.41 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/tag.dict]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:18:13.411 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 20:18:14.703 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0065\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.0065, \"accuracy\": 0.0545}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:18:54.481 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0065 to 0.281\n","2022-05-23 20:18:54.483 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:18:54.495 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.281, \"accuracy\": 0.2}, \"time_spent\": \"0:00:41\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2399, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:19:33.385 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.281 to 0.5163\n","2022-05-23 20:19:33.390 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:19:33.397 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.5163, \"accuracy\": 0.2909}, \"time_spent\": \"0:01:20\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:19:40.433 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.5163 to 0.5294\n","2022-05-23 20:19:40.438 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:19:40.445 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.5294, \"accuracy\": 0.2909}, \"time_spent\": \"0:01:28\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:20:19.567 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.5294 to 0.7386\n","2022-05-23 20:20:19.569 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:20:19.581 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.7386, \"accuracy\": 0.4545}, \"time_spent\": \"0:02:07\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7198, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:20:58.800 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7386 to 0.7974\n","2022-05-23 20:20:58.801 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:20:58.812 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.7974, \"accuracy\": 0.5818}, \"time_spent\": \"0:02:46\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:21:08.405 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.7974\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.7974, \"accuracy\": 0.5818}, \"time_spent\": \"0:02:55\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:21:39.282 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7974 to 0.8366\n","2022-05-23 20:21:39.283 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:21:39.294 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8366, \"accuracy\": 0.6182}, \"time_spent\": \"0:03:26\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11998, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:22:20.179 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8366 to 0.8627\n","2022-05-23 20:22:20.181 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:22:20.194 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8627, \"accuracy\": 0.6909}, \"time_spent\": \"0:04:07\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14397, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:22:31.781 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8627\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8627, \"accuracy\": 0.6909}, \"time_spent\": \"0:04:19\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:23:00.120 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8627 to 0.8693\n","2022-05-23 20:23:00.121 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:23:00.132 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8693, \"accuracy\": 0.7091}, \"time_spent\": \"0:04:47\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16797, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:23:39.683 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8693 to 0.8758\n","2022-05-23 20:23:39.684 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:23:39.696 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8758, \"accuracy\": 0.7091}, \"time_spent\": \"0:05:27\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:23:54.385 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8758\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8693, \"accuracy\": 0.6909}, \"time_spent\": \"0:05:41\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:24:19.921 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8758\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8758, \"accuracy\": 0.7091}, \"time_spent\": \"0:06:07\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21596, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:24:53.938 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8758\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8758, \"accuracy\": 0.7455}, \"time_spent\": \"0:06:41\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23996, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:25:07.552 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8758 to 0.915\n","2022-05-23 20:25:07.553 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:25:07.563 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.915, \"accuracy\": 0.8182}, \"time_spent\": \"0:06:55\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:25:35.291 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.915 to 0.9346\n","2022-05-23 20:25:35.292 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:25:35.303 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:07:22\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26394, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:26:15.905 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9346 to 0.9477\n","2022-05-23 20:26:15.913 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:26:15.919 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:08:03\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:26:35.493 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8364}, \"time_spent\": \"0:08:23\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:26:56.29 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9477 to 0.9542\n","2022-05-23 20:26:56.30 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:26:56.38 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:08:43\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31194, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:27:35.137 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:09:22\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33593, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:27:52.992 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:09:40\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:28:10.260 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:09:57\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35993, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:28:44.588 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:10:32\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38393, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:29:05.338 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9216, \"accuracy\": 0.8182}, \"time_spent\": \"0:10:52\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:29:19.951 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8364}, \"time_spent\": \"0:11:07\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:29:54.425 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:11:42\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43192, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:30:17.789 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:12:05\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:30:30.127 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9542 to 0.9608\n","2022-05-23 20:30:30.128 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:30:30.140 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.9091}, \"time_spent\": \"0:12:17\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:31:09.983 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8364}, \"time_spent\": \"0:12:57\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47991, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:31:35.778 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:13:23\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:31:45.701 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.8364}, \"time_spent\": \"0:13:33\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:32:20.720 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:14:08\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52789, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:32:48.146 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:14:35\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:32:56.80 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:14:43\", \"epochs_done\": 11, \"batches_seen\": 6900, \"train_examples_seen\": 55189, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:33:29.730 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:15:17\", \"epochs_done\": 11, \"batches_seen\": 7200, \"train_examples_seen\": 57589, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:34:00.543 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:15:48\", \"epochs_done\": 12, \"batches_seen\": 7464, \"train_examples_seen\": 59700, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:34:05.803 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:15:53\", \"epochs_done\": 12, \"batches_seen\": 7500, \"train_examples_seen\": 59988, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:34:40.314 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9608 to 0.9673\n","2022-05-23 20:34:40.316 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:34:40.323 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9673, \"accuracy\": 0.9273}, \"time_spent\": \"0:16:27\", \"epochs_done\": 12, \"batches_seen\": 7800, \"train_examples_seen\": 62388, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:35:18.645 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9673, \"accuracy\": 0.9273}, \"time_spent\": \"0:17:06\", \"epochs_done\": 13, \"batches_seen\": 8086, \"train_examples_seen\": 64675, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:35:21.70 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9673, \"accuracy\": 0.9273}, \"time_spent\": \"0:17:08\", \"epochs_done\": 13, \"batches_seen\": 8100, \"train_examples_seen\": 64787, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:35:55.439 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9673, \"accuracy\": 0.9273}, \"time_spent\": \"0:17:43\", \"epochs_done\": 13, \"batches_seen\": 8400, \"train_examples_seen\": 67187, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:36:30.350 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:18:17\", \"epochs_done\": 13, \"batches_seen\": 8700, \"train_examples_seen\": 69586, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:36:31.303 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:18:18\", \"epochs_done\": 14, \"batches_seen\": 8708, \"train_examples_seen\": 69650, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:37:05.283 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:18:52\", \"epochs_done\": 14, \"batches_seen\": 9000, \"train_examples_seen\": 71985, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:37:40.301 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:19:27\", \"epochs_done\": 14, \"batches_seen\": 9300, \"train_examples_seen\": 74385, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:37:43.728 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.9091}, \"time_spent\": \"0:19:31\", \"epochs_done\": 15, \"batches_seen\": 9330, \"train_examples_seen\": 74625, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:38:15.244 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:20:02\", \"epochs_done\": 15, \"batches_seen\": 9600, \"train_examples_seen\": 76785, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:38:49.267 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:20:36\", \"epochs_done\": 15, \"batches_seen\": 9900, \"train_examples_seen\": 79185, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:38:56.68 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:20:43\", \"epochs_done\": 16, \"batches_seen\": 9952, \"train_examples_seen\": 79600, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:39:25.648 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:21:13\", \"epochs_done\": 16, \"batches_seen\": 10200, \"train_examples_seen\": 81584, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:40:00.285 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:21:47\", \"epochs_done\": 16, \"batches_seen\": 10500, \"train_examples_seen\": 83983, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:40:08.436 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:21:56\", \"epochs_done\": 17, \"batches_seen\": 10574, \"train_examples_seen\": 84575, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:40:35.338 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:22:22\", \"epochs_done\": 17, \"batches_seen\": 10800, \"train_examples_seen\": 86383, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:41:09.646 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:22:57\", \"epochs_done\": 17, \"batches_seen\": 11100, \"train_examples_seen\": 88782, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:41:20.831 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8727}, \"time_spent\": \"0:23:08\", \"epochs_done\": 18, \"batches_seen\": 11196, \"train_examples_seen\": 89550, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:41:44.331 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8727}, \"time_spent\": \"0:23:31\", \"epochs_done\": 18, \"batches_seen\": 11400, \"train_examples_seen\": 91182, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:42:18.756 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:24:06\", \"epochs_done\": 18, \"batches_seen\": 11700, \"train_examples_seen\": 93581, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:42:33.221 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:24:20\", \"epochs_done\": 19, \"batches_seen\": 11818, \"train_examples_seen\": 94525, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:42:54.906 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:24:42\", \"epochs_done\": 19, \"batches_seen\": 12000, \"train_examples_seen\": 95981, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:43:29.40 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8727}, \"time_spent\": \"0:25:16\", \"epochs_done\": 19, \"batches_seen\": 12300, \"train_examples_seen\": 98381, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:43:45.645 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8909}, \"time_spent\": \"0:25:33\", \"epochs_done\": 20, \"batches_seen\": 12440, \"train_examples_seen\": 99500, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:44:06.273 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.9091}, \"time_spent\": \"0:25:53\", \"epochs_done\": 20, \"batches_seen\": 12600, \"train_examples_seen\": 100779, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:44:40.501 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:26:28\", \"epochs_done\": 20, \"batches_seen\": 12900, \"train_examples_seen\": 103179, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:44:58.153 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:26:45\", \"epochs_done\": 21, \"batches_seen\": 13062, \"train_examples_seen\": 104475, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:45:14.227 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:27:01\", \"epochs_done\": 21, \"batches_seen\": 13200, \"train_examples_seen\": 105579, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:45:48.830 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:27:36\", \"epochs_done\": 21, \"batches_seen\": 13500, \"train_examples_seen\": 107979, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:46:10.976 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:27:58\", \"epochs_done\": 22, \"batches_seen\": 13684, \"train_examples_seen\": 109450, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:46:25.249 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9673\n","2022-05-23 20:46:25.260 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:46:28.59 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n","2022-05-23 20:46:28.61 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 308: Ran out of patience\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:28:12\", \"epochs_done\": 22, \"batches_seen\": 13800, \"train_examples_seen\": 110378, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:46:28.683 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/tag.dict]\n","2022-05-23 20:46:43.340 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:46:45.188 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9673, \"accuracy\": 0.9273}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:46:46.954 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/tag.dict]\n","2022-05-23 20:47:03.260 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_top1000/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:47:05.63 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]},{"cell_type":"markdown","source":["### other"],"metadata":{"id":"jjcuynC5jpoi"}},{"cell_type":"code","source":["### dir for my models\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/fs_models/model_other'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt', '{MODELS_PATH}/freq_groups/0.txt']\n","base_config['train']['validation_patience'] = 30\n","base_config['train']['epochs'] = 60\n","\n","base_config['chainer']['pipe'][1]['last'] = True"],"metadata":{"id":"WqkYhAsajvnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = train_model(base_config, download=False) \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItzRPmPxjwkT","outputId":"e63641c4-1109-4e7e-859d-b14978c820f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 20:49:37.741 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n","2022-05-23 20:49:38.721 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/tag.dict]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:49:55.511 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 20:49:56.858 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.0031\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.0031, \"accuracy\": 0.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:50:37.196 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.0031 to 0.6789\n","2022-05-23 20:50:37.198 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:50:37.209 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.6789, \"accuracy\": 0.1273}, \"time_spent\": \"0:00:42\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2399, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:51:16.952 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.6789 to 0.8089\n","2022-05-23 20:51:16.954 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:51:16.964 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8089, \"accuracy\": 0.2364}, \"time_spent\": \"0:01:22\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:51:24.449 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8089 to 0.815\n","2022-05-23 20:51:24.450 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:51:24.462 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.815, \"accuracy\": 0.2}, \"time_spent\": \"0:01:29\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:52:05.538 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.815 to 0.8486\n","2022-05-23 20:52:05.540 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:52:05.549 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8486, \"accuracy\": 0.2545}, \"time_spent\": \"0:02:11\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7198, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:52:44.958 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8486 to 0.87\n","2022-05-23 20:52:44.965 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:52:44.973 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.87, \"accuracy\": 0.2909}, \"time_spent\": \"0:02:50\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:52:54.719 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.87 to 0.8777\n","2022-05-23 20:52:54.721 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:52:54.732 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8777, \"accuracy\": 0.2727}, \"time_spent\": \"0:03:00\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:53:30.565 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8777 to 0.8914\n","2022-05-23 20:53:30.572 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:53:30.581 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8914, \"accuracy\": 0.3455}, \"time_spent\": \"0:03:36\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11997, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:54:10.600 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8914 to 0.9052\n","2022-05-23 20:54:10.602 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:54:10.613 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9052, \"accuracy\": 0.3818}, \"time_spent\": \"0:04:16\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14397, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:54:23.880 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9052 to 0.9113\n","2022-05-23 20:54:23.883 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:54:23.896 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9113, \"accuracy\": 0.4182}, \"time_spent\": \"0:04:29\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:54:57.509 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9113 to 0.9159\n","2022-05-23 20:54:57.511 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:54:57.521 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9159, \"accuracy\": 0.4364}, \"time_spent\": \"0:05:02\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16797, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:55:38.104 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9159\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9144, \"accuracy\": 0.3818}, \"time_spent\": \"0:05:43\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:55:48.732 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9159\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9159, \"accuracy\": 0.4182}, \"time_spent\": \"0:05:54\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:56:14.164 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9159 to 0.9205\n","2022-05-23 20:56:14.165 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:56:14.177 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9205, \"accuracy\": 0.4364}, \"time_spent\": \"0:06:19\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21596, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:56:54.936 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9205\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9174, \"accuracy\": 0.4727}, \"time_spent\": \"0:07:00\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23995, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:57:08.141 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9205 to 0.9312\n","2022-05-23 20:57:08.148 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:57:08.151 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9312, \"accuracy\": 0.5273}, \"time_spent\": \"0:07:13\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:57:37.607 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9312\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9251, \"accuracy\": 0.4727}, \"time_spent\": \"0:07:43\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26395, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:58:12.264 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9312 to 0.9343\n","2022-05-23 20:58:12.270 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 20:58:12.276 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.5273}, \"time_spent\": \"0:08:17\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:58:33.759 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9343\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.4909}, \"time_spent\": \"0:08:39\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:58:53.955 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9343\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9266, \"accuracy\": 0.4545}, \"time_spent\": \"0:08:59\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31194, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:59:27.978 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9343\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9312, \"accuracy\": 0.4909}, \"time_spent\": \"0:09:33\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33594, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 20:59:47.338 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9343\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9297, \"accuracy\": 0.5273}, \"time_spent\": \"0:09:52\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:00:04.924 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9343 to 0.9373\n","2022-05-23 21:00:04.925 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:00:04.933 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9373, \"accuracy\": 0.5273}, \"time_spent\": \"0:10:10\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35993, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:00:44.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9373 to 0.9434\n","2022-05-23 21:00:44.696 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:00:44.703 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5636}, \"time_spent\": \"0:10:50\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38393, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:01:11.712 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9434\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.5273}, \"time_spent\": \"0:11:17\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:01:26.911 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9434\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.5455}, \"time_spent\": \"0:11:32\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:02:02.198 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9434\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.5091}, \"time_spent\": \"0:12:07\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43191, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:02:25.437 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9434\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.5273}, \"time_spent\": \"0:12:30\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:02:38.745 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9434\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.4727}, \"time_spent\": \"0:12:44\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:03:13.0 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9434 to 0.9465\n","2022-05-23 21:03:13.4 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:03:13.11 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9465, \"accuracy\": 0.5818}, \"time_spent\": \"0:13:18\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47991, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:03:44.852 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9465\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9327, \"accuracy\": 0.4909}, \"time_spent\": \"0:13:50\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:03:55.128 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9465\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9297, \"accuracy\": 0.4545}, \"time_spent\": \"0:14:00\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:04:30.608 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9465\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9327, \"accuracy\": 0.5091}, \"time_spent\": \"0:14:36\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52790, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:04:58.378 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9465\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5455}, \"time_spent\": \"0:15:03\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:05:06.309 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9465\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9373, \"accuracy\": 0.5273}, \"time_spent\": \"0:15:11\", \"epochs_done\": 11, \"batches_seen\": 6900, \"train_examples_seen\": 55189, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:05:40.208 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9465 to 0.9495\n","2022-05-23 21:05:40.216 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:05:40.223 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.6}, \"time_spent\": \"0:15:45\", \"epochs_done\": 11, \"batches_seen\": 7200, \"train_examples_seen\": 57589, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:06:17.767 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.5455}, \"time_spent\": \"0:16:23\", \"epochs_done\": 12, \"batches_seen\": 7464, \"train_examples_seen\": 59700, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:06:22.968 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9495 to 0.9511\n","2022-05-23 21:06:22.970 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:06:22.982 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9511, \"accuracy\": 0.5636}, \"time_spent\": \"0:16:28\", \"epochs_done\": 12, \"batches_seen\": 7500, \"train_examples_seen\": 59988, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:07:04.230 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:17:09\", \"epochs_done\": 12, \"batches_seen\": 7800, \"train_examples_seen\": 62387, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:07:37.235 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9373, \"accuracy\": 0.5273}, \"time_spent\": \"0:17:42\", \"epochs_done\": 13, \"batches_seen\": 8086, \"train_examples_seen\": 64675, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:07:39.915 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9358, \"accuracy\": 0.4909}, \"time_spent\": \"0:17:45\", \"epochs_done\": 13, \"batches_seen\": 8100, \"train_examples_seen\": 64787, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:08:14.166 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9511 to 0.9572\n","2022-05-23 21:08:14.167 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:08:14.179 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9572, \"accuracy\": 0.6}, \"time_spent\": \"0:18:19\", \"epochs_done\": 13, \"batches_seen\": 8400, \"train_examples_seen\": 67187, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:08:54.789 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5091}, \"time_spent\": \"0:19:00\", \"epochs_done\": 13, \"batches_seen\": 8700, \"train_examples_seen\": 69586, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:08:55.907 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:19:01\", \"epochs_done\": 14, \"batches_seen\": 8708, \"train_examples_seen\": 69650, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:09:30.25 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.5455}, \"time_spent\": \"0:19:35\", \"epochs_done\": 14, \"batches_seen\": 9000, \"train_examples_seen\": 71986, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:10:05.490 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.4727}, \"time_spent\": \"0:20:10\", \"epochs_done\": 14, \"batches_seen\": 9300, \"train_examples_seen\": 74385, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:10:09.100 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.5273}, \"time_spent\": \"0:20:14\", \"epochs_done\": 15, \"batches_seen\": 9330, \"train_examples_seen\": 74625, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:10:41.62 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.5273}, \"time_spent\": \"0:20:46\", \"epochs_done\": 15, \"batches_seen\": 9600, \"train_examples_seen\": 76785, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:11:15.658 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9388, \"accuracy\": 0.4909}, \"time_spent\": \"0:21:21\", \"epochs_done\": 15, \"batches_seen\": 9900, \"train_examples_seen\": 79185, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:11:22.444 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5455}, \"time_spent\": \"0:21:27\", \"epochs_done\": 16, \"batches_seen\": 9952, \"train_examples_seen\": 79600, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:11:53.321 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.5091}, \"time_spent\": \"0:21:58\", \"epochs_done\": 16, \"batches_seen\": 10200, \"train_examples_seen\": 81583, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:12:27.694 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5091}, \"time_spent\": \"0:22:33\", \"epochs_done\": 16, \"batches_seen\": 10500, \"train_examples_seen\": 83983, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:12:36.351 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.4909}, \"time_spent\": \"0:22:41\", \"epochs_done\": 17, \"batches_seen\": 10574, \"train_examples_seen\": 84575, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:13:04.283 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5455}, \"time_spent\": \"0:23:09\", \"epochs_done\": 17, \"batches_seen\": 10800, \"train_examples_seen\": 86382, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:13:39.321 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.5455}, \"time_spent\": \"0:23:44\", \"epochs_done\": 17, \"batches_seen\": 11100, \"train_examples_seen\": 88782, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:13:50.553 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.5636}, \"time_spent\": \"0:23:56\", \"epochs_done\": 18, \"batches_seen\": 11196, \"train_examples_seen\": 89550, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:14:16.163 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.5273}, \"time_spent\": \"0:24:21\", \"epochs_done\": 18, \"batches_seen\": 11400, \"train_examples_seen\": 91181, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:14:51.145 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5636}, \"time_spent\": \"0:24:56\", \"epochs_done\": 18, \"batches_seen\": 11700, \"train_examples_seen\": 93581, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:15:04.723 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5455}, \"time_spent\": \"0:25:10\", \"epochs_done\": 19, \"batches_seen\": 11818, \"train_examples_seen\": 94525, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:15:27.47 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.6}, \"time_spent\": \"0:25:32\", \"epochs_done\": 19, \"batches_seen\": 12000, \"train_examples_seen\": 95981, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:16:02.609 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9511, \"accuracy\": 0.6}, \"time_spent\": \"0:26:08\", \"epochs_done\": 19, \"batches_seen\": 12300, \"train_examples_seen\": 98380, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:16:18.960 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.5818}, \"time_spent\": \"0:26:24\", \"epochs_done\": 20, \"batches_seen\": 12440, \"train_examples_seen\": 99500, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:16:38.369 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.5818}, \"time_spent\": \"0:26:43\", \"epochs_done\": 20, \"batches_seen\": 12600, \"train_examples_seen\": 100780, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:17:14.280 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9404, \"accuracy\": 0.5091}, \"time_spent\": \"0:27:19\", \"epochs_done\": 20, \"batches_seen\": 12900, \"train_examples_seen\": 103179, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:17:33.222 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9388, \"accuracy\": 0.4909}, \"time_spent\": \"0:27:38\", \"epochs_done\": 21, \"batches_seen\": 13062, \"train_examples_seen\": 104475, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:17:50.313 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9388, \"accuracy\": 0.5455}, \"time_spent\": \"0:27:55\", \"epochs_done\": 21, \"batches_seen\": 13200, \"train_examples_seen\": 105579, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:18:25.391 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9373, \"accuracy\": 0.4909}, \"time_spent\": \"0:28:30\", \"epochs_done\": 21, \"batches_seen\": 13500, \"train_examples_seen\": 107979, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:18:47.642 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:28:53\", \"epochs_done\": 22, \"batches_seen\": 13684, \"train_examples_seen\": 109450, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:19:01.718 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5455}, \"time_spent\": \"0:29:07\", \"epochs_done\": 22, \"batches_seen\": 13800, \"train_examples_seen\": 110378, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:19:36.559 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9404, \"accuracy\": 0.4909}, \"time_spent\": \"0:29:42\", \"epochs_done\": 22, \"batches_seen\": 14100, \"train_examples_seen\": 112778, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:01.988 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5636}, \"time_spent\": \"0:30:07\", \"epochs_done\": 23, \"batches_seen\": 14306, \"train_examples_seen\": 114425, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:14.422 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9572\n","2022-05-23 21:20:14.445 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:17.532 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n","2022-05-23 21:20:17.534 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 308: Ran out of patience\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9404, \"accuracy\": 0.5273}, \"time_spent\": \"0:30:19\", \"epochs_done\": 23, \"batches_seen\": 14400, \"train_examples_seen\": 115177, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:18.185 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/tag.dict]\n","2022-05-23 21:20:32.999 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:34.955 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9572, \"accuracy\": 0.6}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:36.795 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/tag.dict]\n","2022-05-23 21:20:55.485 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/fs_models/model_other/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:20:57.368 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]},{"cell_type":"markdown","source":["## Baseline General"],"metadata":{"id":"bhyIG3at48Wp"}},{"cell_type":"markdown","source":["From Scratch General Model to compare with"],"metadata":{"id":"y2XkriFeXPqK"}},{"cell_type":"code","source":["empty_file = open('empty_file.txt', 'w') #take tokens apart from the ones in this file => all\n"],"metadata":{"id":"0jV-yjM347qY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### dir for my models\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/baseline'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{ROOT_PATH}/empty_file.txt']\n","base_config['train']['validation_patience'] = 30\n","base_config['train']['epochs'] = 60\n","base_config['chainer']['pipe'][1]['last'] = True #take all tokens"],"metadata":{"id":"NwCGpbKVZ8Pk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["baseline_model = train_model(base_config, download=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lD-XSLchbULm","outputId":"7bddd9a0-718f-40cd-ae0c-7151f23c7ba1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 21:21:57.849 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n","2022-05-23 21:21:58.210 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/tag.dict]\n","2022-05-23 21:21:58.879 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/tag.dict]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:22:18.154 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 21:22:19.544 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.001\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.001, \"accuracy\": 0.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:22:58.555 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.001 to 0.7093\n","2022-05-23 21:22:58.563 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:22:58.567 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.7093, \"accuracy\": 0.0545}, \"time_spent\": \"0:00:41\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2400, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:23:38.862 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.7093 to 0.8268\n","2022-05-23 21:23:38.863 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:23:38.877 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8268, \"accuracy\": 0.1273}, \"time_spent\": \"0:01:21\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:23:46.115 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8268 to 0.8296\n","2022-05-23 21:23:46.117 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:23:46.128 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8296, \"accuracy\": 0.0727}, \"time_spent\": \"0:01:28\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:24:24.548 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8296 to 0.8691\n","2022-05-23 21:24:24.554 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:24:24.560 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8691, \"accuracy\": 0.2182}, \"time_spent\": \"0:02:07\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7198, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:25:03.275 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8691 to 0.8941\n","2022-05-23 21:25:03.276 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:25:03.285 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8941, \"accuracy\": 0.2909}, \"time_spent\": \"0:02:46\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:25:12.970 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.8941\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.8874, \"accuracy\": 0.2182}, \"time_spent\": \"0:02:55\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:25:44.804 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.8941 to 0.9076\n","2022-05-23 21:25:44.809 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:25:44.816 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9076, \"accuracy\": 0.3091}, \"time_spent\": \"0:03:27\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11997, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:26:24.277 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9076 to 0.9182\n","2022-05-23 21:26:24.279 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:26:24.289 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9182, \"accuracy\": 0.2909}, \"time_spent\": \"0:04:07\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14397, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:26:36.8 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9182 to 0.923\n","2022-05-23 21:26:36.17 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:26:36.27 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.923, \"accuracy\": 0.3273}, \"time_spent\": \"0:04:18\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:27:10.161 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.923\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9192, \"accuracy\": 0.3091}, \"time_spent\": \"0:04:53\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16797, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:27:45.58 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.923 to 0.9307\n","2022-05-23 21:27:45.64 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:27:45.69 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9307, \"accuracy\": 0.3455}, \"time_spent\": \"0:05:27\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:28:00.275 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9307 to 0.9317\n","2022-05-23 21:28:00.277 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:28:00.290 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9317, \"accuracy\": 0.3818}, \"time_spent\": \"0:05:43\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:28:32.30 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9317 to 0.9384\n","2022-05-23 21:28:32.32 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:28:32.43 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9384, \"accuracy\": 0.4}, \"time_spent\": \"0:06:14\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21595, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:29:11.747 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9384\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9336, \"accuracy\": 0.3818}, \"time_spent\": \"0:06:54\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23995, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:29:24.621 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9384\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9326, \"accuracy\": 0.3455}, \"time_spent\": \"0:07:07\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:29:47.802 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9384\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9365, \"accuracy\": 0.3818}, \"time_spent\": \"0:07:30\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26394, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:30:21.953 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9384 to 0.9442\n","2022-05-23 21:30:21.959 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:30:21.965 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4}, \"time_spent\": \"0:08:04\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:30:43.188 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9442\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4182}, \"time_spent\": \"0:08:26\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:31:03.764 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9442\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9326, \"accuracy\": 0.3455}, \"time_spent\": \"0:08:46\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31194, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:31:38.167 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9442\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9403, \"accuracy\": 0.4}, \"time_spent\": \"0:09:21\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33593, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:31:56.282 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9442\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4}, \"time_spent\": \"0:09:39\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:32:14.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9442 to 0.9471\n","2022-05-23 21:32:14.589 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:32:14.596 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.4}, \"time_spent\": \"0:09:57\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35993, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:32:53.845 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9365, \"accuracy\": 0.3455}, \"time_spent\": \"0:10:36\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38393, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:33:14.387 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4182}, \"time_spent\": \"0:10:57\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:33:29.607 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9403, \"accuracy\": 0.4182}, \"time_spent\": \"0:11:12\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:34:03.581 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9451, \"accuracy\": 0.3636}, \"time_spent\": \"0:11:46\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43192, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:34:27.525 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9413, \"accuracy\": 0.4}, \"time_spent\": \"0:12:10\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:34:40.657 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9432, \"accuracy\": 0.4182}, \"time_spent\": \"0:12:23\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:35:15.55 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9403, \"accuracy\": 0.3636}, \"time_spent\": \"0:12:57\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47991, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:35:40.588 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9471\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9423, \"accuracy\": 0.3455}, \"time_spent\": \"0:13:23\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:35:50.637 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9471 to 0.948\n","2022-05-23 21:35:50.639 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:35:50.651 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.4182}, \"time_spent\": \"0:13:33\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:36:31.867 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.948\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.3636}, \"time_spent\": \"0:14:14\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52789, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:36:58.908 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.948\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.4182}, \"time_spent\": \"0:14:41\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:37:06.520 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.948\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4182}, \"time_spent\": \"0:14:49\", \"epochs_done\": 11, \"batches_seen\": 6900, \"train_examples_seen\": 55189, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:37:41.768 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.948\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9432, \"accuracy\": 0.4364}, \"time_spent\": \"0:15:24\", \"epochs_done\": 11, \"batches_seen\": 7200, \"train_examples_seen\": 57588, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:38:11.921 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.948 to 0.95\n","2022-05-23 21:38:11.922 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:38:11.930 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.95, \"accuracy\": 0.4182}, \"time_spent\": \"0:15:54\", \"epochs_done\": 12, \"batches_seen\": 7464, \"train_examples_seen\": 59700, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:38:22.298 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9461, \"accuracy\": 0.4364}, \"time_spent\": \"0:16:05\", \"epochs_done\": 12, \"batches_seen\": 7500, \"train_examples_seen\": 59988, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:38:57.258 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9394, \"accuracy\": 0.3455}, \"time_spent\": \"0:16:40\", \"epochs_done\": 12, \"batches_seen\": 7800, \"train_examples_seen\": 62388, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:39:31.134 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.3455}, \"time_spent\": \"0:17:13\", \"epochs_done\": 13, \"batches_seen\": 8086, \"train_examples_seen\": 64675, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:39:33.889 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9451, \"accuracy\": 0.3818}, \"time_spent\": \"0:17:16\", \"epochs_done\": 13, \"batches_seen\": 8100, \"train_examples_seen\": 64787, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:40:08.923 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.3818}, \"time_spent\": \"0:17:51\", \"epochs_done\": 13, \"batches_seen\": 8400, \"train_examples_seen\": 67186, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:40:43.400 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4}, \"time_spent\": \"0:18:26\", \"epochs_done\": 13, \"batches_seen\": 8700, \"train_examples_seen\": 69586, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:40:44.443 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9423, \"accuracy\": 0.3818}, \"time_spent\": \"0:18:27\", \"epochs_done\": 14, \"batches_seen\": 8708, \"train_examples_seen\": 69650, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:41:18.779 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.4182}, \"time_spent\": \"0:19:01\", \"epochs_done\": 14, \"batches_seen\": 9000, \"train_examples_seen\": 71986, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:41:53.810 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.95, \"accuracy\": 0.3818}, \"time_spent\": \"0:19:36\", \"epochs_done\": 14, \"batches_seen\": 9300, \"train_examples_seen\": 74385, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:41:57.570 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.95\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.3818}, \"time_spent\": \"0:19:40\", \"epochs_done\": 15, \"batches_seen\": 9330, \"train_examples_seen\": 74625, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:42:29.602 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.95 to 0.9509\n","2022-05-23 21:42:29.603 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:42:29.614 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9509, \"accuracy\": 0.4}, \"time_spent\": \"0:20:12\", \"epochs_done\": 15, \"batches_seen\": 9600, \"train_examples_seen\": 76785, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:43:09.752 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9509, \"accuracy\": 0.4545}, \"time_spent\": \"0:20:52\", \"epochs_done\": 15, \"batches_seen\": 9900, \"train_examples_seen\": 79184, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:43:16.173 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.4545}, \"time_spent\": \"0:20:59\", \"epochs_done\": 16, \"batches_seen\": 9952, \"train_examples_seen\": 79600, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:43:45.654 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.949, \"accuracy\": 0.3818}, \"time_spent\": \"0:21:28\", \"epochs_done\": 16, \"batches_seen\": 10200, \"train_examples_seen\": 81584, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:44:20.637 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.949, \"accuracy\": 0.3818}, \"time_spent\": \"0:22:03\", \"epochs_done\": 16, \"batches_seen\": 10500, \"train_examples_seen\": 83983, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:44:29.576 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9461, \"accuracy\": 0.4182}, \"time_spent\": \"0:22:12\", \"epochs_done\": 17, \"batches_seen\": 10574, \"train_examples_seen\": 84575, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:44:56.692 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.4364}, \"time_spent\": \"0:22:39\", \"epochs_done\": 17, \"batches_seen\": 10800, \"train_examples_seen\": 86383, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:45:31.795 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.95, \"accuracy\": 0.3818}, \"time_spent\": \"0:23:14\", \"epochs_done\": 17, \"batches_seen\": 11100, \"train_examples_seen\": 88782, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:45:42.950 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9509\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9509, \"accuracy\": 0.4182}, \"time_spent\": \"0:23:25\", \"epochs_done\": 18, \"batches_seen\": 11196, \"train_examples_seen\": 89550, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:46:07.362 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9509 to 0.9538\n","2022-05-23 21:46:07.364 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 21:46:07.376 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9538, \"accuracy\": 0.4364}, \"time_spent\": \"0:23:50\", \"epochs_done\": 18, \"batches_seen\": 11400, \"train_examples_seen\": 91182, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:46:48.755 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9509, \"accuracy\": 0.4182}, \"time_spent\": \"0:24:31\", \"epochs_done\": 18, \"batches_seen\": 11700, \"train_examples_seen\": 93581, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:47:02.736 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9413, \"accuracy\": 0.3818}, \"time_spent\": \"0:24:45\", \"epochs_done\": 19, \"batches_seen\": 11818, \"train_examples_seen\": 94525, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:47:25.237 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9519, \"accuracy\": 0.4}, \"time_spent\": \"0:25:08\", \"epochs_done\": 19, \"batches_seen\": 12000, \"train_examples_seen\": 95980, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:47:59.909 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9461, \"accuracy\": 0.3636}, \"time_spent\": \"0:25:42\", \"epochs_done\": 19, \"batches_seen\": 12300, \"train_examples_seen\": 98380, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:48:16.3 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.949, \"accuracy\": 0.4182}, \"time_spent\": \"0:25:58\", \"epochs_done\": 20, \"batches_seen\": 12440, \"train_examples_seen\": 99500, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:48:35.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.949, \"accuracy\": 0.3818}, \"time_spent\": \"0:26:18\", \"epochs_done\": 20, \"batches_seen\": 12600, \"train_examples_seen\": 100780, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:49:10.780 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.95, \"accuracy\": 0.4}, \"time_spent\": \"0:26:53\", \"epochs_done\": 20, \"batches_seen\": 12900, \"train_examples_seen\": 103179, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:49:29.160 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.949, \"accuracy\": 0.3818}, \"time_spent\": \"0:27:12\", \"epochs_done\": 21, \"batches_seen\": 13062, \"train_examples_seen\": 104475, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:49:46.208 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.95, \"accuracy\": 0.3818}, \"time_spent\": \"0:27:29\", \"epochs_done\": 21, \"batches_seen\": 13200, \"train_examples_seen\": 105579, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:50:21.245 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9519, \"accuracy\": 0.4}, \"time_spent\": \"0:28:04\", \"epochs_done\": 21, \"batches_seen\": 13500, \"train_examples_seen\": 107978, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:50:42.467 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.3818}, \"time_spent\": \"0:28:25\", \"epochs_done\": 22, \"batches_seen\": 13684, \"train_examples_seen\": 109450, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:50:57.147 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.95, \"accuracy\": 0.3818}, \"time_spent\": \"0:28:39\", \"epochs_done\": 22, \"batches_seen\": 13800, \"train_examples_seen\": 110378, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:51:32.513 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9461, \"accuracy\": 0.3636}, \"time_spent\": \"0:29:15\", \"epochs_done\": 22, \"batches_seen\": 14100, \"train_examples_seen\": 112777, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:51:55.823 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.3818}, \"time_spent\": \"0:29:38\", \"epochs_done\": 23, \"batches_seen\": 14306, \"train_examples_seen\": 114425, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:52:06.863 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.949, \"accuracy\": 0.3818}, \"time_spent\": \"0:29:49\", \"epochs_done\": 23, \"batches_seen\": 14400, \"train_examples_seen\": 115177, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:52:42.473 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.3818}, \"time_spent\": \"0:30:25\", \"epochs_done\": 23, \"batches_seen\": 14700, \"train_examples_seen\": 117577, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:53:09.219 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9451, \"accuracy\": 0.3818}, \"time_spent\": \"0:30:52\", \"epochs_done\": 24, \"batches_seen\": 14928, \"train_examples_seen\": 119400, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:53:18.425 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9432, \"accuracy\": 0.3636}, \"time_spent\": \"0:31:01\", \"epochs_done\": 24, \"batches_seen\": 15000, \"train_examples_seen\": 119976, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:53:52.555 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9423, \"accuracy\": 0.4182}, \"time_spent\": \"0:31:35\", \"epochs_done\": 24, \"batches_seen\": 15300, \"train_examples_seen\": 122376, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:54:22.482 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9394, \"accuracy\": 0.3636}, \"time_spent\": \"0:32:05\", \"epochs_done\": 25, \"batches_seen\": 15550, \"train_examples_seen\": 124375, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:54:29.56 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9432, \"accuracy\": 0.3818}, \"time_spent\": \"0:32:11\", \"epochs_done\": 25, \"batches_seen\": 15600, \"train_examples_seen\": 124775, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:55:03.505 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.4}, \"time_spent\": \"0:32:46\", \"epochs_done\": 25, \"batches_seen\": 15900, \"train_examples_seen\": 127175, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:55:35.757 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9451, \"accuracy\": 0.3455}, \"time_spent\": \"0:33:18\", \"epochs_done\": 26, \"batches_seen\": 16172, \"train_examples_seen\": 129350, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:55:39.950 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.3455}, \"time_spent\": \"0:33:22\", \"epochs_done\": 26, \"batches_seen\": 16200, \"train_examples_seen\": 129574, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:56:15.214 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9451, \"accuracy\": 0.3455}, \"time_spent\": \"0:33:58\", \"epochs_done\": 26, \"batches_seen\": 16500, \"train_examples_seen\": 131973, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:56:48.883 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.3818}, \"time_spent\": \"0:34:31\", \"epochs_done\": 27, \"batches_seen\": 16794, \"train_examples_seen\": 134325, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:56:50.650 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.948, \"accuracy\": 0.3636}, \"time_spent\": \"0:34:33\", \"epochs_done\": 27, \"batches_seen\": 16800, \"train_examples_seen\": 134373, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:57:25.121 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9471, \"accuracy\": 0.4}, \"time_spent\": \"0:35:07\", \"epochs_done\": 27, \"batches_seen\": 17100, \"train_examples_seen\": 136773, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:00.948 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9423, \"accuracy\": 0.3818}, \"time_spent\": \"0:35:43\", \"epochs_done\": 27, \"batches_seen\": 17400, \"train_examples_seen\": 139172, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:02.692 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9538\n","2022-05-23 21:58:02.704 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:05.787 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9442, \"accuracy\": 0.3818}, \"time_spent\": \"0:35:45\", \"epochs_done\": 28, \"batches_seen\": 17416, \"train_examples_seen\": 139300, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:06.665 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n","2022-05-23 21:58:07.320 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/tag.dict]\n","2022-05-23 21:58:21.862 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:23.836 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9538, \"accuracy\": 0.4364}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:25.594 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/tag.dict]\n","2022-05-23 21:58:44.596 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 21:58:46.431 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]},{"cell_type":"markdown","source":["## FineTune Models"],"metadata":{"id":"6OGAEZQpBVZD"}},{"cell_type":"markdown","source":["Load baseline general model and fit it on groups separately"],"metadata":{"id":"pXFjfVeTSdzB"}},{"cell_type":"code","source":["base_config['chainer']['pipe'][3]['load_path'] = '{MODELS_PATH}/baseline/model'"],"metadata":{"id":"HQVGHaTTTdJt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### top100"],"metadata":{"id":"4KxssxMlvDsV"}},{"cell_type":"code","source":["### dir for my models\n","\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_top100'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt']\n","base_config['train']['validation_patience'] = 30\n","base_config['train']['epochs'] = 60\n","base_config['chainer']['pipe'][1]['last'] = False"],"metadata":{"id":"LrDJnvqMrgAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = train_model(base_config, download=False)  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SAVNphDswarw","outputId":"3b667152-096d-43ff-ed1f-319f75160223"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 22:08:43.694 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n","2022-05-23 22:08:44.524 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/tag.dict]\n","2022-05-23 22:09:04.15 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:09:05.882 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 22:09:07.464 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:09:47.992 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:00:43\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2400, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:10:22.789 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9698\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:01:17\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:10:25.534 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9698 to 0.9741\n","2022-05-23 22:10:25.536 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 22:10:25.543 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9741, \"accuracy\": 0.8909}, \"time_spent\": \"0:01:20\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:11:03.827 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:01:58\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7199, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:11:39.506 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:02:34\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:11:44.891 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:02:40\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:12:15.948 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:03:11\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11998, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:12:50.862 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:03:45\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14397, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:12:58.516 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:03:53\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:13:26.615 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:04:21\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16796, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:14:01.334 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:04:56\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:14:11.842 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:05:06\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:14:37.430 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:05:32\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21596, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:15:13.16 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8364}, \"time_spent\": \"0:06:08\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23995, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:15:25.54 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:06:20\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:15:47.621 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:06:42\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26395, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:16:23.671 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:07:18\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:16:38.625 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:07:33\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:16:58.993 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:07:54\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31194, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:17:34.423 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:08:29\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33593, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:17:52.54 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:08:47\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:18:09.800 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:09:04\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35993, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:18:45.452 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9483, \"accuracy\": 0.7818}, \"time_spent\": \"0:09:40\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38392, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:19:05.553 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:10:00\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:19:20.863 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:10:15\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:19:56.423 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:10:51\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43191, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:20:19.43 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:11:14\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:20:31.733 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:11:26\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:21:07.33 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:12:02\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47991, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:21:32.572 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:12:27\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:21:42.639 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9655, \"accuracy\": 0.8545}, \"time_spent\": \"0:12:37\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:22:18.97 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9569, \"accuracy\": 0.8182}, \"time_spent\": \"0:13:13\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52789, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:22:46.122 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9741\n","2022-05-23 22:22:46.132 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:22:48.594 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9612, \"accuracy\": 0.8364}, \"time_spent\": \"0:13:41\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:22:49.217 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n","2022-05-23 22:22:49.737 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/tag.dict]\n","2022-05-23 22:22:49.751 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model' differs from save path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/model' in 'infer' mode for MyBertSequenceTagger.\n","2022-05-23 22:23:04.885 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:23:06.814 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9698, \"accuracy\": 0.8727}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:23:08.496 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/tag.dict]\n","2022-05-23 22:23:28.869 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top100/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:23:30.773 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]},{"cell_type":"markdown","source":["### top1000"],"metadata":{"id":"mpMTEudm7d9j"}},{"cell_type":"code","source":["### dir for my models\n","\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_top1000'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/1.txt']\n","base_config['train']['validation_patience'] = 30\n","base_config['train']['epochs'] = 60\n","base_config['chainer']['pipe'][1]['last'] = False"],"metadata":{"id":"Fg97uNC57dvg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = train_model(base_config, download=False)  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pj99XN_z7l7C","outputId":"6e07700b-aee8-45f2-e5a1-63072aaff72f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 22:32:16.268 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n","2022-05-23 22:32:17.697 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/tag.dict]\n","2022-05-23 22:32:35.344 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:32:37.189 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 22:32:38.470 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:33:19.126 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.8545}, \"time_spent\": \"0:00:42\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2399, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:33:52.968 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.8545}, \"time_spent\": \"0:01:16\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:33:55.721 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9216, \"accuracy\": 0.8364}, \"time_spent\": \"0:01:19\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:34:28.51 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.8364}, \"time_spent\": \"0:01:51\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7199, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:35:03.928 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8909}, \"time_spent\": \"0:02:27\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:35:08.844 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8909}, \"time_spent\": \"0:02:32\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:35:39.184 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8727}, \"time_spent\": \"0:03:02\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11997, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:36:13.895 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9477\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:03:37\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14397, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:36:21.877 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9477 to 0.9542\n","2022-05-23 22:36:21.878 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 22:36:21.886 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:03:45\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:36:55.149 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:04:18\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16796, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:37:29.827 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8727}, \"time_spent\": \"0:04:53\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:37:39.917 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:05:03\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:38:04.814 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8909}, \"time_spent\": \"0:05:28\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21596, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:38:40.71 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:06:03\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23995, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:38:52.975 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:06:16\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:39:14.585 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8364}, \"time_spent\": \"0:06:38\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26395, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:39:50.641 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:07:14\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:40:05.795 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9542\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:07:29\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:40:26.195 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9542 to 0.9608\n","2022-05-23 22:40:26.196 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 22:40:26.208 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:07:50\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31193, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:41:06.674 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:08:30\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33593, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:41:23.889 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8182}, \"time_spent\": \"0:08:47\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:41:42.204 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8909}, \"time_spent\": \"0:09:06\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35992, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:42:16.735 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:09:40\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38392, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:42:36.680 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:10:00\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:42:51.121 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9608, \"accuracy\": 0.8909}, \"time_spent\": \"0:10:14\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:43:26.259 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:10:50\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43191, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:43:49.407 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:11:13\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:44:01.393 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:11:25\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:44:36.851 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8545}, \"time_spent\": \"0:12:00\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47990, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:45:02.65 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:12:25\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:45:11.836 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9542, \"accuracy\": 0.8727}, \"time_spent\": \"0:12:35\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:45:46.106 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:13:09\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52790, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:46:14.931 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:13:38\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:46:22.58 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:13:45\", \"epochs_done\": 11, \"batches_seen\": 6900, \"train_examples_seen\": 55189, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:46:57.344 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8727}, \"time_spent\": \"0:14:21\", \"epochs_done\": 11, \"batches_seen\": 7200, \"train_examples_seen\": 57588, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:47:27.818 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8909}, \"time_spent\": \"0:14:51\", \"epochs_done\": 12, \"batches_seen\": 7464, \"train_examples_seen\": 59700, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:47:32.635 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:14:56\", \"epochs_done\": 12, \"batches_seen\": 7500, \"train_examples_seen\": 59988, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:48:07.819 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8727}, \"time_spent\": \"0:15:31\", \"epochs_done\": 12, \"batches_seen\": 7800, \"train_examples_seen\": 62387, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:48:40.586 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:16:04\", \"epochs_done\": 13, \"batches_seen\": 8086, \"train_examples_seen\": 64675, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:48:42.750 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9412, \"accuracy\": 0.8545}, \"time_spent\": \"0:16:06\", \"epochs_done\": 13, \"batches_seen\": 8100, \"train_examples_seen\": 64787, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:49:18.387 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.8545}, \"time_spent\": \"0:16:42\", \"epochs_done\": 13, \"batches_seen\": 8400, \"train_examples_seen\": 67186, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:49:52.645 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9216, \"accuracy\": 0.8364}, \"time_spent\": \"0:17:16\", \"epochs_done\": 13, \"batches_seen\": 8700, \"train_examples_seen\": 69586, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:49:53.695 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.915, \"accuracy\": 0.8182}, \"time_spent\": \"0:17:17\", \"epochs_done\": 14, \"batches_seen\": 8708, \"train_examples_seen\": 69650, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:50:28.501 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8364}, \"time_spent\": \"0:17:52\", \"epochs_done\": 14, \"batches_seen\": 9000, \"train_examples_seen\": 71985, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:51:02.719 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:18:26\", \"epochs_done\": 14, \"batches_seen\": 9300, \"train_examples_seen\": 74385, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:51:06.377 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:18:30\", \"epochs_done\": 15, \"batches_seen\": 9330, \"train_examples_seen\": 74625, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:51:37.486 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:19:01\", \"epochs_done\": 15, \"batches_seen\": 9600, \"train_examples_seen\": 76785, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:13.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9346, \"accuracy\": 0.8545}, \"time_spent\": \"0:19:36\", \"epochs_done\": 15, \"batches_seen\": 9900, \"train_examples_seen\": 79184, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:19.175 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9608\n","2022-05-23 22:52:19.186 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:21.582 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9281, \"accuracy\": 0.8545}, \"time_spent\": \"0:19:42\", \"epochs_done\": 16, \"batches_seen\": 9952, \"train_examples_seen\": 79600, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:22.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 329: Ran out of patience\n","2022-05-23 22:52:22.639 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/tag.dict]\n","2022-05-23 22:52:22.655 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model' differs from save path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model' in 'infer' mode for MyBertSequenceTagger.\n","2022-05-23 22:52:36.865 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:38.749 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9477, \"accuracy\": 0.8727}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:40.443 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/tag.dict]\n","2022-05-23 22:52:57.375 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_top1000/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:52:59.624 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]},{"cell_type":"markdown","source":["### top1000+"],"metadata":{"id":"txfdOKICAuMK"}},{"cell_type":"code","source":["### dir for my models\n","base_config['metadata']['variables']['WORK_PATH'] = '{MODELS_PATH}/finetuned_models/model_other'\n","base_config['chainer']['pipe'][1]['topk_tokens_path'] = ['{MODELS_PATH}/freq_groups/0.txt', '{MODELS_PATH}/freq_groups/1.txt']\n","base_config['train']['validation_patience'] = 30\n","base_config['train']['epochs'] = 60\n","base_config['chainer']['pipe'][1]['last'] = True"],"metadata":{"id":"OTIym1LtAwdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = train_model(base_config, download=False)  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPRnK0N5A24R","outputId":"2e73555c-e9eb-4cfc-90e1-96fa6a9a3040"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-23 22:53:08.224 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n","2022-05-23 22:53:08.681 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/tag.dict]\n","2022-05-23 22:53:25.630 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:53:27.449 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n","2022-05-23 22:53:28.688 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 199: Initial best per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.5455}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:54:07.379 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5636}, \"time_spent\": \"0:00:40\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 2400, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:54:41.991 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.5273}, \"time_spent\": \"0:01:15\", \"epochs_done\": 0, \"batches_seen\": 600, \"train_examples_seen\": 4799, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:54:45.13 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5091}, \"time_spent\": \"0:01:18\", \"epochs_done\": 1, \"batches_seen\": 622, \"train_examples_seen\": 4975, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:55:17.322 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.5091}, \"time_spent\": \"0:01:50\", \"epochs_done\": 1, \"batches_seen\": 900, \"train_examples_seen\": 7199, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:55:52.909 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5091}, \"time_spent\": \"0:02:26\", \"epochs_done\": 1, \"batches_seen\": 1200, \"train_examples_seen\": 9598, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:55:57.809 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5091}, \"time_spent\": \"0:02:31\", \"epochs_done\": 2, \"batches_seen\": 1244, \"train_examples_seen\": 9950, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:56:27.507 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:03:01\", \"epochs_done\": 2, \"batches_seen\": 1500, \"train_examples_seen\": 11998, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:57:02.12 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.4727}, \"time_spent\": \"0:03:35\", \"epochs_done\": 2, \"batches_seen\": 1800, \"train_examples_seen\": 14397, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:57:10.112 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9465, \"accuracy\": 0.4727}, \"time_spent\": \"0:03:43\", \"epochs_done\": 3, \"batches_seen\": 1866, \"train_examples_seen\": 14925, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:57:38.23 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9495\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.4909}, \"time_spent\": \"0:04:11\", \"epochs_done\": 3, \"batches_seen\": 2100, \"train_examples_seen\": 16796, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:58:12.513 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 207: Improved best per_token_accuracy from 0.9495 to 0.9511\n","2022-05-23 22:58:12.514 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 209: Saving model\n","2022-05-23 22:58:12.527 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9511, \"accuracy\": 0.5091}, \"time_spent\": \"0:04:46\", \"epochs_done\": 3, \"batches_seen\": 2400, \"train_examples_seen\": 19196, \"impatience\": 0, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:58:27.182 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.5273}, \"time_spent\": \"0:05:00\", \"epochs_done\": 4, \"batches_seen\": 2488, \"train_examples_seen\": 19900, \"impatience\": 1, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:58:53.679 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5455}, \"time_spent\": \"0:05:27\", \"epochs_done\": 4, \"batches_seen\": 2700, \"train_examples_seen\": 21595, \"impatience\": 2, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:59:27.926 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5818}, \"time_spent\": \"0:06:01\", \"epochs_done\": 4, \"batches_seen\": 3000, \"train_examples_seen\": 23995, \"impatience\": 3, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 22:59:40.179 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5091}, \"time_spent\": \"0:06:13\", \"epochs_done\": 5, \"batches_seen\": 3110, \"train_examples_seen\": 24875, \"impatience\": 4, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:00:02.144 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9358, \"accuracy\": 0.4909}, \"time_spent\": \"0:06:35\", \"epochs_done\": 5, \"batches_seen\": 3300, \"train_examples_seen\": 26395, \"impatience\": 5, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:00:37.928 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.4909}, \"time_spent\": \"0:07:11\", \"epochs_done\": 5, \"batches_seen\": 3600, \"train_examples_seen\": 28794, \"impatience\": 6, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:00:52.975 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.4727}, \"time_spent\": \"0:07:26\", \"epochs_done\": 6, \"batches_seen\": 3732, \"train_examples_seen\": 29850, \"impatience\": 7, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:01:13.252 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.4909}, \"time_spent\": \"0:07:46\", \"epochs_done\": 6, \"batches_seen\": 3900, \"train_examples_seen\": 31193, \"impatience\": 8, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:01:47.223 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9404, \"accuracy\": 0.4909}, \"time_spent\": \"0:08:20\", \"epochs_done\": 6, \"batches_seen\": 4200, \"train_examples_seen\": 33593, \"impatience\": 9, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:02:05.662 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.4909}, \"time_spent\": \"0:08:39\", \"epochs_done\": 7, \"batches_seen\": 4354, \"train_examples_seen\": 34825, \"impatience\": 10, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:02:22.406 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:08:55\", \"epochs_done\": 7, \"batches_seen\": 4500, \"train_examples_seen\": 35993, \"impatience\": 11, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:02:57.861 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9404, \"accuracy\": 0.5273}, \"time_spent\": \"0:09:31\", \"epochs_done\": 7, \"batches_seen\": 4800, \"train_examples_seen\": 38392, \"impatience\": 12, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:03:18.191 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.945, \"accuracy\": 0.5273}, \"time_spent\": \"0:09:51\", \"epochs_done\": 8, \"batches_seen\": 4976, \"train_examples_seen\": 39800, \"impatience\": 13, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:03:32.782 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9388, \"accuracy\": 0.4909}, \"time_spent\": \"0:10:06\", \"epochs_done\": 8, \"batches_seen\": 5100, \"train_examples_seen\": 40792, \"impatience\": 14, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:04:08.301 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5273}, \"time_spent\": \"0:10:41\", \"epochs_done\": 8, \"batches_seen\": 5400, \"train_examples_seen\": 43191, \"impatience\": 15, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:04:30.624 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:11:04\", \"epochs_done\": 9, \"batches_seen\": 5598, \"train_examples_seen\": 44775, \"impatience\": 16, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:04:42.601 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9465, \"accuracy\": 0.5455}, \"time_spent\": \"0:11:16\", \"epochs_done\": 9, \"batches_seen\": 5700, \"train_examples_seen\": 45591, \"impatience\": 17, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:05:16.381 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5091}, \"time_spent\": \"0:11:49\", \"epochs_done\": 9, \"batches_seen\": 6000, \"train_examples_seen\": 47991, \"impatience\": 18, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:05:42.942 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9465, \"accuracy\": 0.5455}, \"time_spent\": \"0:12:16\", \"epochs_done\": 10, \"batches_seen\": 6220, \"train_examples_seen\": 49750, \"impatience\": 19, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:05:52.410 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5636}, \"time_spent\": \"0:12:25\", \"epochs_done\": 10, \"batches_seen\": 6300, \"train_examples_seen\": 50390, \"impatience\": 20, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:06:26.939 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9373, \"accuracy\": 0.4727}, \"time_spent\": \"0:13:00\", \"epochs_done\": 10, \"batches_seen\": 6600, \"train_examples_seen\": 52790, \"impatience\": 21, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:06:55.512 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5273}, \"time_spent\": \"0:13:29\", \"epochs_done\": 11, \"batches_seen\": 6842, \"train_examples_seen\": 54725, \"impatience\": 22, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:07:02.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9373, \"accuracy\": 0.5091}, \"time_spent\": \"0:13:36\", \"epochs_done\": 11, \"batches_seen\": 6900, \"train_examples_seen\": 55189, \"impatience\": 23, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:07:36.605 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5455}, \"time_spent\": \"0:14:10\", \"epochs_done\": 11, \"batches_seen\": 7200, \"train_examples_seen\": 57589, \"impatience\": 24, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:08:08.131 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9343, \"accuracy\": 0.4727}, \"time_spent\": \"0:14:41\", \"epochs_done\": 12, \"batches_seen\": 7464, \"train_examples_seen\": 59700, \"impatience\": 25, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:08:13.151 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5273}, \"time_spent\": \"0:14:46\", \"epochs_done\": 12, \"batches_seen\": 7500, \"train_examples_seen\": 59988, \"impatience\": 26, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:08:47.931 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9419, \"accuracy\": 0.5273}, \"time_spent\": \"0:15:21\", \"epochs_done\": 12, \"batches_seen\": 7800, \"train_examples_seen\": 62388, \"impatience\": 27, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:09:20.526 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9434, \"accuracy\": 0.5455}, \"time_spent\": \"0:15:54\", \"epochs_done\": 13, \"batches_seen\": 8086, \"train_examples_seen\": 64675, \"impatience\": 28, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:09:22.976 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9404, \"accuracy\": 0.5273}, \"time_spent\": \"0:15:56\", \"epochs_done\": 13, \"batches_seen\": 8100, \"train_examples_seen\": 64787, \"impatience\": 29, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:09:57.495 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 212: Did not improve on the per_token_accuracy of 0.9511\n","2022-05-23 23:09:57.505 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:09:59.893 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 1.5\n","2022-05-23 23:09:59.895 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 308: Ran out of patience\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9388, \"accuracy\": 0.5455}, \"time_spent\": \"0:16:31\", \"epochs_done\": 13, \"batches_seen\": 8400, \"train_examples_seen\": 67186, \"impatience\": 30, \"patience_limit\": 30}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:10:00.416 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/tag.dict]\n","2022-05-23 23:10:00.428 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model' differs from save path '/content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/model' in 'infer' mode for MyBertSequenceTagger.\n","2022-05-23 23:10:15.168 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/baseline/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:10:17.8 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]},{"output_type":"stream","name":"stdout","text":["{\"valid\": {\"eval_examples_count\": 55, \"metrics\": {\"per_token_accuracy\": 0.9495, \"accuracy\": 0.5455}, \"time_spent\": \"0:00:02\"}}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:10:18.668 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/tag.dict]\n","2022-05-23 23:10:36.898 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/model]\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from /content/drive/.shortcut-targets-by-id/1GTaDlf0tB2yaTzRccvhA3cso1sKiTY9u/models_diploma/GramEval_GSD/finetuned_models/model_other/model\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-23 23:10:38.796 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n"]}]}],"metadata":{"colab":{"collapsed_sections":["IUjZMZXtb89p","89m2jMJMcJky","EGRf5xGxcaHF","YGxpVfS4ccbj","Br3NWTQEcnXL","bb-UPIUPczCA","hcMJpEuZLzPh","Qa0czko8L2Iv","rrMdYc1dG7eO","4XSodQDbIMDo","_6HdtWbaGTiY","msN4Q1KmT5Za","DavKW8gHT1vg","jjcuynC5jpoi","bhyIG3at48Wp","6OGAEZQpBVZD","4KxssxMlvDsV","mpMTEudm7d9j","txfdOKICAuMK"],"name":"GramEval_GSD_of_main_2305.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}